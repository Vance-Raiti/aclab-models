device: cuda:0
save interval: 100000
batch size: 32
n_blocks=6
writing to half_model-#.pth
device: cuda:0
save interval: 100000
batch size: 32
n_blocks=6
writing to half_model-#.pth
device: cuda:0
save interval: 100000
batch size: 32
epoch 1 iter 0: train loss 0.61081. lr 3.000000e-04, running loss 0.61081, it/sec: 0.035460083227083695
epoch 1 iter 20: train loss 0.58277. lr 3.000000e-04, running loss 0.74889, it/sec: 4.2865529992885785
epoch 1 iter 40: train loss 0.69485. lr 3.000000e-04, running loss 0.67742, it/sec: 4.297154065063573
epoch 1 iter 60: train loss 0.58758. lr 3.000000e-04, running loss 0.65003, it/sec: 4.330806638397378
epoch 1 iter 80: train loss 0.49363. lr 3.000000e-04, running loss 0.63651, it/sec: 4.317286130499463
epoch 1 iter 100: train loss 0.61097. lr 3.000000e-04, running loss 0.63364, it/sec: 4.270133331064329
epoch 1 iter 120: train loss 0.57941. lr 3.000000e-04, running loss 0.63000, it/sec: 4.312185312931371
epoch 1 iter 140: train loss 0.59775. lr 3.000000e-04, running loss 0.62832, it/sec: 4.301890740675007
epoch 1 iter 160: train loss 0.61004. lr 3.000000e-04, running loss 0.62946, it/sec: 4.28642186393994
epoch 1 iter 180: train loss 0.52052. lr 3.000000e-04, running loss 0.62428, it/sec: 4.333027949471625
epoch 1 iter 200: train loss 0.61300. lr 3.000000e-04, running loss 0.62148, it/sec: 4.272360065331149
epoch 1 iter 220: train loss 0.53255. lr 3.000000e-04, running loss 0.62185, it/sec: 4.284191573113748
epoch 1 iter 240: train loss 0.72676. lr 3.000000e-04, running loss 0.62391, it/sec: 4.28783346131686
epoch 1 iter 260: train loss 0.59444. lr 3.000000e-04, running loss 0.62530, it/sec: 4.265014743605393
epoch 1 iter 280: train loss 0.53162. lr 3.000000e-04, running loss 0.62432, it/sec: 4.312335323543115
epoch 1 iter 300: train loss 0.58838. lr 3.000000e-04, running loss 0.62424, it/sec: 4.279153816793596
epoch 1 iter 320: train loss 0.65170. lr 3.000000e-04, running loss 0.62247, it/sec: 4.2938353272211085
epoch 1 iter 340: train loss 0.67871. lr 3.000000e-04, running loss 0.62223, it/sec: 4.256773824918462
epoch 1 iter 360: train loss 0.60205. lr 3.000000e-04, running loss 0.62192, it/sec: 4.3119881783378835
epoch 1 iter 380: train loss 0.66369. lr 3.000000e-04, running loss 0.62146, it/sec: 4.281245313956915
epoch 1 iter 400: train loss 0.54843. lr 3.000000e-04, running loss 0.62036, it/sec: 4.265352965290722
epoch 1 iter 420: train loss 0.48854. lr 3.000000e-04, running loss 0.61984, it/sec: 4.2619692167001295
epoch 1 iter 440: train loss 0.62691. lr 3.000000e-04, running loss 0.61926, it/sec: 4.283512994848083
epoch 1 iter 460: train loss 0.55665. lr 3.000000e-04, running loss 0.61852, it/sec: 4.271582463341759
epoch 1 iter 480: train loss 0.65102. lr 3.000000e-04, running loss 0.61856, it/sec: 4.288194381355721
epoch 1 iter 500: train loss 0.61023. lr 3.000000e-04, running loss 0.61894, it/sec: 4.278543519470415
epoch 1 iter 520: train loss 0.61451. lr 3.000000e-04, running loss 0.61879, it/sec: 4.276395445131226
epoch 1 iter 540: train loss 0.59624. lr 3.000000e-04, running loss 0.61832, it/sec: 4.302897642852494
epoch 1 iter 560: train loss 0.61836. lr 3.000000e-04, running loss 0.61804, it/sec: 4.254624974960765
epoch 1 iter 580: train loss 0.59550. lr 3.000000e-04, running loss 0.61753, it/sec: 4.289476138134933
epoch 1 iter 600: train loss 0.59553. lr 3.000000e-04, running loss 0.61717, it/sec: 4.232261769163267
epoch 1 iter 620: train loss 0.56477. lr 3.000000e-04, running loss 0.61744, it/sec: 4.2798449730891415
epoch 1 iter 640: train loss 0.54146. lr 3.000000e-04, running loss 0.61798, it/sec: 4.277602855922509
epoch 1 iter 660: train loss 0.66633. lr 3.000000e-04, running loss 0.61710, it/sec: 4.25462810645663
epoch 1 iter 680: train loss 0.59592. lr 3.000000e-04, running loss 0.61759, it/sec: 4.2709464329983655
epoch 1 iter 700: train loss 0.52145. lr 3.000000e-04, running loss 0.61738, it/sec: 4.272186048667527
epoch 1 iter 720: train loss 0.62020. lr 3.000000e-04, running loss 0.61645, it/sec: 4.271744369956066
epoch 1 iter 740: train loss 0.66208. lr 3.000000e-04, running loss 0.61622, it/sec: 4.239288720642363
epoch 1 iter 760: train loss 0.60183. lr 3.000000e-04, running loss 0.61570, it/sec: 4.264846217181627
epoch 1 iter 780: train loss 0.61233. lr 3.000000e-04, running loss 0.61622, it/sec: 4.27551707311358
epoch 1 iter 800: train loss 0.72036. lr 3.000000e-04, running loss 0.61651, it/sec: 4.26960247682987
epoch 1 iter 820: train loss 0.63541. lr 3.000000e-04, running loss 0.61634, it/sec: 4.30312370346121
epoch 1 iter 840: train loss 0.56232. lr 3.000000e-04, running loss 0.61664, it/sec: 4.310552830397005
epoch 1 iter 860: train loss 0.58418. lr 3.000000e-04, running loss 0.61709, it/sec: 4.277206451772102
epoch 1 iter 880: train loss 0.59636. lr 3.000000e-04, running loss 0.61691, it/sec: 4.272142884546983
epoch 1 iter 900: train loss 0.92434. lr 3.000000e-04, running loss 0.61695, it/sec: 4.2644712666483064
epoch 1 iter 920: train loss 0.60424. lr 3.000000e-04, running loss 0.61715, it/sec: 4.255123629970813
epoch 1 iter 940: train loss 0.63971. lr 3.000000e-04, running loss 0.61743, it/sec: 4.262149961338123
epoch 1 iter 960: train loss 0.58745. lr 3.000000e-04, running loss 0.61727, it/sec: 4.283947824458593
epoch 1 iter 980: train loss 0.64755. lr 3.000000e-04, running loss 0.61703, it/sec: 4.27356870627855
epoch 1 iter 1000: train loss 0.71598. lr 3.000000e-04, running loss 0.61633, it/sec: 4.262835144492285
epoch 1 iter 1020: train loss 0.61291. lr 3.000000e-04, running loss 0.61641, it/sec: 4.271584652292313
epoch 1 iter 1040: train loss 0.52402. lr 3.000000e-04, running loss 0.61602, it/sec: 4.288509198905676
epoch 1 iter 1060: train loss 0.59533. lr 3.000000e-04, running loss 0.61566, it/sec: 4.283269799683714
epoch 1 iter 1080: train loss 0.57568. lr 3.000000e-04, running loss 0.61531, it/sec: 4.259521067417648
epoch 1 iter 1100: train loss 0.60747. lr 3.000000e-04, running loss 0.61482, it/sec: 4.258801525761028
epoch 1 iter 1120: train loss 0.67664. lr 3.000000e-04, running loss 0.61488, it/sec: 4.271402816669594
epoch 1 iter 1140: train loss 0.56967. lr 3.000000e-04, running loss 0.61500, it/sec: 4.2561478840929095
epoch 1 iter 1160: train loss 0.59112. lr 3.000000e-04, running loss 0.61442, it/sec: 4.276528108500544
epoch 1 iter 1180: train loss 0.60304. lr 3.000000e-04, running loss 0.61424, it/sec: 4.291304401632334
epoch 1 iter 1200: train loss 0.60759. lr 3.000000e-04, running loss 0.61375, it/sec: 4.288724461413712
epoch 1 iter 1220: train loss 0.57053. lr 3.000000e-04, running loss 0.61414, it/sec: 4.262320618114196
epoch 1 iter 1240: train loss 0.62288. lr 3.000000e-04, running loss 0.61424, it/sec: 4.237365898868528
epoch 1 iter 1260: train loss 0.66933. lr 3.000000e-04, running loss 0.61428, it/sec: 4.254673307141552
epoch 1 iter 1280: train loss 0.56122. lr 3.000000e-04, running loss 0.61433, it/sec: 4.284729973845697
epoch 1 iter 1300: train loss 0.57014. lr 3.000000e-04, running loss 0.61413, it/sec: 4.2744962132149995
epoch 1 iter 1320: train loss 0.73394. lr 3.000000e-04, running loss 0.61440, it/sec: 4.260363291849885
epoch 1 iter 1340: train loss 0.60863. lr 3.000000e-04, running loss 0.61383, it/sec: 4.269717801012997
epoch 1 iter 1360: train loss 0.57947. lr 3.000000e-04, running loss 0.61348, it/sec: 4.265424520037359
epoch 1 iter 1380: train loss 0.55211. lr 3.000000e-04, running loss 0.61339, it/sec: 4.25256990758964
epoch 1 iter 1400: train loss 0.59798. lr 3.000000e-04, running loss 0.61285, it/sec: 4.299885763329242
epoch 1 iter 1420: train loss 0.58414. lr 3.000000e-04, running loss 0.61304, it/sec: 4.270954750881406
epoch 1 iter 1440: train loss 0.55606. lr 3.000000e-04, running loss 0.61290, it/sec: 4.26428730847858
epoch 1 iter 1460: train loss 0.64331. lr 3.000000e-04, running loss 0.61252, it/sec: 4.24637240364325
epoch 1 iter 1480: train loss 0.66302. lr 3.000000e-04, running loss 0.61225, it/sec: 4.269051343176608
epoch 1 iter 1500: train loss 0.60238. lr 3.000000e-04, running loss 0.61222, it/sec: 4.236599347978795
epoch 1 iter 1520: train loss 1.71042. lr 3.000000e-04, running loss 0.61331, it/sec: 4.312062180841828
epoch 1 iter 1540: train loss 0.62317. lr 3.000000e-04, running loss 0.61284, it/sec: 4.488807689426465
epoch 1 iter 1560: train loss 0.62615. lr 3.000000e-04, running loss 0.61320, it/sec: 4.439076811994689
epoch 1 iter 1580: train loss 0.62991. lr 3.000000e-04, running loss 0.61358, it/sec: 4.491171975218554
epoch 1 iter 1600: train loss 0.61430. lr 3.000000e-04, running loss 0.61326, it/sec: 4.432793840979181
epoch 1 iter 1620: train loss 0.60251. lr 3.000000e-04, running loss 0.61324, it/sec: 4.48563769063325
epoch 1 iter 1640: train loss 0.60557. lr 3.000000e-04, running loss 0.61290, it/sec: 4.4155557788018385
epoch 1 iter 1660: train loss 0.63460. lr 3.000000e-04, running loss 0.61322, it/sec: 4.484403388975062
epoch 1 iter 1680: train loss 0.64408. lr 3.000000e-04, running loss 0.61318, it/sec: 4.48124410233104
epoch 1 iter 1700: train loss 0.57280. lr 3.000000e-04, running loss 0.61313, it/sec: 4.465045130245408
epoch 1 iter 1720: train loss 0.61732. lr 3.000000e-04, running loss 0.61314, it/sec: 4.509200918549279
epoch 1 iter 1740: train loss 0.57839. lr 3.000000e-04, running loss 0.61302, it/sec: 4.417965769192449
epoch 1 iter 1760: train loss 0.70222. lr 3.000000e-04, running loss 0.61320, it/sec: 4.4689680751660745
epoch 1 iter 1780: train loss 0.54446. lr 3.000000e-04, running loss 0.61309, it/sec: 4.446215659095542
epoch 1 iter 1800: train loss 0.70263. lr 3.000000e-04, running loss 0.61311, it/sec: 4.446870973217504
epoch 1 iter 1820: train loss 0.53762. lr 3.000000e-04, running loss 0.61291, it/sec: 4.488958371583889
epoch 1 iter 1840: train loss 0.66765. lr 3.000000e-04, running loss 0.61310, it/sec: 4.431807254655486
epoch 1 iter 1860: train loss 0.58508. lr 3.000000e-04, running loss 0.61286, it/sec: 4.494163677782871
epoch 1 iter 1880: train loss 0.58166. lr 3.000000e-04, running loss 0.61272, it/sec: 4.435064597938318
epoch 1 iter 1900: train loss 0.71152. lr 3.000000e-04, running loss 0.61276, it/sec: 4.516726359441499
epoch 1 iter 1920: train loss 0.57821. lr 3.000000e-04, running loss 0.61299, it/sec: 4.448715389209783
epoch 1 iter 1940: train loss 0.79488. lr 3.000000e-04, running loss 0.61304, it/sec: 4.486531016905769
epoch 1 iter 1960: train loss 0.56170. lr 3.000000e-04, running loss 0.61309, it/sec: 4.484057403812582
epoch 1 iter 1980: train loss 0.62132. lr 3.000000e-04, running loss 0.61276, it/sec: 4.460276145727678
epoch 1 iter 2000: train loss 0.50849. lr 3.000000e-04, running loss 0.61269, it/sec: 4.508730911981266
epoch 1 iter 2020: train loss 0.54861. lr 3.000000e-04, running loss 0.61290, it/sec: 4.415286267469233
epoch 1 iter 2040: train loss 0.58964. lr 3.000000e-04, running loss 0.61267, it/sec: 4.473711045404139
epoch 1 iter 2060: train loss 0.60688. lr 3.000000e-04, running loss 0.61271, it/sec: 4.486096292435321
epoch 1 iter 2080: train loss 0.52652. lr 3.000000e-04, running loss 0.61234, it/sec: 4.426769573609625
epoch 1 iter 2100: train loss 0.70062. lr 3.000000e-04, running loss 0.61217, it/sec: 4.489659908486858
epoch 1 iter 2120: train loss 0.55171. lr 3.000000e-04, running loss 0.61309, it/sec: 4.428732619794028
epoch 1 iter 2140: train loss 0.71813. lr 3.000000e-04, running loss 0.61307, it/sec: 4.487519365517479
epoch 1 iter 2160: train loss 0.64096. lr 3.000000e-04, running loss 0.61334, it/sec: 4.47513812340923
epoch 1 iter 2180: train loss 0.59277. lr 3.000000e-04, running loss 0.61311, it/sec: 4.433533183752561
epoch 1 iter 2200: train loss 0.56882. lr 3.000000e-04, running loss 0.61348, it/sec: 4.48607222430891
epoch 1 iter 2220: train loss 0.58301. lr 3.000000e-04, running loss 0.61322, it/sec: 4.483735076010354
epoch 1 iter 2240: train loss 0.68144. lr 3.000000e-04, running loss 0.61292, it/sec: 4.495364860199334
epoch 1 iter 2260: train loss 0.60173. lr 3.000000e-04, running loss 0.61258, it/sec: 4.462484902770028
epoch 1 iter 2280: train loss 0.57470. lr 3.000000e-04, running loss 0.61232, it/sec: 4.520141119322507
epoch 1 iter 2300: train loss 0.74744. lr 3.000000e-04, running loss 0.61224, it/sec: 4.4445706898401625
epoch 1 iter 2320: train loss 0.66745. lr 3.000000e-04, running loss 0.61219, it/sec: 4.488102652795093
epoch 1 iter 2340: train loss 0.68003. lr 3.000000e-04, running loss 0.61256, it/sec: 4.5251419038281
epoch 1 iter 2360: train loss 0.71712. lr 3.000000e-04, running loss 0.61348, it/sec: 4.480784582403394
epoch 1 iter 2380: train loss 0.64925. lr 3.000000e-04, running loss 0.61375, it/sec: 4.494193608846604
epoch 1 iter 2400: train loss 0.51522. lr 3.000000e-04, running loss 0.61351, it/sec: 4.46333440718738
epoch 1 iter 2420: train loss 0.61767. lr 3.000000e-04, running loss 0.61354, it/sec: 4.490810365040619
epoch 1 iter 2440: train loss 0.56343. lr 3.000000e-04, running loss 0.61351, it/sec: 4.506833116309434
epoch 1 iter 2460: train loss 0.53034. lr 3.000000e-04, running loss 0.61786, it/sec: 4.472491417852321
epoch 1 iter 2480: train loss 0.56902. lr 3.000000e-04, running loss 0.61755, it/sec: 4.490396447593452
epoch 1 iter 2500: train loss 0.67000. lr 3.000000e-04, running loss 0.61761, it/sec: 4.472877293056848
epoch 1 iter 2520: train loss 0.63540. lr 3.000000e-04, running loss 0.61759, it/sec: 4.506014689286971
epoch 1 iter 2540: train loss 0.56040. lr 3.000000e-04, running loss 0.61741, it/sec: 4.458053932503852
epoch 1 iter 2560: train loss 0.56096. lr 3.000000e-04, running loss 0.61704, it/sec: 4.5091314830889155
epoch 1 iter 2580: train loss 0.61308. lr 3.000000e-04, running loss 0.61670, it/sec: 4.462701356053254
epoch 1 iter 2600: train loss 0.61200. lr 3.000000e-04, running loss 0.61694, it/sec: 4.4901667949085144
epoch 1 iter 2620: train loss 0.57761. lr 3.000000e-04, running loss 0.61682, it/sec: 4.505542870011514
epoch 1 iter 2640: train loss 0.60036. lr 3.000000e-04, running loss 0.61666, it/sec: 4.439163831266127
epoch 1 iter 2660: train loss 0.63305. lr 3.000000e-04, running loss 0.61668, it/sec: 4.484093576671156
epoch 1 iter 2680: train loss 0.63178. lr 3.000000e-04, running loss 0.61679, it/sec: 4.456631827222508
epoch 1 iter 2700: train loss 0.71046. lr 3.000000e-04, running loss 0.61660, it/sec: 4.48796727521967
epoch 1 iter 2720: train loss 0.54920. lr 3.000000e-04, running loss 0.61674, it/sec: 4.500077685736469
epoch 1 iter 2740: train loss 0.56403. lr 3.000000e-04, running loss 0.61673, it/sec: 4.4368881676709275
epoch 1 iter 2760: train loss 0.66217. lr 3.000000e-04, running loss 0.61636, it/sec: 4.4953358216075285
epoch 1 iter 2780: train loss 0.58141. lr 3.000000e-04, running loss 0.61624, it/sec: 4.446354579098391
epoch 1 iter 2800: train loss 0.56903. lr 3.000000e-04, running loss 0.61637, it/sec: 4.503087188058265
epoch 1 iter 2820: train loss 0.59704. lr 3.000000e-04, running loss 0.61670, it/sec: 4.461259765593458
epoch 1 iter 2840: train loss 0.63609. lr 3.000000e-04, running loss 0.61634, it/sec: 4.490350615876808
epoch 1 iter 2860: train loss 0.62666. lr 3.000000e-04, running loss 0.61634, it/sec: 4.479910662787513
epoch 1 iter 2880: train loss 0.54794. lr 3.000000e-04, running loss 0.61603, it/sec: 4.510639806942159
epoch 1 iter 2900: train loss 0.59988. lr 3.000000e-04, running loss 0.61577, it/sec: 4.464666326433459
epoch 1 iter 2920: train loss 0.65977. lr 3.000000e-04, running loss 0.61543, it/sec: 4.48741072384453
epoch 1 iter 2940: train loss 0.55510. lr 3.000000e-04, running loss 0.61550, it/sec: 4.494291550955153
epoch 1 iter 2960: train loss 0.49071. lr 3.000000e-04, running loss 0.61548, it/sec: 4.445963243750012
epoch 1 iter 2980: train loss 0.59913. lr 3.000000e-04, running loss 0.61579, it/sec: 4.522301123640604
epoch 1 iter 3000: train loss 0.62685. lr 3.000000e-04, running loss 0.61582, it/sec: 4.447467259141884
epoch 1 iter 3020: train loss 0.53591. lr 3.000000e-04, running loss 0.61567, it/sec: 4.51269089268461
epoch 1 iter 3040: train loss 0.47107. lr 3.000000e-04, running loss 0.61540, it/sec: 4.445130476756979
epoch 1 iter 3060: train loss 0.70050. lr 3.000000e-04, running loss 0.61497, it/sec: 4.489581357794152
epoch 1 iter 3080: train loss 0.58143. lr 3.000000e-04, running loss 0.61457, it/sec: 4.457358064773145
epoch 1 iter 3100: train loss 0.71821. lr 3.000000e-04, running loss 0.61465, it/sec: 4.506043277435093
epoch 1 iter 3120: train loss 0.55425. lr 3.000000e-04, running loss 0.61471, it/sec: 4.470411055602446
epoch 1 iter 3140: train loss 0.62559. lr 3.000000e-04, running loss 0.61441, it/sec: 4.4777077641454675
epoch 1 iter 3160: train loss 0.74935. lr 3.000000e-04, running loss 0.61485, it/sec: 4.460359741210055
epoch 1 iter 3180: train loss 0.55600. lr 3.000000e-04, running loss 0.61462, it/sec: 4.510037263721086
epoch 1 iter 3200: train loss 0.59979. lr 3.000000e-04, running loss 0.61459, it/sec: 4.436671888644279
epoch 1 iter 3220: train loss 0.66042. lr 3.000000e-04, running loss 0.61459, it/sec: 4.515195307073579
epoch 1 iter 3240: train loss 0.61925. lr 3.000000e-04, running loss 0.61468, it/sec: 4.48317939357653
epoch 1 iter 3260: train loss 0.60317. lr 3.000000e-04, running loss 0.61444, it/sec: 4.465883125439944
epoch 1 iter 3280: train loss 0.61807. lr 3.000000e-04, running loss 0.61436, it/sec: 4.52165360930942
epoch 1 iter 3300: train loss 0.61398. lr 3.000000e-04, running loss 0.61442, it/sec: 4.489071702735246
epoch 1 iter 3320: train loss 0.47670. lr 3.000000e-04, running loss 0.61434, it/sec: 4.518951409185703
epoch 1 iter 3340: train loss 0.64164. lr 3.000000e-04, running loss 0.61450, it/sec: 4.434304451561569
epoch 1 iter 3360: train loss 0.56829. lr 3.000000e-04, running loss 0.61420, it/sec: 4.5290542837261505
epoch 1 iter 3380: train loss 0.56132. lr 3.000000e-04, running loss 0.61391, it/sec: 4.4179291920583585
epoch 1 iter 3400: train loss 0.67165. lr 3.000000e-04, running loss 0.61501, it/sec: 4.503193365334199
epoch 1 iter 3420: train loss 0.53744. lr 3.000000e-04, running loss 0.61484, it/sec: 4.445146599421032
epoch 1 iter 3440: train loss 0.59953. lr 3.000000e-04, running loss 0.61432, it/sec: 4.460125650723528
epoch 1 iter 3460: train loss 0.58877. lr 3.000000e-04, running loss 0.61410, it/sec: 4.501857595493247
epoch 1 iter 3480: train loss 0.58022. lr 3.000000e-04, running loss 0.61424, it/sec: 4.445209415438604
epoch 1 iter 3500: train loss 0.59068. lr 3.000000e-04, running loss 0.61431, it/sec: 4.50354019909098
epoch 1 iter 3520: train loss 0.58159. lr 3.000000e-04, running loss 0.61514, it/sec: 4.471407369679724
epoch 1 iter 3540: train loss 0.52562. lr 3.000000e-04, running loss 0.61483, it/sec: 4.501185347585766
epoch 1 iter 3560: train loss 0.70073. lr 3.000000e-04, running loss 0.61470, it/sec: 4.460434049778094
epoch 1 iter 3580: train loss 0.48178. lr 3.000000e-04, running loss 0.61418, it/sec: 4.470430940378112
epoch 1 iter 3600: train loss 0.59884. lr 3.000000e-04, running loss 0.61478, it/sec: 4.500498655249538
epoch 1 iter 3620: train loss 0.60084. lr 3.000000e-04, running loss 0.61468, it/sec: 4.416680367135243
epoch 1 iter 3640: train loss 0.57471. lr 3.000000e-04, running loss 0.61450, it/sec: 4.48718459944917
epoch 1 iter 3660: train loss 0.62608. lr 3.000000e-04, running loss 0.61416, it/sec: 4.4470069090623205
epoch 1 iter 3680: train loss 0.55992. lr 3.000000e-04, running loss 0.61399, it/sec: 4.507762561103279
epoch 1 iter 3700: train loss 0.67105. lr 3.000000e-04, running loss 0.61468, it/sec: 4.4478361071406045
epoch 1 iter 3720: train loss 0.60669. lr 3.000000e-04, running loss 0.61427, it/sec: 4.522251734971206
epoch 1 iter 3740: train loss 0.57070. lr 3.000000e-04, running loss 0.61426, it/sec: 4.418431624782983
epoch 1 iter 3760: train loss 0.62349. lr 3.000000e-04, running loss 0.61375, it/sec: 4.52076379795371
epoch 1 iter 3780: train loss 0.58192. lr 3.000000e-04, running loss 0.61334, it/sec: 4.425671003984964
epoch 1 iter 3800: train loss 0.70953. lr 3.000000e-04, running loss 0.61300, it/sec: 4.49834618758156
epoch 1 iter 3820: train loss 0.71864. lr 3.000000e-04, running loss 0.61313, it/sec: 4.491433602413309
epoch 1 iter 3840: train loss 0.70286. lr 3.000000e-04, running loss 0.61288, it/sec: 4.4592258268814495
epoch 1 iter 3860: train loss 0.47748. lr 3.000000e-04, running loss 0.61263, it/sec: 4.515926993006341
epoch 1 iter 3880: train loss 0.59063. lr 3.000000e-04, running loss 0.61272, it/sec: 4.443577236641759
epoch 1 iter 3900: train loss 0.61373. lr 3.000000e-04, running loss 0.61296, it/sec: 4.504312462899868
epoch 1 iter 3920: train loss 0.59784. lr 3.000000e-04, running loss 0.61294, it/sec: 4.456312416341143
epoch 1 iter 3940: train loss 0.63744. lr 3.000000e-04, running loss 0.61321, it/sec: 4.487716300897027
epoch 1 iter 3960: train loss 0.57673. lr 3.000000e-04, running loss 0.61323, it/sec: 4.442966614797076
epoch 1 iter 3980: train loss 0.52036. lr 3.000000e-04, running loss 0.61311, it/sec: 4.508763458426787
epoch 1 iter 4000: train loss 0.58019. lr 3.000000e-04, running loss 0.61315, it/sec: 4.465202435587385
epoch 1 iter 4020: train loss 0.65373. lr 3.000000e-04, running loss 0.61360, it/sec: 4.515294287758967
epoch 1 iter 4040: train loss 0.62531. lr 3.000000e-04, running loss 0.61363, it/sec: 4.458243182270591
epoch 1 iter 4060: train loss 0.60862. lr 3.000000e-04, running loss 0.61316, it/sec: 4.509370400517081
epoch 1 iter 4080: train loss 0.56627. lr 3.000000e-04, running loss 0.61310, it/sec: 4.438183981365593
epoch 1 iter 4100: train loss 0.59847. lr 3.000000e-04, running loss 0.61294, it/sec: 4.494938586829547
epoch 1 iter 4120: train loss 0.68446. lr 3.000000e-04, running loss 0.61305, it/sec: 4.475946073654745
epoch 1 iter 4140: train loss 0.52965. lr 3.000000e-04, running loss 0.61288, it/sec: 4.464999914365172
epoch 1 iter 4160: train loss 0.52971. lr 3.000000e-04, running loss 0.61308, it/sec: 4.504062680135614
epoch 1 iter 4180: train loss 0.59000. lr 3.000000e-04, running loss 0.61319, it/sec: 4.463173467401171
epoch 1 iter 4200: train loss 0.59616. lr 3.000000e-04, running loss 0.61280, it/sec: 4.5126337897361495
epoch 1 iter 4220: train loss 0.62892. lr 3.000000e-04, running loss 0.61284, it/sec: 4.448337094597994
epoch 1 iter 4240: train loss 0.58192. lr 3.000000e-04, running loss 0.61285, it/sec: 4.528275380121261
epoch 1 iter 4260: train loss 0.56608. lr 3.000000e-04, running loss 0.61285, it/sec: 4.45562058542397
epoch 1 iter 4280: train loss 0.55231. lr 3.000000e-04, running loss 0.61265, it/sec: 4.498258833677201
epoch 1 iter 4300: train loss 0.63098. lr 3.000000e-04, running loss 0.61258, it/sec: 4.430411558726644
epoch 1 iter 4320: train loss 0.62916. lr 3.000000e-04, running loss 0.61255, it/sec: 4.499626747488107
epoch 1 iter 4340: train loss 0.57817. lr 3.000000e-04, running loss 0.61258, it/sec: 4.435716709068496
epoch 1 iter 4360: train loss 0.63214. lr 3.000000e-04, running loss 0.61223, it/sec: 4.5216922502198535
epoch 1 iter 4380: train loss 0.56660. lr 3.000000e-04, running loss 0.61269, it/sec: 4.445283752607495
epoch 1 iter 4400: train loss 0.58675. lr 3.000000e-04, running loss 0.61273, it/sec: 4.503925993254646
epoch 1 iter 4420: train loss 0.68635. lr 3.000000e-04, running loss 0.61283, it/sec: 4.438736327762523
epoch 1 iter 4440: train loss 0.56576. lr 3.000000e-04, running loss 0.61285, it/sec: 4.4986709035168095
epoch 1 iter 4460: train loss 0.61514. lr 3.000000e-04, running loss 0.61260, it/sec: 4.495024458133672
epoch 1 iter 4480: train loss 0.58391. lr 3.000000e-04, running loss 0.61256, it/sec: 4.466519132707226
epoch 1 iter 4500: train loss 0.62082. lr 3.000000e-04, running loss 0.61229, it/sec: 4.514430292250268
epoch 1 iter 4520: train loss 0.61882. lr 3.000000e-04, running loss 0.61214, it/sec: 4.471922440864655
epoch 1 iter 4540: train loss 0.60137. lr 3.000000e-04, running loss 0.61241, it/sec: 4.502134211699942
epoch 1 iter 4560: train loss 0.54504. lr 3.000000e-04, running loss 0.61269, it/sec: 4.424351067478521
epoch 1 iter 4580: train loss 0.56937. lr 3.000000e-04, running loss 0.61282, it/sec: 4.509791076683238
epoch 1 iter 4600: train loss 0.53670. lr 3.000000e-04, running loss 0.61275, it/sec: 4.451052814606127
epoch 1 iter 4620: train loss 0.61582. lr 3.000000e-04, running loss 0.61343, it/sec: 4.50440102523507
epoch 1 iter 4640: train loss 0.50627. lr 3.000000e-04, running loss 0.61311, it/sec: 4.431876372161325
epoch 1 iter 4660: train loss 0.63656. lr 3.000000e-04, running loss 0.61339, it/sec: 4.4886237332351575
epoch 1 iter 4680: train loss 0.61084. lr 3.000000e-04, running loss 0.61328, it/sec: 4.4926324598469645
epoch 1 iter 4700: train loss 0.53933. lr 3.000000e-04, running loss 0.61354, it/sec: 4.457910206383576
epoch 1 iter 4720: train loss 0.56070. lr 3.000000e-04, running loss 0.61337, it/sec: 4.494781664218738
epoch 1 iter 4740: train loss 0.62296. lr 3.000000e-04, running loss 0.61321, it/sec: 4.434334437580753
epoch 1 iter 4760: train loss 0.74250. lr 3.000000e-04, running loss 0.61338, it/sec: 4.5149276212328555
epoch 1 iter 4780: train loss 0.63186. lr 3.000000e-04, running loss 0.61313, it/sec: 4.478979726075517
epoch 1 iter 4800: train loss 0.54684. lr 3.000000e-04, running loss 0.61297, it/sec: 4.407666794948107
epoch 1 iter 4820: train loss 0.63009. lr 3.000000e-04, running loss 0.61248, it/sec: 4.504253747247463
epoch 1 iter 4840: train loss 0.56479. lr 3.000000e-04, running loss 0.61198, it/sec: 4.43673460286535
epoch 1 iter 4860: train loss 0.58389. lr 3.000000e-04, running loss 0.61181, it/sec: 4.4792514731048385
epoch 1 iter 4880: train loss 0.52901. lr 3.000000e-04, running loss 0.61314, it/sec: 4.493729008086752
epoch 1 iter 4900: train loss 0.55323. lr 3.000000e-04, running loss 0.61300, it/sec: 4.474351848080345
epoch 1 iter 4920: train loss 0.65375. lr 3.000000e-04, running loss 0.61287, it/sec: 4.452389505654406
epoch 1 iter 4940: train loss 0.64124. lr 3.000000e-04, running loss 0.61245, it/sec: 4.473562584956624
epoch 1 iter 4960: train loss 0.49817. lr 3.000000e-04, running loss 0.61235, it/sec: 4.518689198987521
epoch 1 iter 4980: train loss 0.63637. lr 3.000000e-04, running loss 0.61210, it/sec: 4.443583238463165
epoch 1 iter 5000: train loss 0.67767. lr 3.000000e-04, running loss 0.61212, it/sec: 4.508247182006797
epoch 1 iter 5020: train loss 0.57074. lr 3.000000e-04, running loss 0.61191, it/sec: 4.443400856763524
epoch 1 iter 5040: train loss 0.62170. lr 3.000000e-04, running loss 0.61155, it/sec: 4.478528334915254
epoch 1 iter 5060: train loss 0.55431. lr 3.000000e-04, running loss 0.61195, it/sec: 4.472361461681787
epoch 1 iter 5080: train loss 0.60322. lr 3.000000e-04, running loss 0.61213, it/sec: 4.478651729659905
epoch 1 iter 5100: train loss 0.61502. lr 3.000000e-04, running loss 0.61201, it/sec: 4.507543664881072
epoch 1 iter 5120: train loss 0.72182. lr 3.000000e-04, running loss 0.61188, it/sec: 4.415835365727825
epoch 1 iter 5140: train loss 0.58841. lr 3.000000e-04, running loss 0.61164, it/sec: 4.477423955319664
epoch 1 iter 5160: train loss 0.60055. lr 3.000000e-04, running loss 0.61169, it/sec: 4.485606784229572
epoch 1 iter 5180: train loss 0.55779. lr 3.000000e-04, running loss 0.61153, it/sec: 4.451250762576248
epoch 1 iter 5200: train loss 0.53865. lr 3.000000e-04, running loss 0.61132, it/sec: 4.441021285835445
epoch 1 iter 5220: train loss 0.65032. lr 3.000000e-04, running loss 0.61139, it/sec: 4.477616016762746
epoch 1 iter 5240: train loss 0.57391. lr 3.000000e-04, running loss 0.61105, it/sec: 4.495879787897075
epoch 1 iter 5260: train loss 0.61942. lr 3.000000e-04, running loss 0.61098, it/sec: 4.442786377047224
epoch 1 iter 5280: train loss 0.57809. lr 3.000000e-04, running loss 0.61080, it/sec: 4.463203268858338
epoch 1 iter 5300: train loss 0.61381. lr 3.000000e-04, running loss 0.61073, it/sec: 4.458852841281033
epoch 1 iter 5320: train loss 0.54719. lr 3.000000e-04, running loss 0.61099, it/sec: 4.476937860259708
epoch 1 iter 5340: train loss 0.73404. lr 3.000000e-04, running loss 0.61125, it/sec: 4.4980574907033075
epoch 1 iter 5360: train loss 0.70302. lr 3.000000e-04, running loss 0.61107, it/sec: 4.434808335538609
epoch 1 iter 5380: train loss 0.62350. lr 3.000000e-04, running loss 0.61122, it/sec: 4.489051651783498
epoch 1 iter 5400: train loss 0.74155. lr 3.000000e-04, running loss 0.61111, it/sec: 4.474375971233791
epoch 1 iter 5420: train loss 0.56772. lr 3.000000e-04, running loss 0.61079, it/sec: 4.464821971314008
epoch 1 iter 5440: train loss 0.48569. lr 3.000000e-04, running loss 0.61076, it/sec: 4.480721440579062
epoch 1 iter 5460: train loss 0.56407. lr 3.000000e-04, running loss 0.61042, it/sec: 4.4782435197131285
epoch 1 iter 5480: train loss 0.58704. lr 3.000000e-04, running loss 0.61004, it/sec: 4.496253151595177
epoch 1 iter 5500: train loss 0.62180. lr 3.000000e-04, running loss 0.61008, it/sec: 4.452775786038911
epoch 1 iter 5520: train loss 0.50662. lr 3.000000e-04, running loss 0.61015, it/sec: 4.515706956569586
epoch 1 iter 5540: train loss 0.56236. lr 3.000000e-04, running loss 0.61061, it/sec: 4.4396845304745725
epoch 1 iter 5560: train loss 0.56612. lr 3.000000e-04, running loss 0.61058, it/sec: 4.48042442324916
epoch 1 iter 5580: train loss 0.59440. lr 3.000000e-04, running loss 0.61039, it/sec: 4.476271710979086
epoch 1 iter 5600: train loss 0.54222. lr 3.000000e-04, running loss 0.61020, it/sec: 4.442946738050392
epoch 1 iter 5620: train loss 0.60100. lr 3.000000e-04, running loss 0.61055, it/sec: 4.488003752708179
epoch 1 iter 5640: train loss 0.55918. lr 3.000000e-04, running loss 0.61062, it/sec: 4.452408378847841
epoch 1 iter 5660: train loss 0.55734. lr 3.000000e-04, running loss 0.61077, it/sec: 4.4794519184997625
epoch 1 iter 5680: train loss 0.62240. lr 3.000000e-04, running loss 0.61068, it/sec: 4.4789871492774
epoch 1 iter 5700: train loss 0.56788. lr 3.000000e-04, running loss 0.61067, it/sec: 4.436701709616791
epoch 1 iter 5720: train loss 0.51285. lr 3.000000e-04, running loss 0.61072, it/sec: 4.4896431585970085
epoch 1 iter 5740: train loss 0.50222. lr 3.000000e-04, running loss 0.61051, it/sec: 4.43943955915645
epoch 1 iter 5760: train loss 0.64120. lr 3.000000e-04, running loss 0.61107, it/sec: 4.46863678942422
epoch 1 iter 5780: train loss 0.59650. lr 3.000000e-04, running loss 0.61095, it/sec: 4.428906639364046
epoch 1 iter 5800: train loss 0.55636. lr 3.000000e-04, running loss 0.61109, it/sec: 4.504623410110657
epoch 1 iter 5820: train loss 0.58292. lr 3.000000e-04, running loss 0.61071, it/sec: 4.453576949863835
epoch 1 iter 5840: train loss 0.64081. lr 3.000000e-04, running loss 0.61044, it/sec: 4.489790934107847
epoch 1 iter 5860: train loss 0.70371. lr 3.000000e-04, running loss 0.61038, it/sec: 4.505093718409502
epoch 1 iter 5880: train loss 0.60598. lr 3.000000e-04, running loss 0.61025, it/sec: 4.453762248504271
epoch 1 iter 5900: train loss 0.63463. lr 3.000000e-04, running loss 0.61022, it/sec: 4.508094471080195
epoch 1 iter 5920: train loss 0.54660. lr 3.000000e-04, running loss 0.61025, it/sec: 4.4586020311513455
epoch 1 iter 5940: train loss 0.64520. lr 3.000000e-04, running loss 0.61020, it/sec: 4.484335699505862
epoch 1 iter 5960: train loss 0.67370. lr 3.000000e-04, running loss 0.61132, it/sec: 4.4896407193372605
epoch 1 iter 5980: train loss 0.69171. lr 3.000000e-04, running loss 0.61134, it/sec: 4.457009785694517
epoch 1 iter 6000: train loss 0.58810. lr 3.000000e-04, running loss 0.61100, it/sec: 4.5236911089673395
epoch 1 iter 6020: train loss 0.56109. lr 3.000000e-04, running loss 0.61032, it/sec: 4.441377328503056
epoch 1 iter 6040: train loss 0.67990. lr 3.000000e-04, running loss 0.61014, it/sec: 4.493344049142514
epoch 1 iter 6060: train loss 0.54699. lr 3.000000e-04, running loss 0.60983, it/sec: 4.464046408450956
epoch 1 iter 6080: train loss 0.60364. lr 3.000000e-04, running loss 0.60945, it/sec: 4.49210941937816
epoch 1 iter 6100: train loss 0.55313. lr 3.000000e-04, running loss 0.60922, it/sec: 4.452278634066454
epoch 1 iter 6120: train loss 0.63249. lr 3.000000e-04, running loss 0.60904, it/sec: 4.499200857931542
epoch 1 iter 6140: train loss 0.68886. lr 3.000000e-04, running loss 0.60912, it/sec: 4.485446065850479
epoch 1 iter 6160: train loss 0.62821. lr 3.000000e-04, running loss 0.60897, it/sec: 4.454520550314238
epoch 1 iter 6180: train loss 0.54085. lr 3.000000e-04, running loss 0.60887, it/sec: 4.501448711247994
epoch 1 iter 6200: train loss 0.61614. lr 3.000000e-04, running loss 0.60905, it/sec: 4.429057191824687
epoch 1 iter 6220: train loss 0.57656. lr 3.000000e-04, running loss 0.60872, it/sec: 4.5141173788567555
epoch 1 iter 6240: train loss 0.70620. lr 3.000000e-04, running loss 0.60892, it/sec: 4.449904992471047
epoch 1 iter 6260: train loss 0.56351. lr 3.000000e-04, running loss 0.60903, it/sec: 4.464911160961481
epoch 1 iter 6280: train loss 0.64858. lr 3.000000e-04, running loss 0.60952, it/sec: 4.444410904897185
epoch 1 iter 6300: train loss 0.55590. lr 3.000000e-04, running loss 0.60942, it/sec: 4.487808300884018
epoch 1 iter 6320: train loss 0.52183. lr 3.000000e-04, running loss 0.60915, it/sec: 4.425023194754758
epoch 1 iter 6340: train loss 0.59569. lr 3.000000e-04, running loss 0.60942, it/sec: 4.479647887107374
epoch 1 iter 6360: train loss 0.64073. lr 3.000000e-04, running loss 0.60946, it/sec: 4.45380013610248
epoch 1 iter 6380: train loss 0.61375. lr 3.000000e-04, running loss 0.60977, it/sec: 4.4773124343744755
epoch 1 iter 6400: train loss 0.57859. lr 3.000000e-04, running loss 0.60960, it/sec: 4.511061454391093
epoch 1 iter 6420: train loss 0.51396. lr 3.000000e-04, running loss 0.60953, it/sec: 4.4486280330821515
epoch 1 iter 6440: train loss 0.71825. lr 3.000000e-04, running loss 0.60969, it/sec: 4.506527773415817
epoch 1 iter 6460: train loss 0.62770. lr 3.000000e-04, running loss 0.60955, it/sec: 4.455840920910543
epoch 1 iter 6480: train loss 0.50512. lr 3.000000e-04, running loss 0.60893, it/sec: 4.514100017796462
epoch 1 iter 6500: train loss 0.60431. lr 3.000000e-04, running loss 0.60884, it/sec: 4.462187867779983
epoch 1 iter 6520: train loss 0.58843. lr 3.000000e-04, running loss 0.60871, it/sec: 4.4815408869871645
epoch 1 iter 6540: train loss 0.76745. lr 3.000000e-04, running loss 0.60899, it/sec: 4.4783854301390855
epoch 1 iter 6560: train loss 0.59590. lr 3.000000e-04, running loss 0.60952, it/sec: 4.452275601782387
epoch 1 iter 6580: train loss 0.66416. lr 3.000000e-04, running loss 0.60928, it/sec: 4.494048796235968
epoch 1 iter 6600: train loss 0.73673. lr 3.000000e-04, running loss 0.60969, it/sec: 4.452518067162636
epoch 1 iter 6620: train loss 0.66845. lr 3.000000e-04, running loss 0.61009, it/sec: 4.5263778164368045
epoch 1 iter 6640: train loss 0.58802. lr 3.000000e-04, running loss 0.61060, it/sec: 4.441757911832937
epoch 1 iter 6660: train loss 0.59454. lr 3.000000e-04, running loss 0.60993, it/sec: 4.515497462866296
epoch 1 iter 6680: train loss 0.62337. lr 3.000000e-04, running loss 0.60963, it/sec: 4.444467279671474
epoch 1 iter 6700: train loss 0.50165. lr 3.000000e-04, running loss 0.60955, it/sec: 4.50027349690513
epoch 1 iter 6720: train loss 0.63397. lr 3.000000e-04, running loss 0.60946, it/sec: 4.4582669538694075
epoch 1 iter 6740: train loss 0.54565. lr 3.000000e-04, running loss 0.60937, it/sec: 4.488274881579826
epoch 1 iter 6760: train loss 0.59162. lr 3.000000e-04, running loss 0.60888, it/sec: 4.490199356725169
epoch 1 iter 6780: train loss 0.61627. lr 3.000000e-04, running loss 0.60886, it/sec: 4.486953926330951
epoch 1 iter 6800: train loss 0.59388. lr 3.000000e-04, running loss 0.60855, it/sec: 4.47110706634949
epoch 1 iter 6820: train loss 0.68249. lr 3.000000e-04, running loss 0.60861, it/sec: 4.430985356509171
epoch 1 iter 6840: train loss 0.52486. lr 3.000000e-04, running loss 0.60836, it/sec: 4.482616755126985
epoch 1 iter 6860: train loss 0.60204. lr 3.000000e-04, running loss 0.60857, it/sec: 4.465076272687489
epoch 1 iter 6880: train loss 0.63442. lr 3.000000e-04, running loss 0.60904, it/sec: 4.491055997406695
epoch 1 iter 6900: train loss 0.60308. lr 3.000000e-04, running loss 0.60892, it/sec: 4.492496162739048
epoch 1 iter 6920: train loss 0.65934. lr 3.000000e-04, running loss 0.60873, it/sec: 4.4375739959959075
epoch 1 iter 6940: train loss 0.61514. lr 3.000000e-04, running loss 0.60849, it/sec: 4.503816698604195
epoch 1 iter 6960: train loss 0.60754. lr 3.000000e-04, running loss 0.60833, it/sec: 4.4465991276089145
epoch 1 iter 6980: train loss 0.55953. lr 3.000000e-04, running loss 0.60845, it/sec: 4.526206706645464
epoch 1 iter 7000: train loss 0.56090. lr 3.000000e-04, running loss 0.60867, it/sec: 4.453782660895952
epoch 1 iter 7020: train loss 0.59860. lr 3.000000e-04, running loss 0.60887, it/sec: 4.521294044516375
epoch 1 iter 7040: train loss 0.69560. lr 3.000000e-04, running loss 0.60882, it/sec: 4.444847009328991
epoch 1 iter 7060: train loss 0.53091. lr 3.000000e-04, running loss 0.60929, it/sec: 4.519609425028074
epoch 1 iter 7080: train loss 0.55270. lr 3.000000e-04, running loss 0.60921, it/sec: 4.446461083062811
epoch 1 iter 7100: train loss 0.57746. lr 3.000000e-04, running loss 0.60922, it/sec: 4.504873071978342
epoch 1 iter 7120: train loss 0.53847. lr 3.000000e-04, running loss 0.60876, it/sec: 4.468592818830617
epoch 1 iter 7140: train loss 0.60710. lr 3.000000e-04, running loss 0.60871, it/sec: 4.411447562182172
epoch 1 iter 7160: train loss 0.52900. lr 3.000000e-04, running loss 0.60952, it/sec: 4.513180261170536
epoch 1 iter 7180: train loss 0.55846. lr 3.000000e-04, running loss 0.60948, it/sec: 4.458751349472912
epoch 1 iter 7200: train loss 0.57606. lr 3.000000e-04, running loss 0.60988, it/sec: 4.511960599768302
epoch 1 iter 7220: train loss 0.55193. lr 3.000000e-04, running loss 0.60958, it/sec: 4.471092353616785
epoch 1 iter 7240: train loss 0.55731. lr 3.000000e-04, running loss 0.60915, it/sec: 4.48382110256196
epoch 1 iter 7260: train loss 0.57948. lr 3.000000e-04, running loss 0.61005, it/sec: 4.459649291630662
epoch 1 iter 7280: train loss 0.56819. lr 3.000000e-04, running loss 0.61006, it/sec: 4.492802130850077
epoch 1 iter 7300: train loss 0.62030. lr 3.000000e-04, running loss 0.61007, it/sec: 4.448888093310461
epoch 1 iter 7320: train loss 0.56394. lr 3.000000e-04, running loss 0.61039, it/sec: 4.496979438233936
epoch 1 iter 7340: train loss 0.52451. lr 3.000000e-04, running loss 0.61065, it/sec: 4.464487673258565
epoch 1 iter 7360: train loss 0.53162. lr 3.000000e-04, running loss 0.61097, it/sec: 4.437547746362593
epoch 1 iter 7380: train loss 0.69689. lr 3.000000e-04, running loss 0.61089, it/sec: 4.459626419831231
epoch 1 iter 7400: train loss 0.60930. lr 3.000000e-04, running loss 0.61090, it/sec: 4.440884532148893
epoch 1 iter 7420: train loss 0.67663. lr 3.000000e-04, running loss 0.61122, it/sec: 4.491383534156659
epoch 1 iter 7440: train loss 0.54970. lr 3.000000e-04, running loss 0.61102, it/sec: 4.482915028268345
epoch 1 iter 7460: train loss 0.56896. lr 3.000000e-04, running loss 0.61056, it/sec: 4.511758885029519
epoch 1 iter 7480: train loss 0.63524. lr 3.000000e-04, running loss 0.61121, it/sec: 4.441735597552511
epoch 1 iter 7500: train loss 1.14861. lr 3.000000e-04, running loss 0.61393, it/sec: 4.520896399090283
epoch 1 iter 7520: train loss 0.60746. lr 3.000000e-04, running loss 0.61442, it/sec: 4.477225274726127
epoch 1 iter 7540: train loss 0.71247. lr 3.000000e-04, running loss 0.61401, it/sec: 4.489924405768662
epoch 1 iter 7560: train loss 0.49066. lr 3.000000e-04, running loss 0.61413, it/sec: 4.481887968829155
epoch 1 iter 7580: train loss 0.55404. lr 3.000000e-04, running loss 0.61410, it/sec: 4.4603212856714896
epoch 1 iter 7600: train loss 0.62745. lr 3.000000e-04, running loss 0.61384, it/sec: 4.48476837235606
epoch 1 iter 7620: train loss 0.69734. lr 3.000000e-04, running loss 0.61356, it/sec: 4.50004566887
epoch 1 iter 7640: train loss 0.53963. lr 3.000000e-04, running loss 0.61348, it/sec: 4.485840760127045
epoch 1 iter 7660: train loss 0.55582. lr 3.000000e-04, running loss 0.61316, it/sec: 4.448898859535852
epoch 1 iter 7680: train loss 0.54916. lr 3.000000e-04, running loss 0.61319, it/sec: 4.4962920068111405
epoch 1 iter 7700: train loss 0.57939. lr 3.000000e-04, running loss 0.61338, it/sec: 4.484930972861172
epoch 1 iter 7720: train loss 0.68200. lr 3.000000e-04, running loss 0.61350, it/sec: 4.515800717903335
epoch 1 iter 7740: train loss 0.60402. lr 3.000000e-04, running loss 0.61405, it/sec: 4.4684724544836625
epoch 1 iter 7760: train loss 0.59030. lr 3.000000e-04, running loss 0.61402, it/sec: 4.489496966086694
epoch 1 iter 7780: train loss 0.61867. lr 3.000000e-04, running loss 0.61375, it/sec: 4.437606881547441
epoch 1 iter 7800: train loss 0.71821. lr 3.000000e-04, running loss 0.61342, it/sec: 4.467870063048623
epoch 1 iter 7820: train loss 0.59011. lr 3.000000e-04, running loss 0.61358, it/sec: 4.484211286749959
epoch 1 iter 7840: train loss 0.61882. lr 3.000000e-04, running loss 0.61512, it/sec: 4.486224775335412
epoch 1 iter 7860: train loss 0.57006. lr 3.000000e-04, running loss 0.61561, it/sec: 4.517495621342613
epoch 1 iter 7880: train loss 0.60334. lr 3.000000e-04, running loss 0.61518, it/sec: 4.463028216793471
epoch 1 iter 7900: train loss 0.53823. lr 3.000000e-04, running loss 0.61500, it/sec: 4.482507688732694
epoch 1 iter 7920: train loss 0.60171. lr 3.000000e-04, running loss 0.61489, it/sec: 4.4811120497474874
epoch 1 iter 7940: train loss 0.56526. lr 3.000000e-04, running loss 0.61449, it/sec: 4.5057471573061445
epoch 1 iter 7960: train loss 0.63560. lr 3.000000e-04, running loss 0.61488, it/sec: 4.4522830544240275
epoch 1 iter 7980: train loss 0.56916. lr 3.000000e-04, running loss 0.61456, it/sec: 4.4947519252344454
epoch 1 iter 8000: train loss 0.62861. lr 3.000000e-04, running loss 0.61498, it/sec: 4.451562631245416
epoch 1 iter 8020: train loss 0.63400. lr 3.000000e-04, running loss 0.61495, it/sec: 4.469974056304595
epoch 1 iter 8040: train loss 0.61188. lr 3.000000e-04, running loss 0.61499, it/sec: 4.470653961173645
epoch 1 iter 8060: train loss 0.65907. lr 3.000000e-04, running loss 0.61463, it/sec: 4.4950165571074745
epoch 1 iter 8080: train loss 0.63252. lr 3.000000e-04, running loss 0.61453, it/sec: 4.526370401085051
epoch 1 iter 8100: train loss 0.57941. lr 3.000000e-04, running loss 0.61450, it/sec: 4.451608288239163
epoch 1 iter 8120: train loss 0.57804. lr 3.000000e-04, running loss 0.61421, it/sec: 4.504190833835789
epoch 1 iter 8140: train loss 0.60401. lr 3.000000e-04, running loss 0.61409, it/sec: 4.4389800206124495
epoch 1 iter 8160: train loss 0.71843. lr 3.000000e-04, running loss 0.61378, it/sec: 4.482092006273929
epoch 1 iter 8180: train loss 0.54087. lr 3.000000e-04, running loss 0.61374, it/sec: 4.455412502267587
epoch 1 iter 8200: train loss 0.55621. lr 3.000000e-04, running loss 0.61361, it/sec: 4.5204606312888185
epoch 1 iter 8220: train loss 0.53078. lr 3.000000e-04, running loss 0.61349, it/sec: 4.438046813073151
epoch 1 iter 8240: train loss 0.60183. lr 3.000000e-04, running loss 0.61370, it/sec: 4.505425112589398
epoch 1 iter 8260: train loss 0.61861. lr 3.000000e-04, running loss 0.61292, it/sec: 4.445359181553255
epoch 1 iter 8280: train loss 0.60103. lr 3.000000e-04, running loss 0.61286, it/sec: 4.488151399210545
epoch 1 iter 8300: train loss 0.59506. lr 3.000000e-04, running loss 0.61317, it/sec: 4.492897104223388
epoch 1 iter 8320: train loss 0.50811. lr 3.000000e-04, running loss 0.61322, it/sec: 4.462785819193281
epoch 1 iter 8340: train loss 0.67086. lr 3.000000e-04, running loss 0.61297, it/sec: 4.51819759424465
epoch 1 iter 8360: train loss 0.61521. lr 3.000000e-04, running loss 0.61363, it/sec: 4.403571374637704
epoch 1 iter 8380: train loss 0.53426. lr 3.000000e-04, running loss 0.61303, it/sec: 4.495671016854817
epoch 1 iter 8400: train loss 0.60702. lr 3.000000e-04, running loss 0.61297, it/sec: 4.457003826176238
epoch 1 iter 8420: train loss 0.69471. lr 3.000000e-04, running loss 0.61264, it/sec: 4.475335717624885
epoch 1 iter 8440: train loss 0.54323. lr 3.000000e-04, running loss 0.61226, it/sec: 4.494164747624305
epoch 1 iter 8460: train loss 0.56936. lr 3.000000e-04, running loss 0.61202, it/sec: 4.4968617642983215
epoch 1 iter 8480: train loss 0.56044. lr 3.000000e-04, running loss 0.61158, it/sec: 4.497549913933112
epoch 1 iter 8500: train loss 0.53319. lr 3.000000e-04, running loss 0.61153, it/sec: 4.474998301219884
epoch 1 iter 8520: train loss 0.55296. lr 3.000000e-04, running loss 0.61166, it/sec: 4.456137050218113
epoch 1 iter 8540: train loss 0.67862. lr 3.000000e-04, running loss 0.61169, it/sec: 4.489877011320111
epoch 1 iter 8560: train loss 0.59730. lr 3.000000e-04, running loss 0.61147, it/sec: 4.472250693389418
epoch 1 iter 8580: train loss 0.62206. lr 3.000000e-04, running loss 0.61184, it/sec: 4.48057018674404
epoch 1 iter 8600: train loss 0.54943. lr 3.000000e-04, running loss 0.61176, it/sec: 4.491279023790515
epoch 1 iter 8620: train loss 0.56967. lr 3.000000e-04, running loss 0.61146, it/sec: 4.459055680201675
epoch 1 iter 8640: train loss 0.63688. lr 3.000000e-04, running loss 0.61182, it/sec: 4.508726684113556
epoch 1 iter 8660: train loss 0.64327. lr 3.000000e-04, running loss 0.61150, it/sec: 4.439446101607084
epoch 1 iter 8680: train loss 0.55576. lr 3.000000e-04, running loss 0.61125, it/sec: 4.511494210526481
epoch 1 iter 8700: train loss 0.68914. lr 3.000000e-04, running loss 0.61141, it/sec: 4.458238630906614
epoch 1 iter 8720: train loss 0.50543. lr 3.000000e-04, running loss 0.61137, it/sec: 4.443216714603564
epoch 1 iter 8740: train loss 0.71170. lr 3.000000e-04, running loss 0.61115, it/sec: 4.486533532460578
epoch 1 iter 8760: train loss 0.59527. lr 3.000000e-04, running loss 0.61130, it/sec: 4.471029703407391
epoch 1 iter 8780: train loss 0.50026. lr 3.000000e-04, running loss 0.61183, it/sec: 4.447113938128742
epoch 1 iter 8800: train loss 0.66191. lr 3.000000e-04, running loss 0.61177, it/sec: 4.466806488463767
epoch 1 iter 8820: train loss 0.66410. lr 3.000000e-04, running loss 0.61198, it/sec: 4.469435221797833
epoch 1 iter 8840: train loss 0.57800. lr 3.000000e-04, running loss 0.61167, it/sec: 4.45484000240307
epoch 1 iter 8860: train loss 0.55847. lr 3.000000e-04, running loss 0.61198, it/sec: 4.50653287075455
epoch 1 iter 8880: train loss 0.60398. lr 3.000000e-04, running loss 0.61193, it/sec: 4.459085166285589
epoch 1 iter 8900: train loss 0.49995. lr 3.000000e-04, running loss 0.61219, it/sec: 4.500294722170939
epoch 1 iter 8920: train loss 0.58813. lr 3.000000e-04, running loss 0.61202, it/sec: 4.476708560218933
epoch 1 iter 8940: train loss 0.60605. lr 3.000000e-04, running loss 0.61185, it/sec: 4.5180988533873006
epoch 1 iter 8960: train loss 0.73245. lr 3.000000e-04, running loss 0.61186, it/sec: 4.4737409865857325
epoch 1 iter 8980: train loss 0.57818. lr 3.000000e-04, running loss 0.61190, it/sec: 4.463509820735722
epoch 1 iter 9000: train loss 0.59156. lr 3.000000e-04, running loss 0.61244, it/sec: 4.4657565630528
epoch 1 iter 9020: train loss 0.55713. lr 3.000000e-04, running loss 0.61215, it/sec: 4.459725505257552
epoch 1 iter 9040: train loss 0.67521. lr 3.000000e-04, running loss 0.61210, it/sec: 4.508580403354085
epoch 1 iter 9060: train loss 0.57102. lr 3.000000e-04, running loss 0.61156, it/sec: 4.435568497804175
epoch 1 iter 9080: train loss 0.63084. lr 3.000000e-04, running loss 0.61182, it/sec: 4.5167623666135
epoch 1 iter 9100: train loss 0.54608. lr 3.000000e-04, running loss 0.61188, it/sec: 4.459507372644943
epoch 1 iter 9120: train loss 0.54564. lr 3.000000e-04, running loss 0.61147, it/sec: 4.472617441229219
epoch 1 iter 9140: train loss 0.59776. lr 3.000000e-04, running loss 0.61175, it/sec: 4.437825122600593
epoch 1 iter 9160: train loss 0.70205. lr 3.000000e-04, running loss 0.61197, it/sec: 4.5058394915378965
epoch 1 iter 9180: train loss 0.60484. lr 3.000000e-04, running loss 0.61161, it/sec: 4.46582602613701
epoch 1 iter 9200: train loss 0.55893. lr 3.000000e-04, running loss 0.61167, it/sec: 4.472422528509916
epoch 1 iter 9220: train loss 0.65188. lr 3.000000e-04, running loss 0.61173, it/sec: 4.510138114105426
epoch 1 iter 9240: train loss 0.69200. lr 3.000000e-04, running loss 0.61176, it/sec: 4.460426927665837
epoch 1 iter 9260: train loss 0.55780. lr 3.000000e-04, running loss 0.61204, it/sec: 4.465528825939496
epoch 1 iter 9280: train loss 0.64342. lr 3.000000e-04, running loss 0.61236, it/sec: 4.433967629724078
epoch 1 iter 9300: train loss 0.60596. lr 3.000000e-04, running loss 0.61242, it/sec: 4.506376720340577
epoch 1 iter 9320: train loss 0.62492. lr 3.000000e-04, running loss 0.61230, it/sec: 4.4890324068387475
epoch 1 iter 9340: train loss 0.66856. lr 3.000000e-04, running loss 0.61179, it/sec: 4.465663252496936
epoch 1 iter 9360: train loss 0.64477. lr 3.000000e-04, running loss 0.61180, it/sec: 4.505434673703344
epoch 1 iter 9380: train loss 0.55319. lr 3.000000e-04, running loss 0.61174, it/sec: 4.507627417711695
epoch 1 iter 9400: train loss 0.65563. lr 3.000000e-04, running loss 0.61197, it/sec: 4.4669122985148375
epoch 1 iter 9420: train loss 0.62251. lr 3.000000e-04, running loss 0.61205, it/sec: 4.507737323187242
epoch 1 iter 9440: train loss 0.56558. lr 3.000000e-04, running loss 0.61200, it/sec: 4.473870482354962
epoch 1 iter 9460: train loss 0.60189. lr 3.000000e-04, running loss 0.61195, it/sec: 4.517853989360903
epoch 1 iter 9480: train loss 0.54929. lr 3.000000e-04, running loss 0.61198, it/sec: 4.4522744721768595
epoch 1 iter 9500: train loss 0.74010. lr 3.000000e-04, running loss 0.61274, it/sec: 4.512618314083215
epoch 1 iter 9520: train loss 0.61451. lr 3.000000e-04, running loss 0.61256, it/sec: 4.449911051739487
epoch 1 iter 9540: train loss 0.60112. lr 3.000000e-04, running loss 0.61288, it/sec: 4.5144254012361715
epoch 1 iter 9560: train loss 0.76366. lr 3.000000e-04, running loss 0.61324, it/sec: 4.452307833281104
epoch 1 iter 9580: train loss 0.52426. lr 3.000000e-04, running loss 0.61323, it/sec: 4.483286442880111
epoch 1 iter 9600: train loss 0.64544. lr 3.000000e-04, running loss 0.61405, it/sec: 4.483326723990412
epoch 1 iter 9620: train loss 0.60277. lr 3.000000e-04, running loss 0.61353, it/sec: 4.4734673264435445
epoch 1 iter 9640: train loss 0.51583. lr 3.000000e-04, running loss 0.61376, it/sec: 4.52935087099217
epoch 1 iter 9660: train loss 0.62263. lr 3.000000e-04, running loss 0.61378, it/sec: 4.4369728379646745
epoch 1 iter 9680: train loss 0.64047. lr 3.000000e-04, running loss 0.61376, it/sec: 4.506739421972255
epoch 1 iter 9700: train loss 0.76349. lr 3.000000e-04, running loss 0.61352, it/sec: 4.460186981361621
epoch 1 iter 9720: train loss 0.55006. lr 3.000000e-04, running loss 0.61316, it/sec: 4.523475471278675
epoch 1 iter 9740: train loss 0.53586. lr 3.000000e-04, running loss 0.61315, it/sec: 4.460508221849208
epoch 1 iter 9760: train loss 0.55272. lr 3.000000e-04, running loss 0.61320, it/sec: 4.51880570985329
epoch 1 iter 9780: train loss 0.57735. lr 3.000000e-04, running loss 0.61303, it/sec: 4.420965521831935
epoch 1 iter 9800: train loss 0.63871. lr 3.000000e-04, running loss 0.61274, it/sec: 4.493691528885653
epoch 1 iter 9820: train loss 0.50435. lr 3.000000e-04, running loss 0.61284, it/sec: 4.453061475354239
epoch 1 iter 9840: train loss 0.58234. lr 3.000000e-04, running loss 0.61266, it/sec: 4.476336872355339
epoch 1 iter 9860: train loss 0.57673. lr 3.000000e-04, running loss 0.61275, it/sec: 4.5110279591506295
epoch 1 iter 9880: train loss 0.69133. lr 3.000000e-04, running loss 0.61246, it/sec: 4.409849800211479
epoch 1 iter 9900: train loss 0.59665. lr 3.000000e-04, running loss 0.61216, it/sec: 4.515172106433169
epoch 1 iter 9920: train loss 0.58619. lr 3.000000e-04, running loss 0.61203, it/sec: 4.497387693409477
epoch 1 iter 9940: train loss 0.60538. lr 3.000000e-04, running loss 0.61173, it/sec: 4.461362206945096
epoch 1 iter 9960: train loss 0.58882. lr 3.000000e-04, running loss 0.61189, it/sec: 4.4998471218993865
epoch 1 iter 9980: train loss 0.63023. lr 3.000000e-04, running loss 0.61203, it/sec: 4.451470448082486
epoch 1 iter 10000: train loss 0.60601. lr 3.000000e-04, running loss 0.61235, it/sec: 4.494787341823527
epoch 1 iter 10020: train loss 0.66389. lr 3.000000e-04, running loss 0.61250, it/sec: 4.482966857948395
epoch 1 iter 10040: train loss 0.57661. lr 3.000000e-04, running loss 0.61229, it/sec: 4.495729528956838
epoch 1 iter 10060: train loss 0.58853. lr 3.000000e-04, running loss 0.61207, it/sec: 4.430137051626731
epoch 1 iter 10080: train loss 0.58901. lr 3.000000e-04, running loss 0.61171, it/sec: 4.518198001817031
epoch 1 iter 10100: train loss 0.55554. lr 3.000000e-04, running loss 0.61132, it/sec: 4.443412091772592
epoch 1 iter 10120: train loss 0.64061. lr 3.000000e-04, running loss 0.61154, it/sec: 4.447431715087775
epoch 1 iter 10140: train loss 0.64684. lr 3.000000e-04, running loss 0.61262, it/sec: 4.4971739486130105
epoch 1 iter 10160: train loss 0.63220. lr 3.000000e-04, running loss 0.61238, it/sec: 4.434982930231245
epoch 1 iter 10180: train loss 0.60550. lr 3.000000e-04, running loss 0.61237, it/sec: 4.493900074973341
epoch 1 iter 10200: train loss 0.68647. lr 3.000000e-04, running loss 0.61227, it/sec: 4.47957353851498
epoch 1 iter 10220: train loss 0.72169. lr 3.000000e-04, running loss 0.61192, it/sec: 4.482956286500783
epoch 1 iter 10240: train loss 0.54554. lr 3.000000e-04, running loss 0.61176, it/sec: 4.48394770438355
epoch 1 iter 10260: train loss 0.54305. lr 3.000000e-04, running loss 0.61161, it/sec: 4.420872353581294
epoch 1 iter 10280: train loss 0.54706. lr 3.000000e-04, running loss 0.61167, it/sec: 4.5049091136712365
epoch 1 iter 10300: train loss 0.65713. lr 3.000000e-04, running loss 0.61192, it/sec: 4.42560478182046
epoch 1 iter 10320: train loss 0.65035. lr 3.000000e-04, running loss 0.61227, it/sec: 4.495846071823333
epoch 1 iter 10340: train loss 0.55953. lr 3.000000e-04, running loss 0.61202, it/sec: 4.45672633077427
epoch 1 iter 10360: train loss 0.71191. lr 3.000000e-04, running loss 0.61200, it/sec: 4.478650866842124
epoch 1 iter 10380: train loss 0.75013. lr 3.000000e-04, running loss 0.61237, it/sec: 4.476673108333024
epoch 1 iter 10400: train loss 0.66038. lr 3.000000e-04, running loss 0.61210, it/sec: 4.4864789032588135
epoch 1 iter 10420: train loss 0.60419. lr 3.000000e-04, running loss 0.61202, it/sec: 4.523531640008989
epoch 1 iter 10440: train loss 0.72720. lr 3.000000e-04, running loss 0.61218, it/sec: 4.445488937475423
epoch 1 iter 10460: train loss 0.61873. lr 3.000000e-04, running loss 0.61185, it/sec: 4.512964218356075
epoch 1 iter 10480: train loss 0.59841. lr 3.000000e-04, running loss 0.61168, it/sec: 4.483439106370251
epoch 1 iter 10500: train loss 0.54675. lr 3.000000e-04, running loss 0.61171, it/sec: 4.437430740344854
epoch 1 iter 10520: train loss 0.56373. lr 3.000000e-04, running loss 0.61165, it/sec: 4.516693125575842
epoch 1 iter 10540: train loss 0.67109. lr 3.000000e-04, running loss 0.61210, it/sec: 4.426581574416571
epoch 1 iter 10560: train loss 0.55298. lr 3.000000e-04, running loss 0.61229, it/sec: 4.471805373891272
epoch 1 iter 10580: train loss 0.60394. lr 3.000000e-04, running loss 0.61267, it/sec: 4.466754573048688
epoch 1 iter 10600: train loss 0.58295. lr 3.000000e-04, running loss 0.61315, it/sec: 4.460306005777539
epoch 1 iter 10620: train loss 0.56992. lr 3.000000e-04, running loss 0.61312, it/sec: 4.475094025944933
epoch 1 iter 10640: train loss 0.60563. lr 3.000000e-04, running loss 0.61289, it/sec: 4.459906662720898
epoch 1 iter 10660: train loss 0.59318. lr 3.000000e-04, running loss 0.61289, it/sec: 4.510565607933543
epoch 1 iter 10680: train loss 0.67463. lr 3.000000e-04, running loss 0.61302, it/sec: 4.470606273499665
epoch 1 iter 10700: train loss 0.62489. lr 3.000000e-04, running loss 0.61299, it/sec: 4.503772479258541
epoch 1 iter 10720: train loss 0.56740. lr 3.000000e-04, running loss 0.61315, it/sec: 4.440739150333995
epoch 1 iter 10740: train loss 0.52366. lr 3.000000e-04, running loss 0.61261, it/sec: 4.479510912031393
epoch 1 iter 10760: train loss 0.58658. lr 3.000000e-04, running loss 0.61274, it/sec: 4.515696454479162
epoch 1 iter 10780: train loss 0.56040. lr 3.000000e-04, running loss 0.61261, it/sec: 4.460101939194242
epoch 1 iter 10800: train loss 0.64780. lr 3.000000e-04, running loss 0.61218, it/sec: 4.50186320841041
epoch 1 iter 10820: train loss 0.65776. lr 3.000000e-04, running loss 0.61232, it/sec: 4.4515050451571
epoch 1 iter 10840: train loss 0.81669. lr 3.000000e-04, running loss 0.61246, it/sec: 4.500585509020803
epoch 1 iter 10860: train loss 0.68568. lr 3.000000e-04, running loss 0.61231, it/sec: 4.4697151615068185
epoch 1 iter 10880: train loss 0.61306. lr 3.000000e-04, running loss 0.61246, it/sec: 4.467419369008937
epoch 1 iter 10900: train loss 0.55605. lr 3.000000e-04, running loss 0.61241, it/sec: 4.5042207793377385
epoch 1 iter 10920: train loss 0.65893. lr 3.000000e-04, running loss 0.61244, it/sec: 4.488287492613249
epoch 1 iter 10940: train loss 0.62955. lr 3.000000e-04, running loss 0.61225, it/sec: 4.464824782840164
epoch 1 iter 10960: train loss 0.56329. lr 3.000000e-04, running loss 0.61196, it/sec: 4.492083872514426
epoch 1 iter 10980: train loss 0.51435. lr 3.000000e-04, running loss 0.61191, it/sec: 4.489819256922308
epoch 1 iter 11000: train loss 0.61596. lr 3.000000e-04, running loss 0.61174, it/sec: 4.459573636267164
epoch 1 iter 11020: train loss 0.61060. lr 3.000000e-04, running loss 0.61173, it/sec: 4.508395189775789
epoch 1 iter 11040: train loss 0.53613. lr 3.000000e-04, running loss 0.61175, it/sec: 4.437558734010274
epoch 1 iter 11060: train loss 0.50552. lr 3.000000e-04, running loss 0.61186, it/sec: 4.508714567346578
epoch 1 iter 11080: train loss 0.61258. lr 3.000000e-04, running loss 0.61164, it/sec: 4.45656497469832
epoch 1 iter 11100: train loss 0.60298. lr 3.000000e-04, running loss 0.61184, it/sec: 4.475742836742507
epoch 1 iter 11120: train loss 0.59182. lr 3.000000e-04, running loss 0.61157, it/sec: 4.484507057506653
epoch 1 iter 11140: train loss 0.54939. lr 3.000000e-04, running loss 0.61159, it/sec: 4.4499870516046816
epoch 1 iter 11160: train loss 0.62255. lr 3.000000e-04, running loss 0.61227, it/sec: 4.4980444407834
epoch 1 iter 11180: train loss 0.54481. lr 3.000000e-04, running loss 0.61181, it/sec: 4.427596573434551
epoch 1 iter 11200: train loss 0.69443. lr 3.000000e-04, running loss 0.61189, it/sec: 4.5020114237439115
epoch 1 iter 11220: train loss 0.55775. lr 3.000000e-04, running loss 0.61222, it/sec: 4.4513702424407615
epoch 1 iter 11240: train loss 0.55955. lr 3.000000e-04, running loss 0.61221, it/sec: 4.492442034348497
epoch 1 iter 11260: train loss 0.57069. lr 3.000000e-04, running loss 0.61215, it/sec: 4.4216396900066215
epoch 1 iter 11280: train loss 0.63913. lr 3.000000e-04, running loss 0.61206, it/sec: 4.489783213392665
epoch 1 iter 11300: train loss 0.61524. lr 3.000000e-04, running loss 0.61175, it/sec: 4.453851553377616
epoch 1 iter 11320: train loss 0.60725. lr 3.000000e-04, running loss 0.61222, it/sec: 4.478522036349925
epoch 1 iter 11340: train loss 0.70513. lr 3.000000e-04, running loss 0.61212, it/sec: 4.508077663797933
epoch 1 iter 11360: train loss 0.61694. lr 3.000000e-04, running loss 0.61171, it/sec: 4.407285561509145
epoch 1 iter 11380: train loss 0.56274. lr 3.000000e-04, running loss 0.61196, it/sec: 4.511304219136598
epoch 1 iter 11400: train loss 0.52370. lr 3.000000e-04, running loss 0.61177, it/sec: 4.491348919138444
epoch 1 iter 11420: train loss 0.53796. lr 3.000000e-04, running loss 0.61157, it/sec: 4.466074117929088
epoch 1 iter 11440: train loss 0.60856. lr 3.000000e-04, running loss 0.61175, it/sec: 4.488324881724489
epoch 1 iter 11460: train loss 0.50795. lr 3.000000e-04, running loss 0.61161, it/sec: 4.463514084833763
epoch 1 iter 11480: train loss 0.69424. lr 3.000000e-04, running loss 0.61145, it/sec: 4.484911442428482
epoch 1 iter 11500: train loss 0.60998. lr 3.000000e-04, running loss 0.61178, it/sec: 4.471338012156929
epoch 1 iter 11520: train loss 0.62036. lr 3.000000e-04, running loss 0.61152, it/sec: 4.51306483334763
epoch 1 iter 11540: train loss 0.96446. lr 3.000000e-04, running loss 0.61165, it/sec: 4.440361857478536
epoch 1 iter 11560: train loss 0.55806. lr 3.000000e-04, running loss 0.61147, it/sec: 4.513205517388576
epoch 1 iter 11580: train loss 0.60342. lr 3.000000e-04, running loss 0.61171, it/sec: 4.447017904465112
epoch 1 iter 11600: train loss 0.57026. lr 3.000000e-04, running loss 0.61149, it/sec: 4.489732596431483
epoch 1 iter 11620: train loss 0.72437. lr 3.000000e-04, running loss 0.61113, it/sec: 4.479984038910511
epoch 1 iter 11640: train loss 0.57638. lr 3.000000e-04, running loss 0.61097, it/sec: 4.465396900543995
epoch 1 iter 11660: train loss 0.61758. lr 3.000000e-04, running loss 0.61080, it/sec: 4.487660073245627
epoch 1 iter 11680: train loss 0.57282. lr 3.000000e-04, running loss 0.61070, it/sec: 4.4671318147550485
epoch 1 iter 11700: train loss 0.55298. lr 3.000000e-04, running loss 0.61069, it/sec: 4.5027213861140485
epoch 1 iter 11720: train loss 0.64466. lr 3.000000e-04, running loss 0.61111, it/sec: 4.466325268995736
epoch 1 iter 11740: train loss 0.67114. lr 3.000000e-04, running loss 0.61129, it/sec: 4.473479693652674
epoch 1 iter 11760: train loss 0.69332. lr 3.000000e-04, running loss 0.61121, it/sec: 4.486646539669484
epoch 1 iter 11780: train loss 0.64702. lr 3.000000e-04, running loss 0.61102, it/sec: 4.506538638374132
epoch 1 iter 11800: train loss 0.75457. lr 3.000000e-04, running loss 0.61091, it/sec: 4.477298141677106
epoch 1 iter 11820: train loss 0.55203. lr 3.000000e-04, running loss 0.61097, it/sec: 4.50372051212909
epoch 1 iter 11840: train loss 0.53615. lr 3.000000e-04, running loss 0.61080, it/sec: 4.459127558784357
epoch 1 iter 11860: train loss 0.58893. lr 3.000000e-04, running loss 0.61101, it/sec: 4.4790962265901015
epoch 1 iter 11880: train loss 0.62079. lr 3.000000e-04, running loss 0.61110, it/sec: 4.49595083720404
epoch 1 iter 11900: train loss 0.56864. lr 3.000000e-04, running loss 0.61103, it/sec: 4.45844326288916
epoch 1 iter 11920: train loss 0.73331. lr 3.000000e-04, running loss 0.61086, it/sec: 4.492784912208338
epoch 1 iter 11940: train loss 0.59802. lr 3.000000e-04, running loss 0.61063, it/sec: 4.46945649669145
epoch 1 iter 11960: train loss 0.64907. lr 3.000000e-04, running loss 0.61071, it/sec: 4.501012002747538
epoch 1 iter 11980: train loss 0.54727. lr 3.000000e-04, running loss 0.61126, it/sec: 4.462119475114998
epoch 1 iter 12000: train loss 0.63785. lr 3.000000e-04, running loss 0.61121, it/sec: 4.4771214618827075
epoch 1 iter 12020: train loss 0.67471. lr 3.000000e-04, running loss 0.61117, it/sec: 4.5070076807275665
epoch 1 iter 12040: train loss 0.54924. lr 3.000000e-04, running loss 0.61069, it/sec: 4.456661897466008
epoch 1 iter 12060: train loss 0.67559. lr 3.000000e-04, running loss 0.61047, it/sec: 4.513253853802368
epoch 1 iter 12080: train loss 0.76014. lr 3.000000e-04, running loss 0.61087, it/sec: 4.442675884401469
epoch 1 iter 12100: train loss 0.63996. lr 3.000000e-04, running loss 0.61095, it/sec: 4.51783982396517
epoch 1 iter 12120: train loss 0.66258. lr 3.000000e-04, running loss 0.61104, it/sec: 4.457747253956249
epoch 1 iter 12140: train loss 0.54800. lr 3.000000e-04, running loss 0.61087, it/sec: 4.463115043693268
epoch 1 iter 12160: train loss 0.63818. lr 3.000000e-04, running loss 0.61117, it/sec: 4.459054109673858
epoch 1 iter 12180: train loss 0.57834. lr 3.000000e-04, running loss 0.61153, it/sec: 4.493313987193882
epoch 1 iter 12200: train loss 0.66851. lr 3.000000e-04, running loss 0.61163, it/sec: 4.511369936508213
epoch 1 iter 12220: train loss 0.61013. lr 3.000000e-04, running loss 0.61160, it/sec: 4.468984611854126
epoch 1 iter 12240: train loss 0.57375. lr 3.000000e-04, running loss 0.61174, it/sec: 4.519215915655477
epoch 1 iter 12260: train loss 0.63245. lr 3.000000e-04, running loss 0.61166, it/sec: 4.442527326049492
epoch 1 iter 12280: train loss 0.54993. lr 3.000000e-04, running loss 0.61143, it/sec: 4.4923056289772525
epoch 1 iter 12300: train loss 0.62613. lr 3.000000e-04, running loss 0.61095, it/sec: 4.487229137105133
epoch 1 iter 12320: train loss 0.76857. lr 3.000000e-04, running loss 0.61130, it/sec: 4.478055915803373
epoch 1 iter 12340: train loss 0.78036. lr 3.000000e-04, running loss 0.61127, it/sec: 4.488256852205008
epoch 1 iter 12360: train loss 0.59815. lr 3.000000e-04, running loss 0.61108, it/sec: 4.442297076963771
epoch 1 iter 12380: train loss 0.58593. lr 3.000000e-04, running loss 0.61080, it/sec: 4.493360908924322
epoch 1 iter 12400: train loss 0.64568. lr 3.000000e-04, running loss 0.61058, it/sec: 4.48392715733041
epoch 1 iter 12420: train loss 0.59078. lr 3.000000e-04, running loss 0.60989, it/sec: 4.488328689149644
epoch 1 iter 12440: train loss 0.58548. lr 3.000000e-04, running loss 0.60979, it/sec: 4.445637001429882
epoch 1 iter 12460: train loss 0.75258. lr 3.000000e-04, running loss 0.60968, it/sec: 4.492667458861422
epoch 1 iter 12480: train loss 0.50037. lr 3.000000e-04, running loss 0.60947, it/sec: 4.493120515626277
epoch 1 iter 12500: train loss 0.73593. lr 3.000000e-04, running loss 0.61009, it/sec: 1.2251657538602998
epoch 1 iter 12520: train loss 0.67535. lr 3.000000e-04, running loss 0.61001, it/sec: 4.468732981456481
epoch 1 iter 12540: train loss 0.55782. lr 3.000000e-04, running loss 0.60998, it/sec: 4.514122575221121
epoch 1 iter 12560: train loss 0.53604. lr 3.000000e-04, running loss 0.60993, it/sec: 4.41517440951286
epoch 1 iter 12580: train loss 0.65612. lr 3.000000e-04, running loss 0.60936, it/sec: 4.469601567168298
epoch 1 iter 12600: train loss 0.68281. lr 3.000000e-04, running loss 0.60941, it/sec: 4.497504806172853
epoch 1 iter 12620: train loss 0.60834. lr 3.000000e-04, running loss 0.60920, it/sec: 4.481309609612264
epoch 1 iter 12640: train loss 0.63294. lr 3.000000e-04, running loss 0.60885, it/sec: 4.507161049974479
epoch 1 iter 12660: train loss 0.54601. lr 3.000000e-04, running loss 0.60878, it/sec: 4.476154798714458
epoch 1 iter 12680: train loss 0.54985. lr 3.000000e-04, running loss 0.60857, it/sec: 4.490271012927305
epoch 1 iter 12700: train loss 0.54948. lr 3.000000e-04, running loss 0.60918, it/sec: 4.440606595439661
epoch 1 iter 12720: train loss 0.65358. lr 3.000000e-04, running loss 0.61024, it/sec: 4.495486841203707
epoch 1 iter 12740: train loss 0.55204. lr 3.000000e-04, running loss 0.60994, it/sec: 4.4508901244125445
epoch 1 iter 12760: train loss 0.64229. lr 3.000000e-04, running loss 0.60970, it/sec: 4.509341992653876
epoch 1 iter 12780: train loss 1.31340. lr 3.000000e-04, running loss 0.61032, it/sec: 4.452212962040561
epoch 1 iter 12800: train loss 0.69146. lr 3.000000e-04, running loss 0.61043, it/sec: 4.512361786461732
epoch 1 iter 12820: train loss 0.52689. lr 3.000000e-04, running loss 0.61033, it/sec: 4.445540556448859
epoch 1 iter 12840: train loss 0.65438. lr 3.000000e-04, running loss 0.61031, it/sec: 4.46088035048308
epoch 1 iter 12860: train loss 0.58421. lr 3.000000e-04, running loss 0.61001, it/sec: 4.490910761208868
epoch 1 iter 12880: train loss 0.60616. lr 3.000000e-04, running loss 0.60971, it/sec: 4.409138979209236
epoch 1 iter 12900: train loss 0.51312. lr 3.000000e-04, running loss 0.60991, it/sec: 4.507608216589384
epoch 1 iter 12920: train loss 0.57744. lr 3.000000e-04, running loss 0.60994, it/sec: 4.452507342265136
epoch 1 iter 12940: train loss 0.57165. lr 3.000000e-04, running loss 0.60978, it/sec: 4.466683305422668
epoch 1 iter 12960: train loss 0.48659. lr 3.000000e-04, running loss 0.61007, it/sec: 4.496924614385268
epoch 1 iter 12980: train loss 0.59332. lr 3.000000e-04, running loss 0.61036, it/sec: 4.49021982047137
epoch 1 iter 13000: train loss 0.56885. lr 3.000000e-04, running loss 0.61025, it/sec: 4.477221666969972
epoch 1 iter 13020: train loss 0.53370. lr 3.000000e-04, running loss 0.60998, it/sec: 4.502227452718241
epoch 1 iter 13040: train loss 0.57855. lr 3.000000e-04, running loss 0.61027, it/sec: 4.463116995067727
epoch 1 iter 13060: train loss 0.64517. lr 3.000000e-04, running loss 0.61034, it/sec: 4.501281384524417
epoch 1 iter 13080: train loss 0.61218. lr 3.000000e-04, running loss 0.61033, it/sec: 4.507543197730287
epoch 1 iter 13100: train loss 0.58104. lr 3.000000e-04, running loss 0.60973, it/sec: 4.450589580943157
epoch 1 iter 13120: train loss 0.63935. lr 3.000000e-04, running loss 0.60944, it/sec: 4.4865972424335
epoch 1 iter 13140: train loss 0.67453. lr 3.000000e-04, running loss 0.60946, it/sec: 4.445669097767754
epoch 1 iter 13160: train loss 0.55347. lr 3.000000e-04, running loss 0.60917, it/sec: 4.488524628413353
epoch 1 iter 13180: train loss 0.59993. lr 3.000000e-04, running loss 0.60951, it/sec: 4.475502081615634
epoch 1 iter 13200: train loss 0.56666. lr 3.000000e-04, running loss 0.60967, it/sec: 4.462260466293957
epoch 1 iter 13220: train loss 0.70532. lr 3.000000e-04, running loss 0.60982, it/sec: 4.487402085342449
epoch 1 iter 13240: train loss 0.62607. lr 3.000000e-04, running loss 0.61042, it/sec: 4.436168289048295
epoch 1 iter 13260: train loss 0.58505. lr 3.000000e-04, running loss 0.61030, it/sec: 4.51132277888168
epoch 1 iter 13280: train loss 0.55282. lr 3.000000e-04, running loss 0.60996, it/sec: 4.467476349907009
epoch 1 iter 13300: train loss 0.58263. lr 3.000000e-04, running loss 0.61013, it/sec: 4.510170293689271
epoch 1 iter 13320: train loss 0.59854. lr 3.000000e-04, running loss 0.60988, it/sec: 4.456223629996987
epoch 1 iter 13340: train loss 0.65205. lr 3.000000e-04, running loss 0.61047, it/sec: 4.514489335206884
epoch 1 iter 13360: train loss 0.65147. lr 3.000000e-04, running loss 0.61059, it/sec: 4.450110027826669
epoch 1 iter 13380: train loss 0.60604. lr 3.000000e-04, running loss 0.61096, it/sec: 4.492133936418603
epoch 1 iter 13400: train loss 0.71140. lr 3.000000e-04, running loss 0.61110, it/sec: 4.469976673119018
epoch 1 iter 13420: train loss 0.68055. lr 3.000000e-04, running loss 0.61057, it/sec: 4.453644903108058
epoch 1 iter 13440: train loss 0.63432. lr 3.000000e-04, running loss 0.61153, it/sec: 4.496837336869917
epoch 1 iter 13460: train loss 0.55842. lr 3.000000e-04, running loss 0.61116, it/sec: 4.457119263747572
epoch 1 iter 13480: train loss 0.59022. lr 3.000000e-04, running loss 0.61094, it/sec: 4.508055186856256
epoch 1 iter 13500: train loss 0.63716. lr 3.000000e-04, running loss 0.61167, it/sec: 4.462598672360136
epoch 1 iter 13520: train loss 0.58177. lr 3.000000e-04, running loss 0.61168, it/sec: 4.468045215099745
epoch 1 iter 13540: train loss 0.62327. lr 3.000000e-04, running loss 0.61156, it/sec: 4.4664701769147
epoch 1 iter 13560: train loss 0.64567. lr 3.000000e-04, running loss 0.61127, it/sec: 4.460466041660436
epoch 1 iter 13580: train loss 0.62409. lr 3.000000e-04, running loss 0.61134, it/sec: 4.5015879005824635
epoch 1 iter 13600: train loss 0.56858. lr 3.000000e-04, running loss 0.61125, it/sec: 4.455524025711241
epoch 1 iter 13620: train loss 0.56441. lr 3.000000e-04, running loss 0.61143, it/sec: 4.506973757344195
epoch 1 iter 13640: train loss 0.70278. lr 3.000000e-04, running loss 0.61155, it/sec: 4.467810238225524
epoch 1 iter 13660: train loss 0.55311. lr 3.000000e-04, running loss 0.61136, it/sec: 4.520297487705246
epoch 1 iter 13680: train loss 0.61941. lr 3.000000e-04, running loss 0.61102, it/sec: 4.4322452902681615
epoch 1 iter 13700: train loss 0.51258. lr 3.000000e-04, running loss 0.61078, it/sec: 4.504438317173079
epoch 1 iter 13720: train loss 0.56216. lr 3.000000e-04, running loss 0.61027, it/sec: 4.438603458931269
epoch 1 iter 13740: train loss 0.49265. lr 3.000000e-04, running loss 0.61005, it/sec: 4.469705052498804
epoch 1 iter 13760: train loss 0.53527. lr 3.000000e-04, running loss 0.60972, it/sec: 4.505969411574424
epoch 1 iter 13780: train loss 0.70759. lr 3.000000e-04, running loss 0.60976, it/sec: 4.428203055131125
epoch 1 iter 13800: train loss 0.68487. lr 3.000000e-04, running loss 0.60945, it/sec: 4.497969967831738
epoch 1 iter 13820: train loss 0.55282. lr 3.000000e-04, running loss 0.60933, it/sec: 4.456662672060494
epoch 1 iter 13840: train loss 0.62704. lr 3.000000e-04, running loss 0.60957, it/sec: 4.513760763199669
epoch 1 iter 13860: train loss 0.67791. lr 3.000000e-04, running loss 0.60955, it/sec: 4.498371259200371
epoch 1 iter 13880: train loss 0.60686. lr 3.000000e-04, running loss 0.61002, it/sec: 4.4622074604187585
epoch 1 iter 13900: train loss 0.63855. lr 3.000000e-04, running loss 0.61012, it/sec: 4.486364536096913
epoch 1 iter 13920: train loss 0.58707. lr 3.000000e-04, running loss 0.61036, it/sec: 4.482022779936837
epoch 1 iter 13940: train loss 0.57495. lr 3.000000e-04, running loss 0.61005, it/sec: 4.461307831021803
epoch 1 iter 13960: train loss 0.56041. lr 3.000000e-04, running loss 0.60971, it/sec: 4.413035635039361
epoch 1 iter 13980: train loss 0.57900. lr 3.000000e-04, running loss 0.60946, it/sec: 4.506842074519694
epoch 1 iter 14000: train loss 0.61088. lr 3.000000e-04, running loss 0.60908, it/sec: 4.436264406838337
epoch 1 iter 14020: train loss 0.60372. lr 3.000000e-04, running loss 0.60915, it/sec: 4.485546584195646
epoch 1 iter 14040: train loss 0.64524. lr 3.000000e-04, running loss 0.60914, it/sec: 4.4509621562709105
epoch 1 iter 14060: train loss 0.58814. lr 3.000000e-04, running loss 0.60875, it/sec: 4.451693165997405
epoch 1 iter 14080: train loss 0.66702. lr 3.000000e-04, running loss 0.60931, it/sec: 4.499051087382261
epoch 1 iter 14100: train loss 0.67520. lr 3.000000e-04, running loss 0.60942, it/sec: 4.44411627106285
epoch 1 iter 14120: train loss 0.59805. lr 3.000000e-04, running loss 0.60994, it/sec: 4.476878353501885
epoch 1 iter 14140: train loss 0.61368. lr 3.000000e-04, running loss 0.60968, it/sec: 4.496000380208554
epoch 1 iter 14160: train loss 0.68354. lr 3.000000e-04, running loss 0.60977, it/sec: 4.445431823599291
epoch 1 iter 14180: train loss 0.67452. lr 3.000000e-04, running loss 0.60966, it/sec: 4.498443399083366
epoch 1 iter 14200: train loss 0.54442. lr 3.000000e-04, running loss 0.60946, it/sec: 4.443189214565273
epoch 1 iter 14220: train loss 0.60886. lr 3.000000e-04, running loss 0.60951, it/sec: 4.477054352581291
epoch 1 iter 14240: train loss 0.62453. lr 3.000000e-04, running loss 0.60991, it/sec: 4.4849748639758245
epoch 1 iter 14260: train loss 0.54281. lr 3.000000e-04, running loss 0.60998, it/sec: 4.520734511190541
epoch 1 iter 14280: train loss 0.70491. lr 3.000000e-04, running loss 0.60988, it/sec: 4.433788494376753
epoch 1 iter 14300: train loss 0.54335. lr 3.000000e-04, running loss 0.60991, it/sec: 4.513159076612265
epoch 1 iter 14320: train loss 0.64421. lr 3.000000e-04, running loss 0.61027, it/sec: 4.466185816993139
epoch 1 iter 14340: train loss 0.77346. lr 3.000000e-04, running loss 0.61046, it/sec: 4.477365036580704
epoch 1 iter 14360: train loss 0.64033. lr 3.000000e-04, running loss 0.61032, it/sec: 4.504810487364046
epoch 1 iter 14380: train loss 0.58246. lr 3.000000e-04, running loss 0.61025, it/sec: 4.456800875587588
epoch 1 iter 14400: train loss 0.58187. lr 3.000000e-04, running loss 0.61003, it/sec: 4.505714309335558
epoch 1 iter 14420: train loss 0.57501. lr 3.000000e-04, running loss 0.60982, it/sec: 4.478419907498216
epoch 1 iter 14440: train loss 0.55739. lr 3.000000e-04, running loss 0.60999, it/sec: 4.419914175804488
epoch 1 iter 14460: train loss 0.58635. lr 3.000000e-04, running loss 0.60984, it/sec: 4.514492901251147
epoch 1 iter 14480: train loss 0.66307. lr 3.000000e-04, running loss 0.60934, it/sec: 4.478704202215345
epoch 1 iter 14500: train loss 0.67471. lr 3.000000e-04, running loss 0.60980, it/sec: 4.5072527503973365
epoch 1 iter 14520: train loss 0.65581. lr 3.000000e-04, running loss 0.60950, it/sec: 4.451962225727118
epoch 1 iter 14540: train loss 0.59196. lr 3.000000e-04, running loss 0.60965, it/sec: 4.477942900900341
epoch 1 iter 14560: train loss 0.61504. lr 3.000000e-04, running loss 0.60948, it/sec: 4.453584804015899
epoch 1 iter 14580: train loss 0.66096. lr 3.000000e-04, running loss 0.60953, it/sec: 4.51960879248001
epoch 1 iter 14600: train loss 0.70044. lr 3.000000e-04, running loss 0.60939, it/sec: 4.447001687646367
epoch 1 iter 14620: train loss 0.56155. lr 3.000000e-04, running loss 0.60907, it/sec: 4.464780647045429
epoch 1 iter 14640: train loss 0.54898. lr 3.000000e-04, running loss 0.60929, it/sec: 4.471931540199954
epoch 1 iter 14660: train loss 0.70380. lr 3.000000e-04, running loss 0.60969, it/sec: 4.457884749739896
epoch 1 iter 14680: train loss 0.65418. lr 3.000000e-04, running loss 0.61135, it/sec: 4.498092210383351
epoch 1 iter 14700: train loss 0.66809. lr 3.000000e-04, running loss 0.61140, it/sec: 4.4590151384856815
epoch 1 iter 14720: train loss 0.63425. lr 3.000000e-04, running loss 0.61164, it/sec: 4.4685388058078646
epoch 1 iter 14740: train loss 0.66400. lr 3.000000e-04, running loss 0.61162, it/sec: 4.4697163197487795
epoch 1 iter 14760: train loss 0.56565. lr 3.000000e-04, running loss 0.61164, it/sec: 4.464861840083721
epoch 1 iter 14780: train loss 0.60711. lr 3.000000e-04, running loss 0.61209, it/sec: 4.509611679977728
epoch 1 iter 14800: train loss 0.64064. lr 3.000000e-04, running loss 0.62054, it/sec: 4.435004566482496
epoch 1 iter 14820: train loss 0.73331. lr 3.000000e-04, running loss 0.62065, it/sec: 4.49028480410694
epoch 1 iter 14840: train loss 0.75035. lr 3.000000e-04, running loss 0.62066, it/sec: 4.45102975297845
epoch 1 iter 14860: train loss 0.60324. lr 3.000000e-04, running loss 0.62008, it/sec: 4.527999314796209
epoch 1 iter 14880: train loss 0.59799. lr 3.000000e-04, running loss 0.61993, it/sec: 4.407152511236761
epoch 1 iter 14900: train loss 0.59559. lr 3.000000e-04, running loss 0.61974, it/sec: 4.488876964828906
epoch 1 iter 14920: train loss 0.70564. lr 3.000000e-04, running loss 0.61936, it/sec: 4.431855453530285
epoch 1 iter 14940: train loss 0.77099. lr 3.000000e-04, running loss 0.61941, it/sec: 4.461544971200684
epoch 1 iter 14960: train loss 0.63886. lr 3.000000e-04, running loss 0.61940, it/sec: 4.498855665318591
epoch 1 iter 14980: train loss 0.65930. lr 3.000000e-04, running loss 0.61978, it/sec: 4.452936332301897
epoch 1 iter 15000: train loss 0.76816. lr 3.000000e-04, running loss 0.61984, it/sec: 4.513425758325187
epoch 1 iter 15020: train loss 0.59576. lr 3.000000e-04, running loss 0.61958, it/sec: 4.429826725930877
epoch 1 iter 15040: train loss 0.58338. lr 3.000000e-04, running loss 0.61936, it/sec: 4.4661134506135785
epoch 1 iter 15060: train loss 0.58408. lr 3.000000e-04, running loss 0.61876, it/sec: 4.480150165679692
epoch 1 iter 15080: train loss 0.65986. lr 3.000000e-04, running loss 0.61871, it/sec: 4.4336416305086415
epoch 1 iter 15100: train loss 0.59979. lr 3.000000e-04, running loss 0.61860, it/sec: 4.5093323545855295
epoch 1 iter 15120: train loss 0.59778. lr 3.000000e-04, running loss 0.61842, it/sec: 4.460971610224377
epoch 1 iter 15140: train loss 0.58291. lr 3.000000e-04, running loss 0.61794, it/sec: 4.474122752267537
epoch 1 iter 15160: train loss 0.55510. lr 3.000000e-04, running loss 0.61758, it/sec: 4.456269959449222
epoch 1 iter 15180: train loss 0.74725. lr 3.000000e-04, running loss 0.61722, it/sec: 4.4953872119484135
epoch 1 iter 15200: train loss 0.66189. lr 3.000000e-04, running loss 0.61685, it/sec: 4.453693399195302
epoch 1 iter 15220: train loss 0.63843. lr 3.000000e-04, running loss 0.61704, it/sec: 4.512065487089643
epoch 1 iter 15240: train loss 1.60764. lr 3.000000e-04, running loss 0.61811, it/sec: 4.443001771531655
epoch 1 iter 15260: train loss 0.66584. lr 3.000000e-04, running loss 0.61844, it/sec: 4.530455586425621
epoch 1 iter 15280: train loss 0.57258. lr 3.000000e-04, running loss 0.61830, it/sec: 4.501617912925345
epoch 1 iter 15300: train loss 0.65393. lr 3.000000e-04, running loss 0.61802, it/sec: 4.510067794941749
epoch 1 iter 15320: train loss 0.62756. lr 3.000000e-04, running loss 0.61819, it/sec: 4.463759868131881
epoch 1 iter 15340: train loss 0.61095. lr 3.000000e-04, running loss 0.61805, it/sec: 4.466669280251414
epoch 1 iter 15360: train loss 0.64792. lr 3.000000e-04, running loss 0.61814, it/sec: 4.522353071652135
epoch 1 iter 15380: train loss 0.72600. lr 3.000000e-04, running loss 0.61779, it/sec: 4.431421678534391
epoch 1 iter 15400: train loss 0.56408. lr 3.000000e-04, running loss 0.61778, it/sec: 4.46725472400124
epoch 1 iter 15420: train loss 0.65064. lr 3.000000e-04, running loss 0.61818, it/sec: 4.464480995302777
epoch 1 iter 15440: train loss 0.50263. lr 3.000000e-04, running loss 0.61783, it/sec: 4.524045834700284
epoch 1 iter 15460: train loss 0.53183. lr 3.000000e-04, running loss 0.61752, it/sec: 4.464628893034077
epoch 1 iter 15480: train loss 0.55354. lr 3.000000e-04, running loss 0.61707, it/sec: 4.514869098366751
epoch 1 iter 15500: train loss 0.61712. lr 3.000000e-04, running loss 0.61645, it/sec: 4.447483518502432
epoch 1 iter 15520: train loss 0.57421. lr 3.000000e-04, running loss 0.61651, it/sec: 4.491848519111541
epoch 1 iter 15540: train loss 0.66844. lr 3.000000e-04, running loss 0.61655, it/sec: 4.459435858020992
epoch 1 iter 15560: train loss 0.60528. lr 3.000000e-04, running loss 0.61620, it/sec: 4.474774145138016
epoch 1 iter 15580: train loss 0.63630. lr 3.000000e-04, running loss 0.61569, it/sec: 4.508961043954146
epoch 1 iter 15600: train loss 0.53887. lr 3.000000e-04, running loss 0.61628, it/sec: 4.45114085991259
epoch 1 iter 15620: train loss 0.51621. lr 3.000000e-04, running loss 0.61602, it/sec: 4.511929372226327
epoch 1 iter 15640: train loss 0.58989. lr 3.000000e-04, running loss 0.61559, it/sec: 4.482377691312297
epoch 1 iter 15660: train loss 0.56193. lr 3.000000e-04, running loss 0.61536, it/sec: 4.485611935072079
epoch 1 iter 15680: train loss 0.55712. lr 3.000000e-04, running loss 0.61568, it/sec: 4.445987359763456
epoch 1 iter 15700: train loss 0.57551. lr 3.000000e-04, running loss 0.61558, it/sec: 4.521013678163668
epoch 1 iter 15720: train loss 0.63304. lr 3.000000e-04, running loss 0.61561, it/sec: 4.4428519677449
epoch 1 iter 15740: train loss 0.52726. lr 3.000000e-04, running loss 0.61544, it/sec: 4.503097550137464
epoch 1 iter 15760: train loss 0.58389. lr 3.000000e-04, running loss 0.61533, it/sec: 4.472626244140072
epoch 1 iter 15780: train loss 0.59536. lr 3.000000e-04, running loss 0.61534, it/sec: 4.513729897340966
epoch 1 iter 15800: train loss 0.50957. lr 3.000000e-04, running loss 0.61501, it/sec: 4.467937115742568
epoch 1 iter 15820: train loss 0.66539. lr 3.000000e-04, running loss 0.61481, it/sec: 4.5174031354360125
epoch 1 iter 15840: train loss 0.51915. lr 3.000000e-04, running loss 0.61481, it/sec: 4.4471373931898315
epoch 1 iter 15860: train loss 0.60739. lr 3.000000e-04, running loss 0.61440, it/sec: 4.51275829816583
epoch 1 iter 15880: train loss 0.60378. lr 3.000000e-04, running loss 0.61414, it/sec: 4.458905368227717
epoch 1 iter 15900: train loss 0.60511. lr 3.000000e-04, running loss 0.61392, it/sec: 4.494724893663497
epoch 1 iter 15920: train loss 0.63688. lr 3.000000e-04, running loss 0.61423, it/sec: 4.485265846546689
epoch 1 iter 15940: train loss 0.59622. lr 3.000000e-04, running loss 0.61421, it/sec: 4.457080743806671
epoch 1 iter 15960: train loss 0.62299. lr 3.000000e-04, running loss 0.61405, it/sec: 4.5091574266033065
epoch 1 iter 15980: train loss 0.74058. lr 3.000000e-04, running loss 0.61472, it/sec: 4.487877041326612
epoch 1 iter 16000: train loss 0.68462. lr 3.000000e-04, running loss 0.61470, it/sec: 4.471048833864408
epoch 1 iter 16020: train loss 0.60909. lr 3.000000e-04, running loss 0.61473, it/sec: 4.430929675212471
epoch 1 iter 16040: train loss 0.58518. lr 3.000000e-04, running loss 0.61458, it/sec: 4.500497622475228
epoch 1 iter 16060: train loss 0.46921. lr 3.000000e-04, running loss 0.61446, it/sec: 4.475978989299715
epoch 1 iter 16080: train loss 0.75764. lr 3.000000e-04, running loss 0.61493, it/sec: 4.510806996366702
epoch 1 iter 16100: train loss 0.57711. lr 3.000000e-04, running loss 0.61495, it/sec: 4.464672745042993
epoch 1 iter 16120: train loss 0.50195. lr 3.000000e-04, running loss 0.61433, it/sec: 4.497753518245317
epoch 1 iter 16140: train loss 0.60745. lr 3.000000e-04, running loss 0.61426, it/sec: 4.452655001665185
epoch 1 iter 16160: train loss 0.62869. lr 3.000000e-04, running loss 0.61402, it/sec: 4.508066160913194
epoch 1 iter 16180: train loss 0.63363. lr 3.000000e-04, running loss 0.61365, it/sec: 4.465353113231157
epoch 1 iter 16200: train loss 0.61346. lr 3.000000e-04, running loss 0.61367, it/sec: 4.457774299475304
epoch 1 iter 16220: train loss 0.63151. lr 3.000000e-04, running loss 0.61341, it/sec: 4.497063727726691
epoch 1 iter 16240: train loss 0.65574. lr 3.000000e-04, running loss 0.61372, it/sec: 4.452000339979931
epoch 1 iter 16260: train loss 0.63585. lr 3.000000e-04, running loss 0.61403, it/sec: 4.5203893975486436
epoch 1 iter 16280: train loss 0.61481. lr 3.000000e-04, running loss 0.61409, it/sec: 4.44530043079129
epoch 1 iter 16300: train loss 0.63760. lr 3.000000e-04, running loss 0.61407, it/sec: 4.524012453721525
epoch 1 iter 16320: train loss 0.79058. lr 3.000000e-04, running loss 0.61412, it/sec: 4.471349728700065
epoch 1 iter 16340: train loss 0.64029. lr 3.000000e-04, running loss 0.61417, it/sec: 4.447997721945022
epoch 1 iter 16360: train loss 0.57086. lr 3.000000e-04, running loss 0.61431, it/sec: 4.487170001050928
epoch 1 iter 16380: train loss 0.56356. lr 3.000000e-04, running loss 0.61406, it/sec: 4.4961974558577555
epoch 1 iter 16400: train loss 0.68567. lr 3.000000e-04, running loss 0.61405, it/sec: 4.445947055332399
epoch 1 iter 16420: train loss 0.57075. lr 3.000000e-04, running loss 0.61397, it/sec: 4.509936744607751
epoch 1 iter 16440: train loss 0.56167. lr 3.000000e-04, running loss 0.61368, it/sec: 4.457351965547168
epoch 1 iter 16460: train loss 0.55155. lr 3.000000e-04, running loss 0.61354, it/sec: 4.480578818827937
epoch 1 iter 16480: train loss 0.57740. lr 3.000000e-04, running loss 0.61332, it/sec: 4.509630614070842
epoch 1 iter 16500: train loss 0.53019. lr 3.000000e-04, running loss 0.61306, it/sec: 4.476768783400961
epoch 1 iter 16520: train loss 0.56389. lr 3.000000e-04, running loss 0.61240, it/sec: 4.510408425988069
epoch 1 iter 16540: train loss 0.62492. lr 3.000000e-04, running loss 0.61231, it/sec: 4.471419284428961
epoch 1 iter 16560: train loss 0.64475. lr 3.000000e-04, running loss 0.61247, it/sec: 4.527125429568645
epoch 1 iter 16580: train loss 0.54659. lr 3.000000e-04, running loss 0.61220, it/sec: 4.455846123810801
epoch 1 iter 16600: train loss 0.64175. lr 3.000000e-04, running loss 0.61229, it/sec: 4.510670448171309
epoch 1 iter 16620: train loss 0.56743. lr 3.000000e-04, running loss 0.61198, it/sec: 4.456342741206212
epoch 1 iter 16640: train loss 0.57172. lr 3.000000e-04, running loss 0.61196, it/sec: 4.487451421365337
epoch 1 iter 16660: train loss 0.70340. lr 3.000000e-04, running loss 0.61177, it/sec: 4.47587962111799
epoch 1 iter 16680: train loss 0.68222. lr 3.000000e-04, running loss 0.61170, it/sec: 4.5179694377373885
epoch 1 iter 16700: train loss 0.56139. lr 3.000000e-04, running loss 0.61161, it/sec: 4.4465799882897725
epoch 1 iter 16720: train loss 0.58250. lr 3.000000e-04, running loss 0.61165, it/sec: 4.5200991107736
epoch 1 iter 16740: train loss 0.60708. lr 3.000000e-04, running loss 0.61198, it/sec: 4.428460811509508
epoch 1 iter 16760: train loss 0.59502. lr 3.000000e-04, running loss 0.61194, it/sec: 4.492607533221088
epoch 1 iter 16780: train loss 0.64947. lr 3.000000e-04, running loss 0.61156, it/sec: 4.438652043131446
epoch 1 iter 16800: train loss 0.50523. lr 3.000000e-04, running loss 0.61127, it/sec: 4.4904575044048585
epoch 1 iter 16820: train loss 0.55128. lr 3.000000e-04, running loss 0.61119, it/sec: 4.501157365887393
epoch 1 iter 16840: train loss 0.58912. lr 3.000000e-04, running loss 0.61117, it/sec: 4.480413984141043
epoch 1 iter 16860: train loss 0.59014. lr 3.000000e-04, running loss 0.61112, it/sec: 4.509198823701911
epoch 1 iter 16880: train loss 0.55524. lr 3.000000e-04, running loss 0.61089, it/sec: 4.464707489626244
epoch 1 iter 16900: train loss 0.58932. lr 3.000000e-04, running loss 0.61068, it/sec: 4.494536815284493
epoch 1 iter 16920: train loss 0.61421. lr 3.000000e-04, running loss 0.61087, it/sec: 4.496315701067692
epoch 1 iter 16940: train loss 0.57969. lr 3.000000e-04, running loss 0.61083, it/sec: 4.489720260047519
epoch 1 iter 16960: train loss 0.57299. lr 3.000000e-04, running loss 0.61091, it/sec: 4.513513416519739
epoch 1 iter 16980: train loss 0.63144. lr 3.000000e-04, running loss 0.61094, it/sec: 4.495173031529967
epoch 1 iter 17000: train loss 0.65929. lr 3.000000e-04, running loss 0.61119, it/sec: 4.491681098546184
epoch 1 iter 17020: train loss 0.58943. lr 3.000000e-04, running loss 0.61228, it/sec: 4.505055846205415
epoch 1 iter 17040: train loss 0.57896. lr 3.000000e-04, running loss 0.61229, it/sec: 4.473686287526575
epoch 1 iter 17060: train loss 0.62214. lr 3.000000e-04, running loss 0.61236, it/sec: 4.49880686753052
epoch 1 iter 17080: train loss 0.84103. lr 3.000000e-04, running loss 0.61276, it/sec: 4.45936229920777
epoch 1 iter 17100: train loss 0.68503. lr 3.000000e-04, running loss 0.61271, it/sec: 4.515844440180459
epoch 1 iter 17120: train loss 0.61959. lr 3.000000e-04, running loss 0.61258, it/sec: 4.45506805884776
epoch 1 iter 17140: train loss 0.65489. lr 3.000000e-04, running loss 0.61264, it/sec: 4.505316171689361
epoch 1 iter 17160: train loss 0.59071. lr 3.000000e-04, running loss 0.61229, it/sec: 4.505829543451596
epoch 1 iter 17180: train loss 0.58210. lr 3.000000e-04, running loss 0.61265, it/sec: 4.486365401889349
epoch 1 iter 17200: train loss 0.62837. lr 3.000000e-04, running loss 0.61250, it/sec: 4.486937456781345
epoch 1 iter 17220: train loss 0.65763. lr 3.000000e-04, running loss 0.61244, it/sec: 4.501932664404827
epoch 1 iter 17240: train loss 0.56043. lr 3.000000e-04, running loss 0.61241, it/sec: 4.422608688529653
epoch 1 iter 17260: train loss 0.69749. lr 3.000000e-04, running loss 0.61223, it/sec: 4.517924122625393
epoch 1 iter 17280: train loss 0.56651. lr 3.000000e-04, running loss 0.61240, it/sec: 4.4518596203302225
epoch 1 iter 17300: train loss 0.55309. lr 3.000000e-04, running loss 0.61210, it/sec: 4.4372723531193925
epoch 1 iter 17320: train loss 0.54956. lr 3.000000e-04, running loss 0.61191, it/sec: 4.500489439288233
epoch 1 iter 17340: train loss 0.59923. lr 3.000000e-04, running loss 0.61162, it/sec: 4.440575794544824
epoch 1 iter 17360: train loss 0.61324. lr 3.000000e-04, running loss 0.61124, it/sec: 4.505756251824793
epoch 1 iter 17380: train loss 0.57418. lr 3.000000e-04, running loss 0.61203, it/sec: 4.432056767391707
epoch 1 iter 17400: train loss 0.63590. lr 3.000000e-04, running loss 0.61283, it/sec: 4.468337239308835
epoch 1 iter 17420: train loss 0.67790. lr 3.000000e-04, running loss 0.61289, it/sec: 4.470691416563945
epoch 1 iter 17440: train loss 0.65632. lr 3.000000e-04, running loss 0.61298, it/sec: 4.473367408145416
epoch 1 iter 17460: train loss 0.52895. lr 3.000000e-04, running loss 0.61283, it/sec: 4.466829035613116
epoch 1 iter 17480: train loss 0.61606. lr 3.000000e-04, running loss 0.61294, it/sec: 4.442425273403233
epoch 1 iter 17500: train loss 0.57285. lr 3.000000e-04, running loss 0.61253, it/sec: 4.497151560257176
epoch 1 iter 17520: train loss 0.61311. lr 3.000000e-04, running loss 0.61262, it/sec: 4.4477156907767155
epoch 1 iter 17540: train loss 0.64804. lr 3.000000e-04, running loss 0.61263, it/sec: 4.502439285161435
epoch 1 iter 17560: train loss 0.55467. lr 3.000000e-04, running loss 0.61275, it/sec: 4.437252447065017
epoch 1 iter 17580: train loss 0.56075. lr 3.000000e-04, running loss 0.61269, it/sec: 4.51721250114444
epoch 1 iter 17600: train loss 0.69760. lr 3.000000e-04, running loss 0.61256, it/sec: 4.485521474974595
epoch 1 iter 17620: train loss 0.57787. lr 3.000000e-04, running loss 0.61213, it/sec: 4.436652696052274
epoch 1 iter 17640: train loss 0.60830. lr 3.000000e-04, running loss 0.61266, it/sec: 4.513973458195715
epoch 1 iter 17660: train loss 0.57037. lr 3.000000e-04, running loss 0.61223, it/sec: 4.468756245495317
epoch 1 iter 17680: train loss 0.53219. lr 3.000000e-04, running loss 0.61215, it/sec: 4.502461238858624
epoch 1 iter 17700: train loss 0.69048. lr 3.000000e-04, running loss 0.61225, it/sec: 4.4322154697123235
epoch 1 iter 17720: train loss 0.68810. lr 3.000000e-04, running loss 0.61222, it/sec: 4.493716548645505
epoch 1 iter 17740: train loss 0.55749. lr 3.000000e-04, running loss 0.61167, it/sec: 4.457227812803889
epoch 1 iter 17760: train loss 0.55208. lr 3.000000e-04, running loss 0.61188, it/sec: 4.486834138721406
epoch 1 iter 17780: train loss 0.59129. lr 3.000000e-04, running loss 0.61138, it/sec: 4.5011938564402545
epoch 1 iter 17800: train loss 0.71005. lr 3.000000e-04, running loss 0.61124, it/sec: 4.448838018662294
epoch 1 iter 17820: train loss 0.58302. lr 3.000000e-04, running loss 0.61139, it/sec: 4.4930860136644295
epoch 1 iter 17840: train loss 0.55959. lr 3.000000e-04, running loss 0.61103, it/sec: 4.516426160918539
epoch 1 iter 17860: train loss 0.53274. lr 3.000000e-04, running loss 0.61093, it/sec: 4.471617330173938
epoch 1 iter 17880: train loss 0.59323. lr 3.000000e-04, running loss 0.61089, it/sec: 4.497118272440358
epoch 1 iter 17900: train loss 0.68829. lr 3.000000e-04, running loss 0.61108, it/sec: 4.479074920550265
epoch 1 iter 17920: train loss 0.62538. lr 3.000000e-04, running loss 0.61125, it/sec: 4.462320739493424
epoch 1 iter 17940: train loss 0.57651. lr 3.000000e-04, running loss 0.61116, it/sec: 4.511746487734281
epoch 1 iter 17960: train loss 0.63834. lr 3.000000e-04, running loss 0.61170, it/sec: 4.455428164621542
epoch 1 iter 17980: train loss 0.70045. lr 3.000000e-04, running loss 0.61163, it/sec: 4.500082140221373
epoch 1 iter 18000: train loss 0.55074. lr 3.000000e-04, running loss 0.61158, it/sec: 4.46668178990559
epoch 1 iter 18020: train loss 0.58248. lr 3.000000e-04, running loss 0.61130, it/sec: 4.4734963045168135
epoch 1 iter 18040: train loss 0.65162. lr 3.000000e-04, running loss 0.61120, it/sec: 4.461937301156182
epoch 1 iter 18060: train loss 0.68325. lr 3.000000e-04, running loss 0.61107, it/sec: 4.437099821961047
epoch 1 iter 18080: train loss 0.60169. lr 3.000000e-04, running loss 0.61120, it/sec: 4.497574046503069
epoch 1 iter 18100: train loss 0.57931. lr 3.000000e-04, running loss 0.61081, it/sec: 4.466080241048383
epoch 1 iter 18120: train loss 0.50113. lr 3.000000e-04, running loss 0.61119, it/sec: 4.485147878525751
epoch 1 iter 18140: train loss 0.60397. lr 3.000000e-04, running loss 0.61135, it/sec: 4.448090672302279
epoch 1 iter 18160: train loss 0.65448. lr 3.000000e-04, running loss 0.61118, it/sec: 4.508037221788579
epoch 1 iter 18180: train loss 0.59827. lr 3.000000e-04, running loss 0.61108, it/sec: 4.443003212421557
epoch 1 iter 18200: train loss 0.52402. lr 3.000000e-04, running loss 0.61051, it/sec: 4.5070665486046195
epoch 1 iter 18220: train loss 0.55925. lr 3.000000e-04, running loss 0.61075, it/sec: 4.489011953914138
epoch 1 iter 18240: train loss 0.69407. lr 3.000000e-04, running loss 0.61089, it/sec: 4.449705381248173
epoch 1 iter 18260: train loss 0.63117. lr 3.000000e-04, running loss 0.61101, it/sec: 4.504642747628468
epoch 1 iter 18280: train loss 0.60113. lr 3.000000e-04, running loss 0.61081, it/sec: 4.440627084842473
epoch 1 iter 18300: train loss 0.53031. lr 3.000000e-04, running loss 0.61128, it/sec: 4.47357455313093
epoch 1 iter 18320: train loss 0.62975. lr 3.000000e-04, running loss 0.61132, it/sec: 4.513098643381876
epoch 1 iter 18340: train loss 0.61159. lr 3.000000e-04, running loss 0.61129, it/sec: 4.427344074737523
epoch 1 iter 18360: train loss 0.56328. lr 3.000000e-04, running loss 0.61117, it/sec: 4.503746536276975
epoch 1 iter 18380: train loss 0.57750. lr 3.000000e-04, running loss 0.61105, it/sec: 4.441596591673796
epoch 1 iter 18400: train loss 0.63826. lr 3.000000e-04, running loss 0.61109, it/sec: 4.493265269592974
epoch 1 iter 18420: train loss 0.59681. lr 3.000000e-04, running loss 0.61139, it/sec: 4.475539358284507
epoch 1 iter 18440: train loss 0.64835. lr 3.000000e-04, running loss 0.61116, it/sec: 4.492503691899918
epoch 1 iter 18460: train loss 0.54085. lr 3.000000e-04, running loss 0.61161, it/sec: 4.419859906091499
epoch 1 iter 18480: train loss 0.58497. lr 3.000000e-04, running loss 0.61175, it/sec: 4.521359746261528
epoch 1 iter 18500: train loss 0.66646. lr 3.000000e-04, running loss 0.61148, it/sec: 4.494541057736818
epoch 1 iter 18520: train loss 0.58709. lr 3.000000e-04, running loss 0.61134, it/sec: 4.481925312196396
epoch 1 iter 18540: train loss 0.56869. lr 3.000000e-04, running loss 0.61112, it/sec: 4.498680739913166
epoch 1 iter 18560: train loss 0.72294. lr 3.000000e-04, running loss 0.61110, it/sec: 4.4654853354981885
epoch 1 iter 18580: train loss 0.57613. lr 3.000000e-04, running loss 0.61116, it/sec: 4.523254985664457
epoch 1 iter 18600: train loss 0.66017. lr 3.000000e-04, running loss 0.61123, it/sec: 4.454821941457084
epoch 1 iter 18620: train loss 0.55169. lr 3.000000e-04, running loss 0.61104, it/sec: 4.500039897819933
epoch 1 iter 18640: train loss 0.79002. lr 3.000000e-04, running loss 0.61092, it/sec: 4.4619069603623505
epoch 1 iter 18660: train loss 0.66790. lr 3.000000e-04, running loss 0.61128, it/sec: 4.506872521114341
epoch 1 iter 18680: train loss 0.66070. lr 3.000000e-04, running loss 0.61139, it/sec: 4.450086679722934
epoch 1 iter 18700: train loss 0.66252. lr 3.000000e-04, running loss 0.61140, it/sec: 4.505659779240392
epoch 1 iter 18720: train loss 0.64042. lr 3.000000e-04, running loss 0.61194, it/sec: 4.449864003803358
epoch 1 iter 18740: train loss 0.62320. lr 3.000000e-04, running loss 0.61205, it/sec: 4.517523130628851
epoch 1 iter 18760: train loss 0.60053. lr 3.000000e-04, running loss 0.61184, it/sec: 4.49214705425512
epoch 1 iter 18780: train loss 0.68333. lr 3.000000e-04, running loss 0.61204, it/sec: 4.497053494633652
epoch 1 iter 18800: train loss 0.66703. lr 3.000000e-04, running loss 0.61171, it/sec: 4.461357351463599
epoch 1 iter 18820: train loss 0.57444. lr 3.000000e-04, running loss 0.61183, it/sec: 4.489305556931254
epoch 1 iter 18840: train loss 0.59097. lr 3.000000e-04, running loss 0.61217, it/sec: 4.423068305306149
epoch 1 iter 18860: train loss 0.60604. lr 3.000000e-04, running loss 0.61197, it/sec: 4.511977925416405
epoch 1 iter 18880: train loss 0.57980. lr 3.000000e-04, running loss 0.61165, it/sec: 4.483497701837616
epoch 1 iter 18900: train loss 0.63808. lr 3.000000e-04, running loss 0.61151, it/sec: 4.532838009659884
epoch 1 iter 18920: train loss 0.78805. lr 3.000000e-04, running loss 0.61159, it/sec: 4.425119298647436
epoch 1 iter 18940: train loss 0.63237. lr 3.000000e-04, running loss 0.61150, it/sec: 4.532730285157954
epoch 1 iter 18960: train loss 0.64557. lr 3.000000e-04, running loss 0.61156, it/sec: 4.429579955140003
epoch 1 iter 18980: train loss 0.58722. lr 3.000000e-04, running loss 0.61139, it/sec: 4.502489052689115
epoch 1 iter 19000: train loss 0.65173. lr 3.000000e-04, running loss 0.61139, it/sec: 4.439992375343069
epoch 1 iter 19020: train loss 0.68843. lr 3.000000e-04, running loss 0.61131, it/sec: 4.506187260185897
epoch 1 iter 19040: train loss 0.54399. lr 3.000000e-04, running loss 0.61121, it/sec: 4.441267378964431
epoch 1 iter 19060: train loss 0.56309. lr 3.000000e-04, running loss 0.61147, it/sec: 4.515356594367145
epoch 1 iter 19080: train loss 0.69513. lr 3.000000e-04, running loss 0.61196, it/sec: 4.430455939675818
epoch 1 iter 19100: train loss 0.65494. lr 3.000000e-04, running loss 0.61169, it/sec: 4.538710722995153
epoch 1 iter 19120: train loss 0.66194. lr 3.000000e-04, running loss 0.61218, it/sec: 4.444057179535461
epoch 1 iter 19140: train loss 0.50767. lr 3.000000e-04, running loss 0.61174, it/sec: 4.4783534223444486
epoch 1 iter 19160: train loss 0.58291. lr 3.000000e-04, running loss 0.61175, it/sec: 4.466384675518661
epoch 1 iter 19180: train loss 0.62531. lr 3.000000e-04, running loss 0.61134, it/sec: 4.473498445533383
epoch 1 iter 19200: train loss 0.59611. lr 3.000000e-04, running loss 0.61085, it/sec: 4.501978144165712
epoch 1 iter 19220: train loss 0.55884. lr 3.000000e-04, running loss 0.61063, it/sec: 4.463246036534728
epoch 1 iter 19240: train loss 0.63353. lr 3.000000e-04, running loss 0.61061, it/sec: 4.51953717658071
epoch 1 iter 19260: train loss 0.64887. lr 3.000000e-04, running loss 0.61047, it/sec: 4.4643543139962665
epoch 1 iter 19280: train loss 0.64679. lr 3.000000e-04, running loss 0.61010, it/sec: 4.532274443854166
epoch 1 iter 19300: train loss 0.54934. lr 3.000000e-04, running loss 0.60982, it/sec: 4.448474743074592
epoch 1 iter 19320: train loss 0.63519. lr 3.000000e-04, running loss 0.60953, it/sec: 4.51057348081885
epoch 1 iter 19340: train loss 0.59317. lr 3.000000e-04, running loss 0.60974, it/sec: 4.458542176566407
epoch 1 iter 19360: train loss 0.63742. lr 3.000000e-04, running loss 0.60987, it/sec: 4.516604303651103
epoch 1 iter 19380: train loss 0.62789. lr 3.000000e-04, running loss 0.60980, it/sec: 4.438385516273978
epoch 1 iter 19400: train loss 0.54493. lr 3.000000e-04, running loss 0.60976, it/sec: 4.477451941447041
epoch 1 iter 19420: train loss 0.55405. lr 3.000000e-04, running loss 0.60965, it/sec: 4.4957832318800435
epoch 1 iter 19440: train loss 0.67382. lr 3.000000e-04, running loss 0.60990, it/sec: 4.463428775430272
epoch 1 iter 19460: train loss 0.61786. lr 3.000000e-04, running loss 0.61026, it/sec: 4.509744706149011
epoch 1 iter 19480: train loss 0.60318. lr 3.000000e-04, running loss 0.61013, it/sec: 4.462317812897179
epoch 1 iter 19500: train loss 0.59281. lr 3.000000e-04, running loss 0.61062, it/sec: 4.495499856289446
epoch 1 iter 19520: train loss 0.53690. lr 3.000000e-04, running loss 0.61054, it/sec: 4.452499471141796
epoch 1 iter 19540: train loss 0.58496. lr 3.000000e-04, running loss 0.61046, it/sec: 4.515131538222244
epoch 1 iter 19560: train loss 0.66428. lr 3.000000e-04, running loss 0.61040, it/sec: 4.468984292163039
epoch 1 iter 19580: train loss 0.62637. lr 3.000000e-04, running loss 0.61045, it/sec: 4.523610768596096
epoch 1 iter 19600: train loss 0.60633. lr 3.000000e-04, running loss 0.61035, it/sec: 4.445110618598592
epoch 1 iter 19620: train loss 0.57512. lr 3.000000e-04, running loss 0.60991, it/sec: 4.523582570515858
epoch 1 iter 19640: train loss 0.72976. lr 3.000000e-04, running loss 0.61021, it/sec: 4.48566909991168
epoch 1 iter 19660: train loss 0.66115. lr 3.000000e-04, running loss 0.60987, it/sec: 4.503613701985062
epoch 1 iter 19680: train loss 0.58105. lr 3.000000e-04, running loss 0.60979, it/sec: 4.45961850383767
epoch 1 iter 19700: train loss 0.59204. lr 3.000000e-04, running loss 0.60965, it/sec: 4.51594179929862
epoch 1 iter 19720: train loss 0.63436. lr 3.000000e-04, running loss 0.61002, it/sec: 4.463506513369124
epoch 1 iter 19740: train loss 0.71044. lr 3.000000e-04, running loss 0.61030, it/sec: 4.5144581319667445
epoch 1 iter 19760: train loss 0.60701. lr 3.000000e-04, running loss 0.61017, it/sec: 4.4649981609395395
epoch 1 iter 19780: train loss 0.59949. lr 3.000000e-04, running loss 0.61027, it/sec: 4.514844006246408
epoch 1 iter 19800: train loss 0.61784. lr 3.000000e-04, running loss 0.61068, it/sec: 4.481106467417162
epoch 1 iter 19820: train loss 0.70188. lr 3.000000e-04, running loss 0.61112, it/sec: 4.524100380660915
epoch 1 iter 19840: train loss 0.70295. lr 3.000000e-04, running loss 0.61100, it/sec: 4.4414086916593085
epoch 1 iter 19860: train loss 0.61923. lr 3.000000e-04, running loss 0.61055, it/sec: 4.5029231680905255
epoch 1 iter 19880: train loss 0.52691. lr 3.000000e-04, running loss 0.61040, it/sec: 4.467570135900184
epoch 1 iter 19900: train loss 0.56283. lr 3.000000e-04, running loss 0.61037, it/sec: 4.502583117926094
epoch 1 iter 19920: train loss 0.57881. lr 3.000000e-04, running loss 0.61038, it/sec: 4.452360920386774
epoch 1 iter 19940: train loss 0.63312. lr 3.000000e-04, running loss 0.61047, it/sec: 4.526986866950888
epoch 1 iter 19960: train loss 0.72671. lr 3.000000e-04, running loss 0.61069, it/sec: 4.495466208259458
epoch 1 iter 19980: train loss 0.60559. lr 3.000000e-04, running loss 0.61003, it/sec: 4.5224167375094515
epoch 1 iter 20000: train loss 0.64108. lr 3.000000e-04, running loss 0.61068, it/sec: 4.470659776926743
epoch 1 iter 20020: train loss 0.63171. lr 3.000000e-04, running loss 0.61083, it/sec: 4.521160398000085
epoch 1 iter 20040: train loss 0.63454. lr 3.000000e-04, running loss 0.61106, it/sec: 4.464860964005138
epoch 1 iter 20060: train loss 0.71356. lr 3.000000e-04, running loss 0.61148, it/sec: 4.510258924306345
epoch 1 iter 20080: train loss 0.61743. lr 3.000000e-04, running loss 0.61115, it/sec: 4.4744397570832435
epoch 1 iter 20100: train loss 0.75478. lr 3.000000e-04, running loss 0.61137, it/sec: 4.499418094967161
epoch 1 iter 20120: train loss 0.56689. lr 3.000000e-04, running loss 0.61142, it/sec: 4.461816437576074
epoch 1 iter 20140: train loss 0.57571. lr 3.000000e-04, running loss 0.61126, it/sec: 4.51611698696038
epoch 1 iter 20160: train loss 0.68869. lr 3.000000e-04, running loss 0.61115, it/sec: 4.461889500281255
epoch 1 iter 20180: train loss 0.77701. lr 3.000000e-04, running loss 0.61155, it/sec: 4.4935337648301426
epoch 1 iter 20200: train loss 0.68443. lr 3.000000e-04, running loss 0.61154, it/sec: 4.431895542887575
epoch 1 iter 20220: train loss 0.54224. lr 3.000000e-04, running loss 0.61116, it/sec: 4.4976937794820735
epoch 1 iter 20240: train loss 0.63964. lr 3.000000e-04, running loss 0.61115, it/sec: 4.461855198173022
epoch 1 iter 20260: train loss 0.63912. lr 3.000000e-04, running loss 0.61104, it/sec: 4.530550516793878
epoch 1 iter 20280: train loss 0.59137. lr 3.000000e-04, running loss 0.61087, it/sec: 4.44844654439281
epoch 1 iter 20300: train loss 0.60541. lr 3.000000e-04, running loss 0.61090, it/sec: 4.516569605140352
epoch 1 iter 20320: train loss 0.59606. lr 3.000000e-04, running loss 0.61061, it/sec: 4.479830164433888
epoch 1 iter 20340: train loss 0.68260. lr 3.000000e-04, running loss 0.61067, it/sec: 4.51675783866997
epoch 1 iter 20360: train loss 0.75682. lr 3.000000e-04, running loss 0.61110, it/sec: 4.454937147044561
epoch 1 iter 20380: train loss 0.62933. lr 3.000000e-04, running loss 0.61206, it/sec: 4.49558233279516
epoch 1 iter 20400: train loss 0.60287. lr 3.000000e-04, running loss 0.61185, it/sec: 4.503594088779293
epoch 1 iter 20420: train loss 0.65900. lr 3.000000e-04, running loss 0.61230, it/sec: 4.467584347967735
epoch 1 iter 20440: train loss 0.64859. lr 3.000000e-04, running loss 0.61263, it/sec: 4.4968770920477965
epoch 1 iter 20460: train loss 0.58002. lr 3.000000e-04, running loss 0.61261, it/sec: 4.4648012185777555
epoch 1 iter 20480: train loss 0.58505. lr 3.000000e-04, running loss 0.61312, it/sec: 4.494886702229222
epoch 1 iter 20500: train loss 0.50193. lr 3.000000e-04, running loss 0.61249, it/sec: 4.462754451334354
epoch 1 iter 20520: train loss 0.60715. lr 3.000000e-04, running loss 0.61254, it/sec: 4.495299649459385
epoch 1 iter 20540: train loss 0.63643. lr 3.000000e-04, running loss 0.61254, it/sec: 4.513035117498699
epoch 1 iter 20560: train loss 0.59343. lr 3.000000e-04, running loss 0.61248, it/sec: 4.479991403524682
epoch 1 iter 20580: train loss 0.54036. lr 3.000000e-04, running loss 0.61232, it/sec: 4.5054205258212585
epoch 1 iter 20600: train loss 0.51301. lr 3.000000e-04, running loss 0.61217, it/sec: 4.4888042647096436
epoch 1 iter 20620: train loss 0.59188. lr 3.000000e-04, running loss 0.61194, it/sec: 4.49795455137443
epoch 1 iter 20640: train loss 0.53992. lr 3.000000e-04, running loss 0.61175, it/sec: 4.488860623077202
epoch 1 iter 20660: train loss 0.54442. lr 3.000000e-04, running loss 0.61169, it/sec: 4.466662696801136
epoch 1 iter 20680: train loss 0.91873. lr 3.000000e-04, running loss 0.61246, it/sec: 4.51063287059214
epoch 1 iter 20700: train loss 0.52278. lr 3.000000e-04, running loss 0.61194, it/sec: 4.473169868898053
epoch 1 iter 20720: train loss 0.57572. lr 3.000000e-04, running loss 0.61146, it/sec: 4.5101503391673585
epoch 1 iter 20740: train loss 0.63153. lr 3.000000e-04, running loss 0.61187, it/sec: 4.455203642506387
epoch 1 iter 20760: train loss 0.60735. lr 3.000000e-04, running loss 0.61198, it/sec: 4.516265857414642
epoch 1 iter 20780: train loss 0.84733. lr 3.000000e-04, running loss 0.61214, it/sec: 4.462922630087001
epoch 1 iter 20800: train loss 0.58949. lr 3.000000e-04, running loss 0.61206, it/sec: 4.53040253099916
epoch 1 iter 20820: train loss 0.75890. lr 3.000000e-04, running loss 0.61305, it/sec: 4.458356239329338
epoch 1 iter 20840: train loss 0.57277. lr 3.000000e-04, running loss 0.61258, it/sec: 4.512456591800423
epoch 1 iter 20860: train loss 0.73366. lr 3.000000e-04, running loss 0.61249, it/sec: 4.473289468448763
epoch 1 iter 20880: train loss 0.50834. lr 3.000000e-04, running loss 0.61289, it/sec: 4.500668718143849
epoch 1 iter 20900: train loss 0.84726. lr 3.000000e-04, running loss 0.61285, it/sec: 4.433518539922551
epoch 1 iter 20920: train loss 0.57577. lr 3.000000e-04, running loss 0.61282, it/sec: 4.509147971583263
epoch 1 iter 20940: train loss 0.60282. lr 3.000000e-04, running loss 0.61255, it/sec: 4.4774864627815
epoch 1 iter 20960: train loss 0.57567. lr 3.000000e-04, running loss 0.61245, it/sec: 4.514339338678905
epoch 1 iter 20980: train loss 0.54360. lr 3.000000e-04, running loss 0.61195, it/sec: 4.46012238889697
epoch 1 iter 21000: train loss 0.58143. lr 3.000000e-04, running loss 0.61211, it/sec: 4.495868649547874
epoch 1 iter 21020: train loss 0.60630. lr 3.000000e-04, running loss 0.61214, it/sec: 4.453552037965208
epoch 1 iter 21040: train loss 0.62264. lr 3.000000e-04, running loss 0.61231, it/sec: 4.522843453351378
epoch 1 iter 21060: train loss 0.69807. lr 3.000000e-04, running loss 0.61255, it/sec: 4.489712842292499
epoch 1 iter 21080: train loss 0.52469. lr 3.000000e-04, running loss 0.61261, it/sec: 4.502808933490085
epoch 1 iter 21100: train loss 0.63422. lr 3.000000e-04, running loss 0.61265, it/sec: 4.4668293143471995
epoch 1 iter 21120: train loss 0.68680. lr 3.000000e-04, running loss 0.61248, it/sec: 4.495683911833154
epoch 1 iter 21140: train loss 0.60379. lr 3.000000e-04, running loss 0.61258, it/sec: 4.446602686182388
epoch 1 iter 21160: train loss 0.67521. lr 3.000000e-04, running loss 0.61273, it/sec: 4.5114673444671185
epoch 1 iter 21180: train loss 0.56513. lr 3.000000e-04, running loss 0.61261, it/sec: 4.423214684755121
epoch 1 iter 21200: train loss 1.18576. lr 3.000000e-04, running loss 0.61275, it/sec: 4.521153980139145
epoch 1 iter 21220: train loss 0.54576. lr 3.000000e-04, running loss 0.61263, it/sec: 4.472218151545697
epoch 1 iter 21240: train loss 0.65615. lr 3.000000e-04, running loss 0.61282, it/sec: 4.526818907802292
epoch 1 iter 21260: train loss 0.52894. lr 3.000000e-04, running loss 0.61257, it/sec: 4.456856850581984
epoch 1 iter 21280: train loss 0.60774. lr 3.000000e-04, running loss 0.61274, it/sec: 4.492388835291873
epoch 1 iter 21300: train loss 0.64099. lr 3.000000e-04, running loss 0.61319, it/sec: 4.526925529629762
epoch 1 iter 21320: train loss 0.55102. lr 3.000000e-04, running loss 0.61296, it/sec: 4.42890118634541
epoch 1 iter 21340: train loss 0.64185. lr 3.000000e-04, running loss 0.61348, it/sec: 4.502438919366627
epoch 1 iter 21360: train loss 0.56563. lr 3.000000e-04, running loss 0.61347, it/sec: 4.466155377756446
epoch 1 iter 21380: train loss 0.64785. lr 3.000000e-04, running loss 0.61301, it/sec: 4.487177893268883
epoch 1 iter 21400: train loss 0.67234. lr 3.000000e-04, running loss 0.61310, it/sec: 4.455787532367078
epoch 1 iter 21420: train loss 0.67598. lr 3.000000e-04, running loss 0.61271, it/sec: 4.493020646937348
epoch 1 iter 21440: train loss 0.70595. lr 3.000000e-04, running loss 0.61268, it/sec: 4.49121788358313
epoch 1 iter 21460: train loss 0.64179. lr 3.000000e-04, running loss 0.61228, it/sec: 4.473257171222615
epoch 1 iter 21480: train loss 0.51928. lr 3.000000e-04, running loss 0.61227, it/sec: 4.486103739245134
epoch 1 iter 21500: train loss 0.56041. lr 3.000000e-04, running loss 0.61221, it/sec: 4.465805363899858
epoch 1 iter 21520: train loss 0.66493. lr 3.000000e-04, running loss 0.61204, it/sec: 4.449374944691557
epoch 1 iter 21540: train loss 0.60813. lr 3.000000e-04, running loss 0.61215, it/sec: 4.504628056674728
epoch 1 iter 21560: train loss 0.59572. lr 3.000000e-04, running loss 0.61194, it/sec: 4.470433258767882
epoch 1 iter 21580: train loss 0.56323. lr 3.000000e-04, running loss 0.61222, it/sec: 4.5268306902777
epoch 1 iter 21600: train loss 0.50297. lr 3.000000e-04, running loss 0.61252, it/sec: 4.44409954313375
epoch 1 iter 21620: train loss 0.65050. lr 3.000000e-04, running loss 0.61264, it/sec: 4.489585752805873
epoch 1 iter 21640: train loss 0.55762. lr 3.000000e-04, running loss 0.61293, it/sec: 4.472931992132428
epoch 1 iter 21660: train loss 0.58909. lr 3.000000e-04, running loss 0.61255, it/sec: 4.480085496078326
epoch 1 iter 21680: train loss 0.76814. lr 3.000000e-04, running loss 0.61246, it/sec: 4.4578500904438245
epoch 1 iter 21700: train loss 0.58622. lr 3.000000e-04, running loss 0.61253, it/sec: 4.507048347841212
epoch 1 iter 21720: train loss 0.60218. lr 3.000000e-04, running loss 0.61212, it/sec: 4.4467153124512535
epoch 1 iter 21740: train loss 0.68967. lr 3.000000e-04, running loss 0.61226, it/sec: 4.502216302952471
epoch 1 iter 21760: train loss 0.57696. lr 3.000000e-04, running loss 0.61227, it/sec: 4.459149112973127
epoch 1 iter 21780: train loss 0.67291. lr 3.000000e-04, running loss 0.61214, it/sec: 4.515365402544533
epoch 1 iter 21800: train loss 0.56190. lr 3.000000e-04, running loss 0.61223, it/sec: 4.455052617372678
epoch 1 iter 21820: train loss 0.59257. lr 3.000000e-04, running loss 0.61242, it/sec: 4.513994262562404
epoch 1 iter 21840: train loss 0.56868. lr 3.000000e-04, running loss 0.61206, it/sec: 4.468903927924686
epoch 1 iter 21860: train loss 0.58049. lr 3.000000e-04, running loss 0.61255, it/sec: 4.487246957806427
epoch 1 iter 21880: train loss 0.47502. lr 3.000000e-04, running loss 0.61204, it/sec: 4.487531366287291
epoch 1 iter 21900: train loss 0.59009. lr 3.000000e-04, running loss 0.61164, it/sec: 4.5194613161163115
epoch 1 iter 21920: train loss 0.55405. lr 3.000000e-04, running loss 0.61135, it/sec: 4.4788966549200255
epoch 1 iter 21940: train loss 0.71849. lr 3.000000e-04, running loss 0.61210, it/sec: 4.507337000914738
epoch 1 iter 21960: train loss 0.70664. lr 3.000000e-04, running loss 0.61226, it/sec: 4.469673826849092
epoch 1 iter 21980: train loss 0.55458. lr 3.000000e-04, running loss 0.61224, it/sec: 4.5210543128832335
epoch 1 iter 22000: train loss 0.58582. lr 3.000000e-04, running loss 0.61203, it/sec: 4.464792367539315
epoch 1 iter 22020: train loss 0.71306. lr 3.000000e-04, running loss 0.61465, it/sec: 4.484861034770868
epoch 1 iter 22040: train loss 0.64117. lr 3.000000e-04, running loss 0.61465, it/sec: 4.46757293113824
epoch 1 iter 22060: train loss 0.64346. lr 3.000000e-04, running loss 0.61461, it/sec: 4.528872552516061
epoch 1 iter 22080: train loss 0.62642. lr 3.000000e-04, running loss 0.61468, it/sec: 4.467457330167762
epoch 1 iter 22100: train loss 0.77760. lr 3.000000e-04, running loss 0.61449, it/sec: 4.525812252741722
epoch 1 iter 22120: train loss 0.55731. lr 3.000000e-04, running loss 0.61451, it/sec: 4.44840781714249
epoch 1 iter 22140: train loss 0.66899. lr 3.000000e-04, running loss 0.61415, it/sec: 4.524675384740278
epoch 1 iter 22160: train loss 0.75279. lr 3.000000e-04, running loss 0.61401, it/sec: 4.452392083458259
epoch 1 iter 22180: train loss 0.58127. lr 3.000000e-04, running loss 0.61384, it/sec: 4.512280097535731
epoch 1 iter 22200: train loss 0.64537. lr 3.000000e-04, running loss 0.61417, it/sec: 4.452077244223723
epoch 1 iter 22220: train loss 0.61474. lr 3.000000e-04, running loss 0.61461, it/sec: 4.508261734500083
epoch 1 iter 22240: train loss 0.56884. lr 3.000000e-04, running loss 0.61471, it/sec: 4.507491001631525
epoch 1 iter 22260: train loss 0.62215. lr 3.000000e-04, running loss 0.61466, it/sec: 4.468336940629533
epoch 1 iter 22280: train loss 0.53193. lr 3.000000e-04, running loss 0.61466, it/sec: 4.505230799894329
epoch 1 iter 22300: train loss 0.58989. lr 3.000000e-04, running loss 0.61421, it/sec: 4.4617201259300225
epoch 1 iter 22320: train loss 0.57191. lr 3.000000e-04, running loss 0.61378, it/sec: 4.5093942931789535
epoch 1 iter 22340: train loss 0.60912. lr 3.000000e-04, running loss 0.61361, it/sec: 4.474832895469945
epoch 1 iter 22360: train loss 0.54192. lr 3.000000e-04, running loss 0.61328, it/sec: 4.50093688317177
epoch 1 iter 22380: train loss 0.60398. lr 3.000000e-04, running loss 0.61298, it/sec: 4.45234339647107
epoch 1 iter 22400: train loss 0.54956. lr 3.000000e-04, running loss 0.61322, it/sec: 4.485849050598226
epoch 1 iter 22420: train loss 0.69012. lr 3.000000e-04, running loss 0.61365, it/sec: 4.462600804117383
epoch 1 iter 22440: train loss 0.54438. lr 3.000000e-04, running loss 0.61324, it/sec: 4.503119005069054
epoch 1 iter 22460: train loss 0.55063. lr 3.000000e-04, running loss 0.61308, it/sec: 4.433170203409479
epoch 1 iter 22480: train loss 0.66194. lr 3.000000e-04, running loss 0.61276, it/sec: 4.5140035339162585
epoch 1 iter 22500: train loss 0.57805. lr 3.000000e-04, running loss 0.61274, it/sec: 4.453808151535452
epoch 1 iter 22520: train loss 0.61070. lr 3.000000e-04, running loss 0.61290, it/sec: 4.470081594782141
epoch 1 iter 22540: train loss 0.57378. lr 3.000000e-04, running loss 0.61271, it/sec: 4.465431576313212
epoch 1 iter 22560: train loss 0.59972. lr 3.000000e-04, running loss 0.61202, it/sec: 4.480852466231973
epoch 1 iter 22580: train loss 0.58920. lr 3.000000e-04, running loss 0.61176, it/sec: 4.50295056037741
epoch 1 iter 22600: train loss 0.66520. lr 3.000000e-04, running loss 0.61172, it/sec: 4.466207758765336
epoch 1 iter 22620: train loss 0.65662. lr 3.000000e-04, running loss 0.61142, it/sec: 4.423420027469689
epoch 1 iter 22640: train loss 0.65102. lr 3.000000e-04, running loss 0.61128, it/sec: 4.476461709351274
epoch 1 iter 22660: train loss 0.63155. lr 3.000000e-04, running loss 0.61156, it/sec: 4.461999615686969
epoch 1 iter 22680: train loss 0.61309. lr 3.000000e-04, running loss 0.61299, it/sec: 4.4705500131015565
epoch 1 iter 22700: train loss 0.68170. lr 3.000000e-04, running loss 0.61324, it/sec: 4.467376180944966
epoch 1 iter 22720: train loss 0.64503. lr 3.000000e-04, running loss 0.61321, it/sec: 4.465946488267144
epoch 1 iter 22740: train loss 0.64350. lr 3.000000e-04, running loss 0.61360, it/sec: 4.5066472329114715
epoch 1 iter 22760: train loss 0.59959. lr 3.000000e-04, running loss 0.61355, it/sec: 4.448511035250042
epoch 1 iter 22780: train loss 0.72878. lr 3.000000e-04, running loss 0.61346, it/sec: 4.510980219994351
epoch 1 iter 22800: train loss 0.61974. lr 3.000000e-04, running loss 0.61325, it/sec: 4.435827426194052
epoch 1 iter 22820: train loss 0.68602. lr 3.000000e-04, running loss 0.61318, it/sec: 4.505833624076123
epoch 1 iter 22840: train loss 0.61975. lr 3.000000e-04, running loss 0.61282, it/sec: 4.441181676729575
epoch 1 iter 22860: train loss 0.57711. lr 3.000000e-04, running loss 0.61266, it/sec: 4.498241634429346
epoch 1 iter 22880: train loss 0.67051. lr 3.000000e-04, running loss 0.61269, it/sec: 4.508468910391815
epoch 1 iter 22900: train loss 0.64934. lr 3.000000e-04, running loss 0.61299, it/sec: 4.441847760345249
epoch 1 iter 22920: train loss 0.56572. lr 3.000000e-04, running loss 0.61300, it/sec: 4.489215893285565
epoch 1 iter 22940: train loss 0.67561. lr 3.000000e-04, running loss 0.61274, it/sec: 4.5196996731407495
epoch 1 iter 22960: train loss 0.64840. lr 3.000000e-04, running loss 0.61195, it/sec: 4.449252127776634
epoch 1 iter 22980: train loss 0.67239. lr 3.000000e-04, running loss 0.61206, it/sec: 4.501607254510936
epoch 1 iter 23000: train loss 0.57321. lr 3.000000e-04, running loss 0.61234, it/sec: 4.497911740081653
epoch 1 iter 23020: train loss 0.57769. lr 3.000000e-04, running loss 0.61176, it/sec: 4.461001103118677
epoch 1 iter 23040: train loss 0.56076. lr 3.000000e-04, running loss 0.61148, it/sec: 4.48703643058651
epoch 1 iter 23060: train loss 0.58965. lr 3.000000e-04, running loss 0.61149, it/sec: 4.446826934986099
epoch 1 iter 23080: train loss 0.65355. lr 3.000000e-04, running loss 0.61199, it/sec: 4.505115129753298
epoch 1 iter 23100: train loss 0.68690. lr 3.000000e-04, running loss 0.61196, it/sec: 4.461215302895406
epoch 1 iter 23120: train loss 0.59759. lr 3.000000e-04, running loss 0.61203, it/sec: 4.512986439598723
epoch 1 iter 23140: train loss 0.55171. lr 3.000000e-04, running loss 0.61190, it/sec: 4.450326134194716
epoch 1 iter 23160: train loss 0.68450. lr 3.000000e-04, running loss 0.61194, it/sec: 4.492429925067673
epoch 1 iter 23180: train loss 0.64392. lr 3.000000e-04, running loss 0.61198, it/sec: 4.428911896013649
epoch 1 iter 23200: train loss 0.66248. lr 3.000000e-04, running loss 0.61219, it/sec: 4.4811082148159675
epoch 1 iter 23220: train loss 0.66520. lr 3.000000e-04, running loss 0.61222, it/sec: 4.4837577733214165
epoch 1 iter 23240: train loss 0.57490. lr 3.000000e-04, running loss 0.61205, it/sec: 4.5046601387800544
epoch 1 iter 23260: train loss 0.62701. lr 3.000000e-04, running loss 0.61191, it/sec: 4.424924528422544
epoch 1 iter 23280: train loss 0.75864. lr 3.000000e-04, running loss 0.61195, it/sec: 4.519813498794095
epoch 1 iter 23300: train loss 0.66568. lr 3.000000e-04, running loss 0.61225, it/sec: 4.467777042925436
epoch 1 iter 23320: train loss 0.75460. lr 3.000000e-04, running loss 0.61197, it/sec: 4.4869156331151485
epoch 1 iter 23340: train loss 0.67927. lr 3.000000e-04, running loss 0.61180, it/sec: 4.494151679134595
epoch 1 iter 23360: train loss 0.65190. lr 3.000000e-04, running loss 0.61181, it/sec: 4.454721962590654
epoch 1 iter 23380: train loss 0.66394. lr 3.000000e-04, running loss 0.61202, it/sec: 4.5020747222484125
epoch 1 iter 23400: train loss 0.65099. lr 3.000000e-04, running loss 0.61199, it/sec: 4.441255780507417
epoch 1 iter 23420: train loss 0.58989. lr 3.000000e-04, running loss 0.61198, it/sec: 4.485737512477495
epoch 1 iter 23440: train loss 0.67891. lr 3.000000e-04, running loss 0.61205, it/sec: 4.495920758013406
epoch 1 iter 23460: train loss 0.51275. lr 3.000000e-04, running loss 0.61239, it/sec: 4.465278481675651
epoch 1 iter 23480: train loss 0.62202. lr 3.000000e-04, running loss 0.61258, it/sec: 4.510439246437456
epoch 1 iter 23500: train loss 0.52035. lr 3.000000e-04, running loss 0.61267, it/sec: 4.473726115550733
epoch 1 iter 23520: train loss 0.57567. lr 3.000000e-04, running loss 0.61307, it/sec: 4.521043643135024
epoch 1 iter 23540: train loss 0.62603. lr 3.000000e-04, running loss 0.61294, it/sec: 4.452030406594778
epoch 1 iter 23560: train loss 0.60805. lr 3.000000e-04, running loss 0.61286, it/sec: 4.48454862716921
epoch 1 iter 23580: train loss 0.51794. lr 3.000000e-04, running loss 0.61216, it/sec: 4.466474905347852
epoch 1 iter 23600: train loss 0.55935. lr 3.000000e-04, running loss 0.61201, it/sec: 4.511184898797862
epoch 1 iter 23620: train loss 0.55673. lr 3.000000e-04, running loss 0.61185, it/sec: 4.501141300183906
epoch 1 iter 23640: train loss 0.65721. lr 3.000000e-04, running loss 0.61239, it/sec: 4.5221019994615705
epoch 1 iter 23660: train loss 0.56899. lr 3.000000e-04, running loss 0.61250, it/sec: 4.455387589472437
epoch 1 iter 23680: train loss 0.62207. lr 3.000000e-04, running loss 0.61250, it/sec: 4.510314846994036
epoch 1 iter 23700: train loss 0.56872. lr 3.000000e-04, running loss 0.61225, it/sec: 4.4405990831268625
epoch 1 iter 23720: train loss 0.62186. lr 3.000000e-04, running loss 0.61203, it/sec: 4.459705955246616
epoch 1 iter 23740: train loss 0.59202. lr 3.000000e-04, running loss 0.61214, it/sec: 4.474524145377553
epoch 1 iter 23760: train loss 0.67715. lr 3.000000e-04, running loss 0.61248, it/sec: 4.444365018305554
epoch 1 iter 23780: train loss 0.61715. lr 3.000000e-04, running loss 0.61276, it/sec: 4.511217664292841
epoch 1 iter 23800: train loss 0.59692. lr 3.000000e-04, running loss 0.61244, it/sec: 4.4408247184038165
epoch 1 iter 23820: train loss 0.56492. lr 3.000000e-04, running loss 0.61259, it/sec: 4.505406803382132
epoch 1 iter 23840: train loss 0.65312. lr 3.000000e-04, running loss 0.61232, it/sec: 4.477289542065624
epoch 1 iter 23860: train loss 0.50394. lr 3.000000e-04, running loss 0.61196, it/sec: 4.48679701700493
epoch 1 iter 23880: train loss 0.75221. lr 3.000000e-04, running loss 0.61196, it/sec: 4.473322445202689
epoch 1 iter 23900: train loss 0.59251. lr 3.000000e-04, running loss 0.61170, it/sec: 4.5037387273481
epoch 1 iter 23920: train loss 0.57628. lr 3.000000e-04, running loss 0.61147, it/sec: 4.445898154831157
epoch 1 iter 23940: train loss 0.67741. lr 3.000000e-04, running loss 0.61119, it/sec: 4.505665485541614
epoch 1 iter 23960: train loss 0.56839. lr 3.000000e-04, running loss 0.61145, it/sec: 4.457592361006385
epoch 1 iter 23980: train loss 0.67258. lr 3.000000e-04, running loss 0.61132, it/sec: 4.500882267013909
epoch 1 iter 24000: train loss 0.68215. lr 3.000000e-04, running loss 0.61157, it/sec: 4.454670149816547
epoch 1 iter 24020: train loss 0.68677. lr 3.000000e-04, running loss 0.61133, it/sec: 4.496569781327105
epoch 1 iter 24040: train loss 0.59473. lr 3.000000e-04, running loss 0.61165, it/sec: 4.452247394123166
epoch 1 iter 24060: train loss 0.63401. lr 3.000000e-04, running loss 0.61193, it/sec: 4.494591439822172
epoch 1 iter 24080: train loss 0.56489. lr 3.000000e-04, running loss 0.61149, it/sec: 4.48553374730549
epoch 1 iter 24100: train loss 0.59701. lr 3.000000e-04, running loss 0.61160, it/sec: 4.446164556053218
epoch 1 iter 24120: train loss 0.56969. lr 3.000000e-04, running loss 0.61149, it/sec: 4.484222205889924
epoch 1 iter 24140: train loss 0.54057. lr 3.000000e-04, running loss 0.61147, it/sec: 4.492968201466893
epoch 1 iter 24160: train loss 0.66817. lr 3.000000e-04, running loss 0.61161, it/sec: 4.453695184163337
epoch 1 iter 24180: train loss 0.62647. lr 3.000000e-04, running loss 0.61156, it/sec: 4.497874496073894
epoch 1 iter 24200: train loss 0.61767. lr 3.000000e-04, running loss 0.61165, it/sec: 4.455193004027381
epoch 1 iter 24220: train loss 0.58113. lr 3.000000e-04, running loss 0.61178, it/sec: 4.524165508723846
epoch 1 iter 24240: train loss 0.64101. lr 3.000000e-04, running loss 0.61182, it/sec: 4.5007303376059316
epoch 1 iter 24260: train loss 0.63474. lr 3.000000e-04, running loss 0.61202, it/sec: 4.4552486798361635
epoch 1 iter 24280: train loss 0.64771. lr 3.000000e-04, running loss 0.61193, it/sec: 4.494398081629792
epoch 1 iter 24300: train loss 0.51113. lr 3.000000e-04, running loss 0.61178, it/sec: 4.467619516630537
epoch 1 iter 24320: train loss 0.52495. lr 3.000000e-04, running loss 0.61190, it/sec: 4.506706518154698
epoch 1 iter 24340: train loss 0.59578. lr 3.000000e-04, running loss 0.61143, it/sec: 4.441008367310966
epoch 1 iter 24360: train loss 0.58092. lr 3.000000e-04, running loss 0.61118, it/sec: 4.527451567254966
epoch 1 iter 24380: train loss 0.52953. lr 3.000000e-04, running loss 0.61127, it/sec: 4.458609307119812
epoch 1 iter 24400: train loss 0.64750. lr 3.000000e-04, running loss 0.61095, it/sec: 4.494155739810467
epoch 1 iter 24420: train loss 0.64816. lr 3.000000e-04, running loss 0.61117, it/sec: 4.450634090358685
epoch 1 iter 24440: train loss 0.51517. lr 3.000000e-04, running loss 0.61109, it/sec: 4.49007834782208
epoch 1 iter 24460: train loss 0.59490. lr 3.000000e-04, running loss 0.61127, it/sec: 4.465781971538855
epoch 1 iter 24480: train loss 0.52908. lr 3.000000e-04, running loss 0.61136, it/sec: 4.509916689152566
epoch 1 iter 24500: train loss 0.65688. lr 3.000000e-04, running loss 0.61139, it/sec: 4.460828989707377
epoch 1 iter 24520: train loss 0.61981. lr 3.000000e-04, running loss 0.61137, it/sec: 4.527116042200568
epoch 1 iter 24540: train loss 0.54055. lr 3.000000e-04, running loss 0.61120, it/sec: 4.459331536212155
epoch 1 iter 24560: train loss 0.60361. lr 3.000000e-04, running loss 0.61108, it/sec: 4.491694596578837
epoch 1 iter 24580: train loss 0.64341. lr 3.000000e-04, running loss 0.61128, it/sec: 4.501012286943276
epoch 1 iter 24600: train loss 0.55173. lr 3.000000e-04, running loss 0.61175, it/sec: 4.466220923003279
epoch 1 iter 24620: train loss 0.62730. lr 3.000000e-04, running loss 0.61175, it/sec: 4.51071541418565
epoch 1 iter 24640: train loss 0.56695. lr 3.000000e-04, running loss 0.61132, it/sec: 4.474296993083914
epoch 1 iter 24660: train loss 0.55932. lr 3.000000e-04, running loss 0.61188, it/sec: 4.506437156904628
epoch 1 iter 24680: train loss 0.57934. lr 3.000000e-04, running loss 0.61181, it/sec: 4.470708925821733
epoch 1 iter 24700: train loss 0.52453. lr 3.000000e-04, running loss 0.61178, it/sec: 4.494700530602496
epoch 1 iter 24720: train loss 0.98976. lr 3.000000e-04, running loss 0.61210, it/sec: 4.449374469930238
epoch 1 iter 24740: train loss 0.62692. lr 3.000000e-04, running loss 0.61162, it/sec: 4.518989780454323
epoch 1 iter 24760: train loss 0.54349. lr 3.000000e-04, running loss 0.61131, it/sec: 4.467898229652453
epoch 1 iter 24780: train loss 0.61791. lr 3.000000e-04, running loss 0.61172, it/sec: 4.4995004112700405
epoch 1 iter 24800: train loss 0.61851. lr 3.000000e-04, running loss 0.61163, it/sec: 4.437898425423173
epoch 1 iter 24820: train loss 0.50792. lr 3.000000e-04, running loss 0.61189, it/sec: 4.491934635305261
epoch 1 iter 24840: train loss 0.62326. lr 3.000000e-04, running loss 0.61238, it/sec: 4.445954151988806
epoch 1 iter 24860: train loss 0.59081. lr 3.000000e-04, running loss 0.61248, it/sec: 4.491636491260848
epoch 1 iter 24880: train loss 0.93197. lr 3.000000e-04, running loss 0.61306, it/sec: 4.500426813722189
epoch 1 iter 24900: train loss 0.59535. lr 3.000000e-04, running loss 0.61255, it/sec: 4.485861607007392
epoch 1 iter 24920: train loss 0.65240. lr 3.000000e-04, running loss 0.61253, it/sec: 4.485756346180988
epoch 1 iter 24940: train loss 0.63665. lr 3.000000e-04, running loss 0.61260, it/sec: 4.4390964178448
epoch 1 iter 24960: train loss 0.59627. lr 3.000000e-04, running loss 0.61241, it/sec: 4.513544421715172
epoch 1 iter 24980: train loss 0.63616. lr 3.000000e-04, running loss 0.61254, it/sec: 4.4717651808206265
epoch 1 iter 25000: train loss 0.64310. lr 3.000000e-04, running loss 0.61262, it/sec: 1.194135000211872
epoch 1 iter 25020: train loss 0.57033. lr 3.000000e-04, running loss 0.61186, it/sec: 4.543945232040579
epoch 1 iter 25040: train loss 0.66327. lr 3.000000e-04, running loss 0.61203, it/sec: 4.458199058495822
epoch 1 iter 25060: train loss 0.69326. lr 3.000000e-04, running loss 0.61207, it/sec: 4.513900473045684
epoch 1 iter 25080: train loss 0.59442. lr 3.000000e-04, running loss 0.61223, it/sec: 4.4648312808093396
epoch 1 iter 25100: train loss 0.61417. lr 3.000000e-04, running loss 0.61201, it/sec: 4.5062336001422
epoch 1 iter 25120: train loss 0.61279. lr 3.000000e-04, running loss 0.61181, it/sec: 4.4783753834386895
epoch 1 iter 25140: train loss 0.80165. lr 3.000000e-04, running loss 0.61218, it/sec: 4.512946479692518
epoch 1 iter 25160: train loss 0.61479. lr 3.000000e-04, running loss 0.61190, it/sec: 4.463424632095942
epoch 1 iter 25180: train loss 0.64381. lr 3.000000e-04, running loss 0.61216, it/sec: 4.505246104410495
epoch 1 iter 25200: train loss 0.64724. lr 3.000000e-04, running loss 0.61225, it/sec: 4.430870875554435
epoch 1 iter 25220: train loss 0.69377. lr 3.000000e-04, running loss 0.61200, it/sec: 4.519004218138257
epoch 1 iter 25240: train loss 0.53270. lr 3.000000e-04, running loss 0.61221, it/sec: 4.443107562222411
epoch 1 iter 25260: train loss 0.68700. lr 3.000000e-04, running loss 0.61242, it/sec: 4.497024150529391
epoch 1 iter 25280: train loss 0.56398. lr 3.000000e-04, running loss 0.61274, it/sec: 4.458175248286564
epoch 1 iter 25300: train loss 0.67017. lr 3.000000e-04, running loss 0.61281, it/sec: 4.523116926618271
epoch 1 iter 25320: train loss 0.59944. lr 3.000000e-04, running loss 0.61239, it/sec: 4.449109464065467
epoch 1 iter 25340: train loss 0.60264. lr 3.000000e-04, running loss 0.61212, it/sec: 4.508029479594766
epoch 1 iter 25360: train loss 0.62282. lr 3.000000e-04, running loss 0.61195, it/sec: 4.460923591423485
epoch 1 iter 25380: train loss 0.68452. lr 3.000000e-04, running loss 0.61210, it/sec: 4.509548352835733
epoch 1 iter 25400: train loss 0.62125. lr 3.000000e-04, running loss 0.61177, it/sec: 4.474433588878611
epoch 1 iter 25420: train loss 0.63371. lr 3.000000e-04, running loss 0.61151, it/sec: 4.5081526161585215
epoch 1 iter 25440: train loss 0.58773. lr 3.000000e-04, running loss 0.61143, it/sec: 4.473853569294677
epoch 1 iter 25460: train loss 0.65955. lr 3.000000e-04, running loss 0.61154, it/sec: 4.491969300459944
epoch 1 iter 25480: train loss 0.65902. lr 3.000000e-04, running loss 0.61156, it/sec: 4.450094779775404
epoch 1 iter 25500: train loss 0.63934. lr 3.000000e-04, running loss 0.61148, it/sec: 4.5216223486070914
epoch 1 iter 25520: train loss 0.74212. lr 3.000000e-04, running loss 0.61160, it/sec: 4.460351644276914
epoch 1 iter 25540: train loss 0.59791. lr 3.000000e-04, running loss 0.61134, it/sec: 4.50168456454655
epoch 1 iter 25560: train loss 0.67386. lr 3.000000e-04, running loss 0.61196, it/sec: 4.46180962855513
epoch 1 iter 25580: train loss 0.52660. lr 3.000000e-04, running loss 0.61181, it/sec: 4.459122031093848
epoch 1 iter 25600: train loss 0.78338. lr 3.000000e-04, running loss 0.61200, it/sec: 4.4964435967031395
epoch 1 iter 25620: train loss 0.54604. lr 3.000000e-04, running loss 0.61156, it/sec: 4.526599837454306
epoch 1 iter 25640: train loss 0.62530. lr 3.000000e-04, running loss 0.61165, it/sec: 4.450662692659204
epoch 1 iter 25660: train loss 0.62346. lr 3.000000e-04, running loss 0.61150, it/sec: 4.516389097654445
epoch 1 iter 25680: train loss 0.63242. lr 3.000000e-04, running loss 0.61129, it/sec: 4.4486984284990125
epoch 1 iter 25700: train loss 0.54333. lr 3.000000e-04, running loss 0.61111, it/sec: 4.532459078883536
epoch 1 iter 25720: train loss 0.62480. lr 3.000000e-04, running loss 0.61116, it/sec: 4.4477105459962685
epoch 1 iter 25740: train loss 0.59548. lr 3.000000e-04, running loss 0.61125, it/sec: 4.524745279487066
epoch 1 iter 25760: train loss 0.70940. lr 3.000000e-04, running loss 0.61125, it/sec: 4.466180032612227
epoch 1 iter 25780: train loss 0.64430. lr 3.000000e-04, running loss 0.61125, it/sec: 4.485964941193742
epoch 1 iter 25800: train loss 0.61555. lr 3.000000e-04, running loss 0.61100, it/sec: 4.4965219016548685
epoch 1 iter 25820: train loss 0.47286. lr 3.000000e-04, running loss 0.61058, it/sec: 4.496154881573817
epoch 1 iter 25840: train loss 0.61275. lr 3.000000e-04, running loss 0.61034, it/sec: 4.508260129119212
epoch 1 iter 25860: train loss 0.59185. lr 3.000000e-04, running loss 0.61012, it/sec: 4.467572850975504
epoch 1 iter 25880: train loss 0.58432. lr 3.000000e-04, running loss 0.60977, it/sec: 4.511681798489937
epoch 1 iter 25900: train loss 0.68178. lr 3.000000e-04, running loss 0.61059, it/sec: 4.4421339040213965
epoch 1 iter 25920: train loss 0.67161. lr 3.000000e-04, running loss 0.61095, it/sec: 4.5231124049787095
epoch 1 iter 25940: train loss 0.59074. lr 3.000000e-04, running loss 0.61088, it/sec: 4.47066629305456
epoch 1 iter 25960: train loss 0.68604. lr 3.000000e-04, running loss 0.61125, it/sec: 4.518871359505136
epoch 1 iter 25980: train loss 0.57111. lr 3.000000e-04, running loss 0.61133, it/sec: 4.495179841609693
epoch 1 iter 26000: train loss 0.57175. lr 3.000000e-04, running loss 0.61095, it/sec: 4.512180760694995
epoch 1 iter 26020: train loss 0.66792. lr 3.000000e-04, running loss 0.61128, it/sec: 4.459602097746866
epoch 1 iter 26040: train loss 0.59374. lr 3.000000e-04, running loss 0.61117, it/sec: 4.508595243152837
epoch 1 iter 26060: train loss 0.66785. lr 3.000000e-04, running loss 0.61107, it/sec: 4.445077166295349
epoch 1 iter 26080: train loss 0.57731. lr 3.000000e-04, running loss 0.61082, it/sec: 4.508429010332351
epoch 1 iter 26100: train loss 0.65334. lr 3.000000e-04, running loss 0.61101, it/sec: 4.452673003499267
epoch 1 iter 26120: train loss 0.55340. lr 3.000000e-04, running loss 0.61078, it/sec: 4.494433350372136
epoch 1 iter 26140: train loss 0.64474. lr 3.000000e-04, running loss 0.61122, it/sec: 4.477041024065752
epoch 1 iter 26160: train loss 0.62667. lr 3.000000e-04, running loss 0.61123, it/sec: 4.531015475825198
epoch 1 iter 26180: train loss 0.67016. lr 3.000000e-04, running loss 0.61161, it/sec: 4.4516399160206195
epoch 1 iter 26200: train loss 0.50056. lr 3.000000e-04, running loss 0.61139, it/sec: 4.465059585037807
epoch 1 iter 26220: train loss 0.62186. lr 3.000000e-04, running loss 0.61112, it/sec: 4.464793944432556
epoch 1 iter 26240: train loss 0.61923. lr 3.000000e-04, running loss 0.61081, it/sec: 4.515270210303082
epoch 1 iter 26260: train loss 0.57137. lr 3.000000e-04, running loss 0.61029, it/sec: 4.4556276737064
epoch 1 iter 26280: train loss 0.58192. lr 3.000000e-04, running loss 0.61028, it/sec: 4.532011630963019
epoch 1 iter 26300: train loss 0.66828. lr 3.000000e-04, running loss 0.61042, it/sec: 4.452619691996443
epoch 1 iter 26320: train loss 0.51817. lr 3.000000e-04, running loss 0.61010, it/sec: 4.507280887160864
epoch 1 iter 26340: train loss 0.58190. lr 3.000000e-04, running loss 0.61013, it/sec: 4.474892647419607
epoch 1 iter 26360: train loss 0.54454. lr 3.000000e-04, running loss 0.60984, it/sec: 4.5048908500019715
epoch 1 iter 26380: train loss 0.67013. lr 3.000000e-04, running loss 0.61000, it/sec: 4.4496245794666125
epoch 1 iter 26400: train loss 0.65840. lr 3.000000e-04, running loss 0.61007, it/sec: 4.51032711327421
epoch 1 iter 26420: train loss 0.61088. lr 3.000000e-04, running loss 0.60998, it/sec: 4.492894178507455
epoch 1 iter 26440: train loss 0.69211. lr 3.000000e-04, running loss 0.61019, it/sec: 4.495847729554748
epoch 1 iter 26460: train loss 0.65315. lr 3.000000e-04, running loss 0.61039, it/sec: 4.464033098117109
epoch 1 iter 26480: train loss 0.61545. lr 3.000000e-04, running loss 0.61042, it/sec: 4.5017110912730764
epoch 1 iter 26500: train loss 0.77776. lr 3.000000e-04, running loss 0.61079, it/sec: 4.472938014120071
epoch 1 iter 26520: train loss 0.55599. lr 3.000000e-04, running loss 0.61049, it/sec: 4.50003368004869
epoch 1 iter 26540: train loss 0.54552. lr 3.000000e-04, running loss 0.61037, it/sec: 4.436431991460046
epoch 1 iter 26560: train loss 0.62351. lr 3.000000e-04, running loss 0.61036, it/sec: 4.503761119943297
epoch 1 iter 26580: train loss 0.58855. lr 3.000000e-04, running loss 0.61019, it/sec: 4.473442751812632
epoch 1 iter 26600: train loss 0.59643. lr 3.000000e-04, running loss 0.61026, it/sec: 4.513942711588183
epoch 1 iter 26620: train loss 0.68356. lr 3.000000e-04, running loss 0.61007, it/sec: 4.464306641133015
epoch 1 iter 26640: train loss 0.67922. lr 3.000000e-04, running loss 0.60991, it/sec: 4.525975712373506
epoch 1 iter 26660: train loss 0.57541. lr 3.000000e-04, running loss 0.60969, it/sec: 4.481441995315774
epoch 1 iter 26680: train loss 0.65963. lr 3.000000e-04, running loss 0.60970, it/sec: 4.519751009672248
epoch 1 iter 26700: train loss 0.61706. lr 3.000000e-04, running loss 0.61035, it/sec: 4.468947784904227
epoch 1 iter 26720: train loss 0.61824. lr 3.000000e-04, running loss 0.61064, it/sec: 4.512251104284031
epoch 1 iter 26740: train loss 0.59825. lr 3.000000e-04, running loss 0.61055, it/sec: 4.468832612620074
epoch 1 iter 26760: train loss 0.56766. lr 3.000000e-04, running loss 0.61055, it/sec: 4.529975166471224
epoch 1 iter 26780: train loss 0.56234. lr 3.000000e-04, running loss 0.61079, it/sec: 4.4730271474891
epoch 1 iter 26800: train loss 0.75536. lr 3.000000e-04, running loss 0.61075, it/sec: 4.5258925485226476
epoch 1 iter 26820: train loss 0.65044. lr 3.000000e-04, running loss 0.61042, it/sec: 4.490118932970048
epoch 1 iter 26840: train loss 0.56212. lr 3.000000e-04, running loss 0.60977, it/sec: 4.49204781375761
epoch 1 iter 26860: train loss 0.70448. lr 3.000000e-04, running loss 0.60979, it/sec: 4.500881112609348
epoch 1 iter 26880: train loss 0.58319. lr 3.000000e-04, running loss 0.60954, it/sec: 4.461543936530211
epoch 1 iter 26900: train loss 0.58698. lr 3.000000e-04, running loss 0.60951, it/sec: 4.52715529070062
epoch 1 iter 26920: train loss 0.53994. lr 3.000000e-04, running loss 0.60931, it/sec: 4.470627418775853
epoch 1 iter 26940: train loss 0.69100. lr 3.000000e-04, running loss 0.60902, it/sec: 4.5170775874716895
epoch 1 iter 26960: train loss 0.71333. lr 3.000000e-04, running loss 0.60939, it/sec: 4.4682897811794104
epoch 1 iter 26980: train loss 0.59194. lr 3.000000e-04, running loss 0.61021, it/sec: 4.523611464202417
epoch 1 iter 27000: train loss 0.64695. lr 3.000000e-04, running loss 0.60994, it/sec: 4.473191458889744
epoch 1 iter 27020: train loss 0.54185. lr 3.000000e-04, running loss 0.61059, it/sec: 4.487593049709658
epoch 1 iter 27040: train loss 0.68673. lr 3.000000e-04, running loss 0.61063, it/sec: 4.507638084546903
epoch 1 iter 27060: train loss 0.63979. lr 3.000000e-04, running loss 0.61032, it/sec: 4.487804616263494
epoch 1 iter 27080: train loss 0.56575. lr 3.000000e-04, running loss 0.61092, it/sec: 4.48586017918083
epoch 1 iter 27100: train loss 0.56470. lr 3.000000e-04, running loss 0.61089, it/sec: 4.494512413108229
epoch 1 iter 27120: train loss 0.54293. lr 3.000000e-04, running loss 0.61104, it/sec: 4.475842238497649
epoch 1 iter 27140: train loss 0.58479. lr 3.000000e-04, running loss 0.61152, it/sec: 4.485179241132591
epoch 1 iter 27160: train loss 0.57817. lr 3.000000e-04, running loss 0.61129, it/sec: 4.453611322230083
epoch 1 iter 27180: train loss 0.61540. lr 3.000000e-04, running loss 0.61086, it/sec: 4.5098468445215945
epoch 1 iter 27200: train loss 0.61450. lr 3.000000e-04, running loss 0.61020, it/sec: 4.4480421392265965
epoch 1 iter 27220: train loss 0.73913. lr 3.000000e-04, running loss 0.61002, it/sec: 4.5223369352372575
epoch 1 iter 27240: train loss 0.53037. lr 3.000000e-04, running loss 0.60997, it/sec: 4.445039210743653
epoch 1 iter 27260: train loss 0.51292. lr 3.000000e-04, running loss 0.61032, it/sec: 4.50144611642827
epoch 1 iter 27280: train loss 0.56079. lr 3.000000e-04, running loss 0.61019, it/sec: 4.4659562610229955
epoch 1 iter 27300: train loss 0.60174. lr 3.000000e-04, running loss 0.61022, it/sec: 4.5311532370858485
epoch 1 iter 27320: train loss 0.56685. lr 3.000000e-04, running loss 0.60997, it/sec: 4.467616221759562
epoch 1 iter 27340: train loss 0.64538. lr 3.000000e-04, running loss 0.60983, it/sec: 4.482649829777369
epoch 1 iter 27360: train loss 0.60968. lr 3.000000e-04, running loss 0.60964, it/sec: 4.452227155027718
epoch 1 iter 27380: train loss 0.57747. lr 3.000000e-04, running loss 0.60933, it/sec: 4.511199266515428
epoch 1 iter 27400: train loss 0.58905. lr 3.000000e-04, running loss 0.60914, it/sec: 4.443774777718494
epoch 1 iter 27420: train loss 0.62233. lr 3.000000e-04, running loss 0.60905, it/sec: 4.520674141375842
epoch 1 iter 27440: train loss 0.58030. lr 3.000000e-04, running loss 0.60911, it/sec: 4.460108783530582
epoch 1 iter 27460: train loss 0.60131. lr 3.000000e-04, running loss 0.60895, it/sec: 4.495798633456795
epoch 1 iter 27480: train loss 0.56424. lr 3.000000e-04, running loss 0.60901, it/sec: 4.443094414380912
epoch 1 iter 27500: train loss 0.60804. lr 3.000000e-04, running loss 0.60923, it/sec: 4.490970902215413
epoch 1 iter 27520: train loss 0.53831. lr 3.000000e-04, running loss 0.60884, it/sec: 4.470132926916993
epoch 1 iter 27540: train loss 0.62212. lr 3.000000e-04, running loss 0.60926, it/sec: 4.507625831705804
epoch 1 iter 27560: train loss 0.55916. lr 3.000000e-04, running loss 0.60935, it/sec: 4.47806465959535
epoch 1 iter 27580: train loss 0.54282. lr 3.000000e-04, running loss 0.60889, it/sec: 4.515616072612602
epoch 1 iter 27600: train loss 0.56088. lr 3.000000e-04, running loss 0.60849, it/sec: 4.468398575169884
epoch 1 iter 27620: train loss 0.64823. lr 3.000000e-04, running loss 0.60875, it/sec: 4.510261609814065
epoch 1 iter 27640: train loss 0.73213. lr 3.000000e-04, running loss 0.60900, it/sec: 4.456322285690442
epoch 1 iter 27660: train loss 0.71055. lr 3.000000e-04, running loss 0.60951, it/sec: 4.49435719804766
epoch 1 iter 27680: train loss 0.66546. lr 3.000000e-04, running loss 0.60952, it/sec: 4.461415529887148
epoch 1 iter 27700: train loss 0.68396. lr 3.000000e-04, running loss 0.60998, it/sec: 4.526036122515603
epoch 1 iter 27720: train loss 0.59508. lr 3.000000e-04, running loss 0.60993, it/sec: 4.475500940193591
epoch 1 iter 27740: train loss 0.57217. lr 3.000000e-04, running loss 0.60990, it/sec: 4.518142578589356
epoch 1 iter 27760: train loss 0.63336. lr 3.000000e-04, running loss 0.61029, it/sec: 4.468583853956947
epoch 1 iter 27780: train loss 0.65869. lr 3.000000e-04, running loss 0.61033, it/sec: 4.502971606717801
epoch 1 iter 27800: train loss 0.74925. lr 3.000000e-04, running loss 0.61064, it/sec: 4.485914168992864
epoch 1 iter 27820: train loss 0.62665. lr 3.000000e-04, running loss 0.61075, it/sec: 4.510212400879265
epoch 1 iter 27840: train loss 0.57233. lr 3.000000e-04, running loss 0.61073, it/sec: 4.457293056950112
epoch 1 iter 27860: train loss 0.57656. lr 3.000000e-04, running loss 0.61080, it/sec: 4.509609240279012
epoch 1 iter 27880: train loss 0.51643. lr 3.000000e-04, running loss 0.61067, it/sec: 4.470955281075506
epoch 1 iter 27900: train loss 0.68915. lr 3.000000e-04, running loss 0.61064, it/sec: 4.532828886813635
epoch 1 iter 27920: train loss 0.59114. lr 3.000000e-04, running loss 0.61121, it/sec: 4.453774092494939
epoch 1 iter 27940: train loss 0.75771. lr 3.000000e-04, running loss 0.61207, it/sec: 4.514881471300468
epoch 1 iter 27960: train loss 0.57927. lr 3.000000e-04, running loss 0.61229, it/sec: 4.4566690283698955
epoch 1 iter 27980: train loss 0.55932. lr 3.000000e-04, running loss 0.61215, it/sec: 4.527512015608326
epoch 1 iter 28000: train loss 0.59056. lr 3.000000e-04, running loss 0.61198, it/sec: 4.493519065149646
epoch 1 iter 28020: train loss 0.69310. lr 3.000000e-04, running loss 0.61214, it/sec: 4.513739676365895
epoch 1 iter 28040: train loss 0.60873. lr 3.000000e-04, running loss 0.61197, it/sec: 4.486729779034371
epoch 1 iter 28060: train loss 0.59297. lr 3.000000e-04, running loss 0.61207, it/sec: 4.477052548840214
epoch 1 iter 28080: train loss 0.62984. lr 3.000000e-04, running loss 0.61206, it/sec: 4.521073465731102
epoch 1 iter 28100: train loss 0.58627. lr 3.000000e-04, running loss 0.61192, it/sec: 4.452974443614322
epoch 1 iter 28120: train loss 0.59482. lr 3.000000e-04, running loss 0.61136, it/sec: 4.523294535245201
epoch 1 iter 28140: train loss 0.52860. lr 3.000000e-04, running loss 0.61144, it/sec: 4.52441568292168
epoch 1 iter 28160: train loss 0.51017. lr 3.000000e-04, running loss 0.61101, it/sec: 4.4427610135628
epoch 1 iter 28180: train loss 0.52612. lr 3.000000e-04, running loss 0.61091, it/sec: 4.496049117132311
epoch 1 iter 28200: train loss 0.65725. lr 3.000000e-04, running loss 0.61096, it/sec: 4.454832023686328
epoch 1 iter 28220: train loss 0.59173. lr 3.000000e-04, running loss 0.61063, it/sec: 4.510836215047285
epoch 1 iter 28240: train loss 0.57139. lr 3.000000e-04, running loss 0.61036, it/sec: 4.4727648584579685
epoch 1 iter 28260: train loss 0.58444. lr 3.000000e-04, running loss 0.61071, it/sec: 4.488834428200002
epoch 1 iter 28280: train loss 0.66319. lr 3.000000e-04, running loss 0.61052, it/sec: 4.462143646186728
epoch 1 iter 28300: train loss 0.68977. lr 3.000000e-04, running loss 0.61010, it/sec: 4.519911437012315
epoch 1 iter 28320: train loss 0.58490. lr 3.000000e-04, running loss 0.61001, it/sec: 4.47682460080109
epoch 1 iter 28340: train loss 0.73678. lr 3.000000e-04, running loss 0.61008, it/sec: 4.517074016155251
epoch 1 iter 28360: train loss 0.69485. lr 3.000000e-04, running loss 0.60980, it/sec: 4.429646334013694
epoch 1 iter 28380: train loss 0.59380. lr 3.000000e-04, running loss 0.60966, it/sec: 4.515703388607076
epoch 1 iter 28400: train loss 0.56138. lr 3.000000e-04, running loss 0.60983, it/sec: 4.438695070955989
epoch 1 iter 28420: train loss 0.56749. lr 3.000000e-04, running loss 0.61005, it/sec: 4.543241945353943
epoch 1 iter 28440: train loss 0.58525. lr 3.000000e-04, running loss 0.60991, it/sec: 4.463126616307925
epoch 1 iter 28460: train loss 0.51531. lr 3.000000e-04, running loss 0.60994, it/sec: 4.5357951776697485
epoch 1 iter 28480: train loss 0.58629. lr 3.000000e-04, running loss 0.60976, it/sec: 4.45004491425937
epoch 1 iter 28500: train loss 0.56788. lr 3.000000e-04, running loss 0.60972, it/sec: 4.49695506955972
epoch 1 iter 28520: train loss 0.53156. lr 3.000000e-04, running loss 0.60988, it/sec: 4.455397057249247
epoch 1 iter 28540: train loss 0.67755. lr 3.000000e-04, running loss 0.61007, it/sec: 4.52532263962125
epoch 1 iter 28560: train loss 0.62910. lr 3.000000e-04, running loss 0.61015, it/sec: 4.50510863568209
epoch 1 iter 28580: train loss 0.63688. lr 3.000000e-04, running loss 0.61026, it/sec: 4.466285014142781
epoch 1 iter 28600: train loss 0.55871. lr 3.000000e-04, running loss 0.61015, it/sec: 4.5057010932349995
epoch 1 iter 28620: train loss 0.59967. lr 3.000000e-04, running loss 0.61032, it/sec: 4.49239864423575
epoch 1 iter 28640: train loss 0.64545. lr 3.000000e-04, running loss 0.61030, it/sec: 4.473931491366973
epoch 1 iter 28660: train loss 0.60907. lr 3.000000e-04, running loss 0.61034, it/sec: 4.5017196634548915
epoch 1 iter 28680: train loss 0.61008. lr 3.000000e-04, running loss 0.61010, it/sec: 4.429936029774599
epoch 1 iter 28700: train loss 0.64343. lr 3.000000e-04, running loss 0.61029, it/sec: 4.50475721822044
epoch 1 iter 28720: train loss 0.49947. lr 3.000000e-04, running loss 0.61024, it/sec: 4.4877319297733225
epoch 1 iter 28740: train loss 0.67126. lr 3.000000e-04, running loss 0.61034, it/sec: 4.513071941972566
epoch 1 iter 28760: train loss 0.71261. lr 3.000000e-04, running loss 0.61063, it/sec: 4.481439303102981
epoch 1 iter 28780: train loss 0.59451. lr 3.000000e-04, running loss 0.61046, it/sec: 4.498075842686124
epoch 1 iter 28800: train loss 0.63007. lr 3.000000e-04, running loss 0.61056, it/sec: 4.513712905704029
epoch 1 iter 28820: train loss 0.58852. lr 3.000000e-04, running loss 0.61071, it/sec: 4.460038960938452
epoch 1 iter 28840: train loss 0.66500. lr 3.000000e-04, running loss 0.61074, it/sec: 4.506584232523547
epoch 1 iter 28860: train loss 0.55018. lr 3.000000e-04, running loss 0.61052, it/sec: 4.477071732039385
epoch 1 iter 28880: train loss 0.53334. lr 3.000000e-04, running loss 0.61001, it/sec: 4.5013408718821895
epoch 1 iter 28900: train loss 0.63762. lr 3.000000e-04, running loss 0.61011, it/sec: 4.473847645035359
epoch 1 iter 28920: train loss 0.63828. lr 3.000000e-04, running loss 0.60982, it/sec: 4.509420097680195
epoch 1 iter 28940: train loss 0.62094. lr 3.000000e-04, running loss 0.60958, it/sec: 4.419361094470898
epoch 1 iter 28960: train loss 0.53885. lr 3.000000e-04, running loss 0.60960, it/sec: 4.485847319412252
epoch 1 iter 28980: train loss 0.58713. lr 3.000000e-04, running loss 0.60941, it/sec: 4.525545436922921
epoch 1 iter 29000: train loss 0.65019. lr 3.000000e-04, running loss 0.60950, it/sec: 4.4619545217276535
epoch 1 iter 29020: train loss 0.53933. lr 3.000000e-04, running loss 0.60896, it/sec: 4.510775701885956
epoch 1 iter 29040: train loss 0.57242. lr 3.000000e-04, running loss 0.60935, it/sec: 4.497349545658792
epoch 1 iter 29060: train loss 0.70850. lr 3.000000e-04, running loss 0.60934, it/sec: 4.456033081486671
epoch 1 iter 29080: train loss 0.58335. lr 3.000000e-04, running loss 0.60962, it/sec: 4.5009679198242045
epoch 1 iter 29100: train loss 0.62989. lr 3.000000e-04, running loss 0.60981, it/sec: 4.445490833205968
epoch 1 iter 29120: train loss 0.68230. lr 3.000000e-04, running loss 0.61006, it/sec: 4.514829858533028
epoch 1 iter 29140: train loss 0.58159. lr 3.000000e-04, running loss 0.60970, it/sec: 4.490815971574364
epoch 1 iter 29160: train loss 0.52791. lr 3.000000e-04, running loss 0.60951, it/sec: 4.51072994235077
epoch 1 iter 29180: train loss 0.56865. lr 3.000000e-04, running loss 0.60964, it/sec: 4.485269366572459
epoch 1 iter 29200: train loss 0.50578. lr 3.000000e-04, running loss 0.60942, it/sec: 4.491719754995591
epoch 1 iter 29220: train loss 0.55147. lr 3.000000e-04, running loss 0.60938, it/sec: 4.4606743203227674
epoch 1 iter 29240: train loss 0.57746. lr 3.000000e-04, running loss 0.60928, it/sec: 4.516216620663169
epoch 1 iter 29260: train loss 0.65518. lr 3.000000e-04, running loss 0.60901, it/sec: 4.499114341550553
epoch 1 iter 29280: train loss 0.63215. lr 3.000000e-04, running loss 0.60885, it/sec: 4.475218032387667
epoch 1 iter 29300: train loss 0.61610. lr 3.000000e-04, running loss 0.60909, it/sec: 4.522138419734798
epoch 1 iter 29320: train loss 0.60231. lr 3.000000e-04, running loss 0.60898, it/sec: 4.469133706811709
epoch 1 iter 29340: train loss 0.66568. lr 3.000000e-04, running loss 0.60910, it/sec: 4.494114194058382
epoch 1 iter 29360: train loss 0.60204. lr 3.000000e-04, running loss 0.60898, it/sec: 4.454215191490008
epoch 1 iter 29380: train loss 0.67735. lr 3.000000e-04, running loss 0.60877, it/sec: 4.487849690268094
epoch 1 iter 29400: train loss 0.60466. lr 3.000000e-04, running loss 0.60899, it/sec: 4.496078489696088
epoch 1 iter 29420: train loss 0.56788. lr 3.000000e-04, running loss 0.60882, it/sec: 4.508863885011073
epoch 1 iter 29440: train loss 0.50461. lr 3.000000e-04, running loss 0.60847, it/sec: 4.4985609932538
epoch 1 iter 29460: train loss 0.64596. lr 3.000000e-04, running loss 0.60849, it/sec: 4.461821493368684
epoch 1 iter 29480: train loss 0.65789. lr 3.000000e-04, running loss 0.60860, it/sec: 4.509849347222542
epoch 1 iter 29500: train loss 0.64805. lr 3.000000e-04, running loss 0.60875, it/sec: 4.466800502718148
epoch 1 iter 29520: train loss 0.57564. lr 3.000000e-04, running loss 0.60864, it/sec: 4.5122870816182425
epoch 1 iter 29540: train loss 0.54267. lr 3.000000e-04, running loss 0.60820, it/sec: 4.431225428484126
epoch 1 iter 29560: train loss 0.59113. lr 3.000000e-04, running loss 0.60837, it/sec: 4.505284060153805
epoch 1 iter 29580: train loss 0.50722. lr 3.000000e-04, running loss 0.60814, it/sec: 4.501441597910701
epoch 1 iter 29600: train loss 0.53832. lr 3.000000e-04, running loss 0.60784, it/sec: 4.4874596568395235
epoch 1 iter 29620: train loss 0.74439. lr 3.000000e-04, running loss 0.60847, it/sec: 4.465355146646344
epoch 1 iter 29640: train loss 0.55295. lr 3.000000e-04, running loss 0.60893, it/sec: 4.522319163291005
epoch 1 iter 29660: train loss 0.61536. lr 3.000000e-04, running loss 0.60914, it/sec: 4.442808622610187
epoch 1 iter 29680: train loss 0.64450. lr 3.000000e-04, running loss 0.60884, it/sec: 4.500180540733526
epoch 1 iter 29700: train loss 0.51728. lr 3.000000e-04, running loss 0.60904, it/sec: 4.462103805085136
epoch 1 iter 29720: train loss 0.54382. lr 3.000000e-04, running loss 0.60883, it/sec: 4.444249411520503
epoch 1 iter 29740: train loss 0.70916. lr 3.000000e-04, running loss 0.60904, it/sec: 4.520105852686963
epoch 1 iter 29760: train loss 0.68010. lr 3.000000e-04, running loss 0.60900, it/sec: 4.46335886972452
epoch 1 iter 29780: train loss 0.54243. lr 3.000000e-04, running loss 0.60916, it/sec: 4.491985058806591
epoch 1 iter 29800: train loss 0.63910. lr 3.000000e-04, running loss 0.60904, it/sec: 4.45185718273085
epoch 1 iter 29820: train loss 0.56698. lr 3.000000e-04, running loss 0.60901, it/sec: 4.51839539550479
epoch 1 iter 29840: train loss 0.55825. lr 3.000000e-04, running loss 0.60885, it/sec: 4.437583250667541
epoch 1 iter 29860: train loss 0.65821. lr 3.000000e-04, running loss 0.60881, it/sec: 4.493334136176377
epoch 1 iter 29880: train loss 0.53446. lr 3.000000e-04, running loss 0.60870, it/sec: 4.444449185456297
epoch 1 iter 29900: train loss 0.62277. lr 3.000000e-04, running loss 0.60879, it/sec: 4.499213409074619
epoch 1 iter 29920: train loss 0.60890. lr 3.000000e-04, running loss 0.60858, it/sec: 4.462817048376372
epoch 1 iter 29940: train loss 1.39506. lr 3.000000e-04, running loss 0.60952, it/sec: 4.494564006861802
epoch 1 iter 29960: train loss 0.59284. lr 3.000000e-04, running loss 0.60951, it/sec: 4.4546325846918995
epoch 1 iter 29980: train loss 0.54805. lr 3.000000e-04, running loss 0.60930, it/sec: 4.499957763331516
epoch 1 iter 30000: train loss 0.54565. lr 3.000000e-04, running loss 0.60928, it/sec: 4.494213584664639
epoch 1 iter 30020: train loss 0.59390. lr 3.000000e-04, running loss 0.60901, it/sec: 4.484458007443216
epoch 1 iter 30040: train loss 0.65411. lr 3.000000e-04, running loss 0.60898, it/sec: 4.502013330235411
epoch 1 iter 30060: train loss 0.58049. lr 3.000000e-04, running loss 0.60906, it/sec: 4.445718330309236
epoch 1 iter 30080: train loss 0.66464. lr 3.000000e-04, running loss 0.60918, it/sec: 4.510255263116668
epoch 1 iter 30100: train loss 0.56946. lr 3.000000e-04, running loss 0.60942, it/sec: 4.4496053334223085
epoch 1 iter 30120: train loss 0.66252. lr 3.000000e-04, running loss 0.60962, it/sec: 4.489548686443122
epoch 1 iter 30140: train loss 0.53939. lr 3.000000e-04, running loss 0.60934, it/sec: 4.464371793373142
epoch 1 iter 30160: train loss 0.58788. lr 3.000000e-04, running loss 0.60938, it/sec: 4.499589836870023
epoch 1 iter 30180: train loss 0.56804. lr 3.000000e-04, running loss 0.60968, it/sec: 4.479714008874867
epoch 1 iter 30200: train loss 0.56376. lr 3.000000e-04, running loss 0.60910, it/sec: 4.4979449006859
epoch 1 iter 30220: train loss 0.57131. lr 3.000000e-04, running loss 0.60902, it/sec: 4.445515695263541
epoch 1 iter 30240: train loss 0.53780. lr 3.000000e-04, running loss 0.60850, it/sec: 4.537671407841108
epoch 1 iter 30260: train loss 0.58221. lr 3.000000e-04, running loss 0.60848, it/sec: 4.461589976934061
epoch 1 iter 30280: train loss 0.65111. lr 3.000000e-04, running loss 0.60826, it/sec: 4.510521439519672
epoch 1 iter 30300: train loss 0.57252. lr 3.000000e-04, running loss 0.60835, it/sec: 4.460897144747312
epoch 1 iter 30320: train loss 0.78908. lr 3.000000e-04, running loss 0.60889, it/sec: 4.487935451548553
epoch 1 iter 30340: train loss 0.68931. lr 3.000000e-04, running loss 0.60947, it/sec: 4.503850959394318
epoch 1 iter 30360: train loss 0.53156. lr 3.000000e-04, running loss 0.60919, it/sec: 4.443882184623209
epoch 1 iter 30380: train loss 0.60160. lr 3.000000e-04, running loss 0.60910, it/sec: 4.513927429764454
epoch 1 iter 30400: train loss 0.50948. lr 3.000000e-04, running loss 0.60882, it/sec: 4.445597948059282
epoch 1 iter 30420: train loss 0.60102. lr 3.000000e-04, running loss 0.60890, it/sec: 4.4999863560055795
epoch 1 iter 30440: train loss 0.67140. lr 3.000000e-04, running loss 0.60873, it/sec: 4.481021548984083
epoch 1 iter 30460: train loss 0.58333. lr 3.000000e-04, running loss 0.60858, it/sec: 4.5314530563483135
epoch 1 iter 30480: train loss 0.63565. lr 3.000000e-04, running loss 0.60832, it/sec: 4.454685231718932
epoch 1 iter 30500: train loss 0.55102. lr 3.000000e-04, running loss 0.60820, it/sec: 4.514807417432534
epoch 1 iter 30520: train loss 0.55007. lr 3.000000e-04, running loss 0.60769, it/sec: 4.442529320348527
epoch 1 iter 30540: train loss 0.74818. lr 3.000000e-04, running loss 0.60873, it/sec: 4.501431527699798
epoch 1 iter 30560: train loss 0.53542. lr 3.000000e-04, running loss 0.60880, it/sec: 4.420637250215435
epoch 1 iter 30580: train loss 0.58451. lr 3.000000e-04, running loss 0.60825, it/sec: 4.490536991896438
epoch 1 iter 30600: train loss 0.54898. lr 3.000000e-04, running loss 0.60841, it/sec: 4.507535741070739
epoch 1 iter 30620: train loss 0.60587. lr 3.000000e-04, running loss 0.60848, it/sec: 4.464921148502272
epoch 1 iter 30640: train loss 0.58853. lr 3.000000e-04, running loss 0.60888, it/sec: 4.50249858128544
epoch 1 iter 30660: train loss 0.59566. lr 3.000000e-04, running loss 0.60916, it/sec: 4.467197070391726
epoch 1 iter 30680: train loss 0.65605. lr 3.000000e-04, running loss 0.60943, it/sec: 4.49943530321272
epoch 1 iter 30700: train loss 0.61304. lr 3.000000e-04, running loss 0.60940, it/sec: 4.456088738996519
epoch 1 iter 30720: train loss 0.66628. lr 3.000000e-04, running loss 0.60984, it/sec: 4.511109561287227
epoch 1 iter 30740: train loss 0.53996. lr 3.000000e-04, running loss 0.60979, it/sec: 4.454460209298172
epoch 1 iter 30760: train loss 0.51970. lr 3.000000e-04, running loss 0.60975, it/sec: 4.511315453053545
epoch 1 iter 30780: train loss 0.57367. lr 3.000000e-04, running loss 0.60964, it/sec: 4.4886401530098885
epoch 1 iter 30800: train loss 0.59550. lr 3.000000e-04, running loss 0.60980, it/sec: 4.500927726733546
epoch 1 iter 30820: train loss 0.67221. lr 3.000000e-04, running loss 0.60974, it/sec: 4.46465622052563
epoch 1 iter 30840: train loss 0.64856. lr 3.000000e-04, running loss 0.60949, it/sec: 4.513420766327573
epoch 1 iter 30860: train loss 0.58057. lr 3.000000e-04, running loss 0.60902, it/sec: 4.472325158854086
epoch 1 iter 30880: train loss 0.59581. lr 3.000000e-04, running loss 0.60958, it/sec: 4.490660647829321
epoch 1 iter 30900: train loss 0.50888. lr 3.000000e-04, running loss 0.60966, it/sec: 4.469041991913819
epoch 1 iter 30920: train loss 0.59988. lr 3.000000e-04, running loss 0.60926, it/sec: 4.515099388667235
epoch 1 iter 30940: train loss 0.72494. lr 3.000000e-04, running loss 0.60928, it/sec: 4.517369301262694
epoch 1 iter 30960: train loss 0.69113. lr 3.000000e-04, running loss 0.60941, it/sec: 4.458005359916227
epoch 1 iter 30980: train loss 0.64585. lr 3.000000e-04, running loss 0.60952, it/sec: 4.48896947454651
epoch 1 iter 31000: train loss 0.59144. lr 3.000000e-04, running loss 0.60996, it/sec: 4.4631299231115555
epoch 1 iter 31020: train loss 0.68754. lr 3.000000e-04, running loss 0.60970, it/sec: 4.5122256952004
epoch 1 iter 31040: train loss 0.62931. lr 3.000000e-04, running loss 0.60947, it/sec: 4.471835369885833
epoch 1 iter 31060: train loss 0.64879. lr 3.000000e-04, running loss 0.60943, it/sec: 4.503110832412153
epoch 1 iter 31080: train loss 0.64120. lr 3.000000e-04, running loss 0.60951, it/sec: 4.482482010036572
epoch 1 iter 31100: train loss 0.65923. lr 3.000000e-04, running loss 0.60940, it/sec: 4.495498098824986
epoch 1 iter 31120: train loss 0.63039. lr 3.000000e-04, running loss 0.60943, it/sec: 4.474192855726228
epoch 1 iter 31140: train loss 0.56791. lr 3.000000e-04, running loss 0.60918, it/sec: 4.516713281719849
epoch 1 iter 31160: train loss 0.56885. lr 3.000000e-04, running loss 0.60918, it/sec: 4.451748141824169
epoch 1 iter 31180: train loss 0.54789. lr 3.000000e-04, running loss 0.60909, it/sec: 4.492319916628015
epoch 1 iter 31200: train loss 0.55735. lr 3.000000e-04, running loss 0.60957, it/sec: 4.453303391436637
epoch 1 iter 31220: train loss 0.54843. lr 3.000000e-04, running loss 0.60937, it/sec: 4.498530294871773
epoch 1 iter 31240: train loss 0.72681. lr 3.000000e-04, running loss 0.60986, it/sec: 4.454803088226712
epoch 1 iter 31260: train loss 0.57746. lr 3.000000e-04, running loss 0.61001, it/sec: 4.482501138040822
epoch 1 iter 31280: train loss 0.62911. lr 3.000000e-04, running loss 0.60987, it/sec: 4.433909553878468
epoch 1 iter 31300: train loss 0.62239. lr 3.000000e-04, running loss 0.60970, it/sec: 4.506634031434587
epoch 1 iter 31320: train loss 0.48997. lr 3.000000e-04, running loss 0.60948, it/sec: 4.439222695231146
epoch 1 iter 31340: train loss 0.59929. lr 3.000000e-04, running loss 0.60926, it/sec: 4.5238155112085785
epoch 1 iter 31360: train loss 0.59527. lr 3.000000e-04, running loss 0.60917, it/sec: 4.438095424069066
epoch 1 iter 31380: train loss 0.61534. lr 3.000000e-04, running loss 0.60907, it/sec: 4.504516739021782
epoch 1 iter 31400: train loss 0.71636. lr 3.000000e-04, running loss 0.60929, it/sec: 4.4588504550370045
epoch 1 iter 31420: train loss 0.60523. lr 3.000000e-04, running loss 0.60946, it/sec: 4.514319937986394
epoch 1 iter 31440: train loss 0.56835. lr 3.000000e-04, running loss 0.60920, it/sec: 4.48105498229635
epoch 1 iter 31460: train loss 0.56875. lr 3.000000e-04, running loss 0.60860, it/sec: 4.493780663786492
epoch 1 iter 31480: train loss 0.61218. lr 3.000000e-04, running loss 0.60833, it/sec: 4.444326066610174
epoch 1 iter 31500: train loss 0.55538. lr 3.000000e-04, running loss 0.60893, it/sec: 4.523897127541312
epoch 1 iter 31520: train loss 0.52687. lr 3.000000e-04, running loss 0.60909, it/sec: 4.444056033403905
epoch 1 iter 31540: train loss 0.58255. lr 3.000000e-04, running loss 0.60924, it/sec: 4.50958390118682
epoch 1 iter 31560: train loss 0.79549. lr 3.000000e-04, running loss 0.60936, it/sec: 4.497126422182822
epoch 1 iter 31580: train loss 0.57600. lr 3.000000e-04, running loss 0.60938, it/sec: 4.455308625113151
epoch 1 iter 31600: train loss 0.51532. lr 3.000000e-04, running loss 0.60940, it/sec: 4.522568948792491
epoch 1 iter 31620: train loss 0.59821. lr 3.000000e-04, running loss 0.60909, it/sec: 4.462691337867404
epoch 1 iter 31640: train loss 0.59787. lr 3.000000e-04, running loss 0.60885, it/sec: 4.4786835210491285
epoch 1 iter 31660: train loss 0.62431. lr 3.000000e-04, running loss 0.60889, it/sec: 4.488007700280258
epoch 1 iter 31680: train loss 0.59685. lr 3.000000e-04, running loss 0.60847, it/sec: 4.463980967610382
epoch 1 iter 31700: train loss 0.60953. lr 3.000000e-04, running loss 0.60852, it/sec: 4.510543695924683
epoch 1 iter 31720: train loss 0.59007. lr 3.000000e-04, running loss 0.60849, it/sec: 4.460852370748275
epoch 1 iter 31740: train loss 0.55428. lr 3.000000e-04, running loss 0.60928, it/sec: 4.497495158591539
epoch 1 iter 31760: train loss 0.52697. lr 3.000000e-04, running loss 0.60938, it/sec: 4.462550200065311
epoch 1 iter 31780: train loss 0.62095. lr 3.000000e-04, running loss 0.60951, it/sec: 4.492900254365968
epoch 1 iter 31800: train loss 0.61154. lr 3.000000e-04, running loss 0.60933, it/sec: 4.499396108481592
epoch 1 iter 31820: train loss 0.62375. lr 3.000000e-04, running loss 0.60948, it/sec: 4.4588629406069025
epoch 1 iter 31840: train loss 0.60344. lr 3.000000e-04, running loss 0.60951, it/sec: 4.477993252376498
epoch 1 iter 31860: train loss 0.68232. lr 3.000000e-04, running loss 0.60914, it/sec: 4.465785839486158
epoch 1 iter 31880: train loss 0.57799. lr 3.000000e-04, running loss 0.60903, it/sec: 4.5289992911036645
epoch 1 iter 31900: train loss 0.47683. lr 3.000000e-04, running loss 0.60874, it/sec: 4.466952805097571
epoch 1 iter 31920: train loss 0.71409. lr 3.000000e-04, running loss 0.60885, it/sec: 4.496054271981839
epoch 1 iter 31940: train loss 0.55237. lr 3.000000e-04, running loss 0.60921, it/sec: 4.438520793924497
epoch 1 iter 31960: train loss 0.53887. lr 3.000000e-04, running loss 0.60922, it/sec: 4.513452709374308
epoch 1 iter 31980: train loss 0.72485. lr 3.000000e-04, running loss 0.60928, it/sec: 4.4648001429449655
epoch 1 iter 32000: train loss 0.56110. lr 3.000000e-04, running loss 0.60932, it/sec: 4.531431187147621
epoch 1 iter 32020: train loss 0.56298. lr 3.000000e-04, running loss 0.61082, it/sec: 4.444579501129649
epoch 1 iter 32040: train loss 0.76050. lr 3.000000e-04, running loss 0.61118, it/sec: 4.5064255205413986
epoch 1 iter 32060: train loss 0.55090. lr 3.000000e-04, running loss 0.61192, it/sec: 4.460095295194387
epoch 1 iter 32080: train loss 0.60131. lr 3.000000e-04, running loss 0.61194, it/sec: 4.511573083220825
epoch 1 iter 32100: train loss 0.59375. lr 3.000000e-04, running loss 0.61440, it/sec: 4.454121687058175
epoch 1 iter 32120: train loss 0.61616. lr 3.000000e-04, running loss 0.61393, it/sec: 4.519475572529283
epoch 1 iter 32140: train loss 0.59599. lr 3.000000e-04, running loss 0.61395, it/sec: 4.464014883677337
epoch 1 iter 32160: train loss 0.57104. lr 3.000000e-04, running loss 0.61423, it/sec: 4.473994422161494
epoch 1 iter 32180: train loss 0.60514. lr 3.000000e-04, running loss 0.61416, it/sec: 4.509978399908262
epoch 1 iter 32200: train loss 0.59002. lr 3.000000e-04, running loss 0.61412, it/sec: 4.43897273057594
epoch 1 iter 32220: train loss 0.55419. lr 3.000000e-04, running loss 0.61405, it/sec: 4.4992972367640816
epoch 1 iter 32240: train loss 0.69375. lr 3.000000e-04, running loss 0.61412, it/sec: 4.458337773842157
epoch 1 iter 32260: train loss 0.60196. lr 3.000000e-04, running loss 0.61418, it/sec: 4.48773672326012
epoch 1 iter 32280: train loss 0.56660. lr 3.000000e-04, running loss 0.61397, it/sec: 4.503055251105843
epoch 1 iter 32300: train loss 0.57774. lr 3.000000e-04, running loss 0.61415, it/sec: 4.446163984169747
epoch 1 iter 32320: train loss 0.56058. lr 3.000000e-04, running loss 0.61413, it/sec: 4.463196673590665
epoch 1 iter 32340: train loss 0.60358. lr 3.000000e-04, running loss 0.61445, it/sec: 4.505596379885721
epoch 1 iter 32360: train loss 0.62384. lr 3.000000e-04, running loss 0.61461, it/sec: 4.462449953992713
epoch 1 iter 32380: train loss 0.56285. lr 3.000000e-04, running loss 0.61450, it/sec: 4.51862641292846
epoch 1 iter 32400: train loss 0.63194. lr 3.000000e-04, running loss 0.61428, it/sec: 4.457691713468935
epoch 1 iter 32420: train loss 0.56133. lr 3.000000e-04, running loss 0.61435, it/sec: 4.46843737118056
epoch 1 iter 32440: train loss 0.51738. lr 3.000000e-04, running loss 0.61438, it/sec: 4.459174366465122
epoch 1 iter 32460: train loss 0.73025. lr 3.000000e-04, running loss 0.61414, it/sec: 4.50581350464801
epoch 1 iter 32480: train loss 0.57868. lr 3.000000e-04, running loss 0.61415, it/sec: 4.467739076333074
epoch 1 iter 32500: train loss 0.66736. lr 3.000000e-04, running loss 0.61401, it/sec: 4.500516114630361
epoch 1 iter 32520: train loss 0.58221. lr 3.000000e-04, running loss 0.61379, it/sec: 4.498039483929958
epoch 1 iter 32540: train loss 0.54741. lr 3.000000e-04, running loss 0.61338, it/sec: 4.469361612949528
epoch 1 iter 32560: train loss 0.57249. lr 3.000000e-04, running loss 0.61312, it/sec: 4.511795790579971
epoch 1 iter 32580: train loss 0.52208. lr 3.000000e-04, running loss 0.61316, it/sec: 4.501818642847179
epoch 1 iter 32600: train loss 0.57906. lr 3.000000e-04, running loss 0.61363, it/sec: 4.469521000495315
epoch 1 iter 32620: train loss 0.69322. lr 3.000000e-04, running loss 0.61317, it/sec: 4.48389719901812
epoch 1 iter 32640: train loss 0.62390. lr 3.000000e-04, running loss 0.61288, it/sec: 4.484595445615674
epoch 1 iter 32660: train loss 0.68598. lr 3.000000e-04, running loss 0.61276, it/sec: 4.44519097933134
epoch 1 iter 32680: train loss 0.67927. lr 3.000000e-04, running loss 0.61338, it/sec: 4.502175744228021
epoch 1 iter 32700: train loss 0.61589. lr 3.000000e-04, running loss 0.61325, it/sec: 4.495119928906211
epoch 1 iter 32720: train loss 0.60048. lr 3.000000e-04, running loss 0.61289, it/sec: 4.446450900590026
epoch 1 iter 32740: train loss 0.57576. lr 3.000000e-04, running loss 0.61324, it/sec: 4.477686771243273
epoch 1 iter 32760: train loss 0.64175. lr 3.000000e-04, running loss 0.61266, it/sec: 4.468988925944509
epoch 1 iter 32780: train loss 0.66406. lr 3.000000e-04, running loss 0.61260, it/sec: 4.464528272782459
epoch 1 iter 32800: train loss 0.60347. lr 3.000000e-04, running loss 0.61278, it/sec: 4.514810434640584
epoch 1 iter 32820: train loss 0.58215. lr 3.000000e-04, running loss 0.61285, it/sec: 4.47345737984168
epoch 1 iter 32840: train loss 0.70695. lr 3.000000e-04, running loss 0.61315, it/sec: 4.515694150625217
epoch 1 iter 32860: train loss 0.60330. lr 3.000000e-04, running loss 0.61286, it/sec: 4.4615595226809335
epoch 1 iter 32880: train loss 0.68320. lr 3.000000e-04, running loss 0.61287, it/sec: 4.503985774884724
epoch 1 iter 32900: train loss 0.63378. lr 3.000000e-04, running loss 0.61284, it/sec: 4.451045285358576
epoch 1 iter 32920: train loss 0.77923. lr 3.000000e-04, running loss 0.61288, it/sec: 4.519001461586669
epoch 1 iter 32940: train loss 0.63044. lr 3.000000e-04, running loss 0.61285, it/sec: 4.435758146456703
epoch 1 iter 32960: train loss 0.57652. lr 3.000000e-04, running loss 0.61242, it/sec: 4.477514531377147
epoch 1 iter 32980: train loss 0.54701. lr 3.000000e-04, running loss 0.61205, it/sec: 4.478483045180778
epoch 1 iter 33000: train loss 0.73763. lr 3.000000e-04, running loss 0.61211, it/sec: 4.445472455730908
epoch 1 iter 33020: train loss 0.61913. lr 3.000000e-04, running loss 0.61240, it/sec: 4.502093633218089
epoch 1 iter 33040: train loss 0.61696. lr 3.000000e-04, running loss 0.61221, it/sec: 4.465018197187677
epoch 1 iter 33060: train loss 0.62953. lr 3.000000e-04, running loss 0.61196, it/sec: 4.4592125441214145
epoch 1 iter 33080: train loss 0.62500. lr 3.000000e-04, running loss 0.61156, it/sec: 4.448979121112958
epoch 1 iter 33100: train loss 0.62886. lr 3.000000e-04, running loss 0.61138, it/sec: 4.511128060203575
epoch 1 iter 33120: train loss 0.58878. lr 3.000000e-04, running loss 0.61138, it/sec: 4.460381844643876
epoch 1 iter 33140: train loss 0.57047. lr 3.000000e-04, running loss 0.61140, it/sec: 4.494635439086001
epoch 1 iter 33160: train loss 0.55695. lr 3.000000e-04, running loss 0.61142, it/sec: 4.488580779222308
epoch 1 iter 33180: train loss 0.57940. lr 3.000000e-04, running loss 0.61175, it/sec: 4.51968782549983
epoch 1 iter 33200: train loss 0.75455. lr 3.000000e-04, running loss 0.61155, it/sec: 4.451192928529231
epoch 1 iter 33220: train loss 0.64254. lr 3.000000e-04, running loss 0.61138, it/sec: 4.5094063922941325
epoch 1 iter 33240: train loss 0.61547. lr 3.000000e-04, running loss 0.61138, it/sec: 4.503920861665639
epoch 1 iter 33260: train loss 0.61641. lr 3.000000e-04, running loss 0.61093, it/sec: 4.462219726042926
epoch 1 iter 33280: train loss 0.59751. lr 3.000000e-04, running loss 0.61094, it/sec: 4.50213433322176
epoch 1 iter 33300: train loss 0.61539. lr 3.000000e-04, running loss 0.61098, it/sec: 4.44316485310913
epoch 1 iter 33320: train loss 0.61001. lr 3.000000e-04, running loss 0.61101, it/sec: 4.519060601589146
epoch 1 iter 33340: train loss 0.60253. lr 3.000000e-04, running loss 0.61093, it/sec: 4.482516831196117
epoch 1 iter 33360: train loss 0.62173. lr 3.000000e-04, running loss 0.61086, it/sec: 4.454783561711146
epoch 1 iter 33380: train loss 0.54027. lr 3.000000e-04, running loss 0.61082, it/sec: 4.508894867778
epoch 1 iter 33400: train loss 0.57894. lr 3.000000e-04, running loss 0.61052, it/sec: 4.439838891616038
epoch 1 iter 33420: train loss 0.59698. lr 3.000000e-04, running loss 0.61063, it/sec: 4.517614989458854
epoch 1 iter 33440: train loss 0.68001. lr 3.000000e-04, running loss 0.61068, it/sec: 4.464016817279856
epoch 1 iter 33460: train loss 0.72231. lr 3.000000e-04, running loss 0.61092, it/sec: 4.5031000441727596
epoch 1 iter 33480: train loss 0.70630. lr 3.000000e-04, running loss 0.61106, it/sec: 4.441836730775806
epoch 1 iter 33500: train loss 0.60269. lr 3.000000e-04, running loss 0.61126, it/sec: 4.520831917108797
epoch 1 iter 33520: train loss 0.56571. lr 3.000000e-04, running loss 0.61122, it/sec: 4.4302232500721
epoch 1 iter 33540: train loss 0.53825. lr 3.000000e-04, running loss 0.61104, it/sec: 4.479631030790101
epoch 1 iter 33560: train loss 0.68942. lr 3.000000e-04, running loss 0.61135, it/sec: 4.491142485920701
epoch 1 iter 33580: train loss 0.72241. lr 3.000000e-04, running loss 0.61121, it/sec: 4.489631266204153
epoch 1 iter 33600: train loss 0.57606. lr 3.000000e-04, running loss 0.61124, it/sec: 4.497494874839774
epoch 1 iter 33620: train loss 0.56144. lr 3.000000e-04, running loss 0.61146, it/sec: 4.436744051113788
epoch 1 iter 33640: train loss 0.69148. lr 3.000000e-04, running loss 0.61159, it/sec: 4.515185929956203
epoch 1 iter 33660: train loss 0.63544. lr 3.000000e-04, running loss 0.61120, it/sec: 4.416229253822373
epoch 1 iter 33680: train loss 0.64286. lr 3.000000e-04, running loss 0.61150, it/sec: 4.485683647552983
epoch 1 iter 33700: train loss 0.54608. lr 3.000000e-04, running loss 0.61142, it/sec: 4.472987011645235
epoch 1 iter 33720: train loss 0.66374. lr 3.000000e-04, running loss 0.61117, it/sec: 4.460282133685928
epoch 1 iter 33740: train loss 0.54288. lr 3.000000e-04, running loss 0.61083, it/sec: 4.525115364849107
epoch 1 iter 33760: train loss 0.57016. lr 3.000000e-04, running loss 0.61068, it/sec: 4.46296513500205
epoch 1 iter 33780: train loss 0.56076. lr 3.000000e-04, running loss 0.61037, it/sec: 4.487441352701132
epoch 1 iter 33800: train loss 0.57562. lr 3.000000e-04, running loss 0.61047, it/sec: 4.430060352876205
epoch 1 iter 33820: train loss 0.59376. lr 3.000000e-04, running loss 0.61051, it/sec: 4.501378479969066
epoch 1 iter 33840: train loss 0.63864. lr 3.000000e-04, running loss 0.61046, it/sec: 4.4597654636652795
epoch 1 iter 33860: train loss 0.60198. lr 3.000000e-04, running loss 0.61020, it/sec: 4.510406370280145
epoch 1 iter 33880: train loss 0.71302. lr 3.000000e-04, running loss 0.61017, it/sec: 4.46336371101022
epoch 1 iter 33900: train loss 0.52629. lr 3.000000e-04, running loss 0.60989, it/sec: 4.506620363075523
epoch 1 iter 33920: train loss 0.59609. lr 3.000000e-04, running loss 0.60964, it/sec: 4.500688771608808
epoch 1 iter 33940: train loss 0.64775. lr 3.000000e-04, running loss 0.60995, it/sec: 4.4465188931867825
epoch 1 iter 33960: train loss 0.67129. lr 3.000000e-04, running loss 0.61016, it/sec: 4.496274175385582
epoch 1 iter 33980: train loss 0.57740. lr 3.000000e-04, running loss 0.61005, it/sec: 4.476480887487531
epoch 1 iter 34000: train loss 0.54700. lr 3.000000e-04, running loss 0.61014, it/sec: 4.508705215944872
epoch 1 iter 34020: train loss 0.59625. lr 3.000000e-04, running loss 0.61015, it/sec: 4.449308131098558
epoch 1 iter 34040: train loss 0.65954. lr 3.000000e-04, running loss 0.61055, it/sec: 4.502950641814754
epoch 1 iter 34060: train loss 0.59039. lr 3.000000e-04, running loss 0.61032, it/sec: 4.421308366704927
epoch 1 iter 34080: train loss 0.57012. lr 3.000000e-04, running loss 0.61027, it/sec: 4.49683029930559
epoch 1 iter 34100: train loss 0.67895. lr 3.000000e-04, running loss 0.61023, it/sec: 4.466804093699043
epoch 1 iter 34120: train loss 0.60365. lr 3.000000e-04, running loss 0.61039, it/sec: 4.503658689159331
epoch 1 iter 34140: train loss 0.60636. lr 3.000000e-04, running loss 0.61059, it/sec: 4.444393185960942
epoch 1 iter 34160: train loss 0.61271. lr 3.000000e-04, running loss 0.61051, it/sec: 4.514717731192783
epoch 1 iter 34180: train loss 0.58050. lr 3.000000e-04, running loss 0.61068, it/sec: 4.496506453931575
epoch 1 iter 34200: train loss 0.55880. lr 3.000000e-04, running loss 0.61103, it/sec: 4.450749832380907
epoch 1 iter 34220: train loss 0.56504. lr 3.000000e-04, running loss 0.61079, it/sec: 4.51615261876507
epoch 1 iter 34240: train loss 0.54847. lr 3.000000e-04, running loss 0.61042, it/sec: 4.443988827674247
epoch 1 iter 34260: train loss 0.56562. lr 3.000000e-04, running loss 0.61071, it/sec: 4.496900085045012
epoch 1 iter 34280: train loss 0.60055. lr 3.000000e-04, running loss 0.61094, it/sec: 4.490160827366638
epoch 1 iter 34300: train loss 0.56034. lr 3.000000e-04, running loss 0.61078, it/sec: 4.43826941086172
epoch 1 iter 34320: train loss 0.61224. lr 3.000000e-04, running loss 0.61064, it/sec: 4.498561094557623
epoch 1 iter 34340: train loss 0.68581. lr 3.000000e-04, running loss 0.61044, it/sec: 4.410046493446299
epoch 1 iter 34360: train loss 0.54738. lr 3.000000e-04, running loss 0.61070, it/sec: 4.485928034158334
epoch 1 iter 34380: train loss 0.61955. lr 3.000000e-04, running loss 0.61069, it/sec: 4.455194373116368
epoch 1 iter 34400: train loss 0.61767. lr 3.000000e-04, running loss 0.61059, it/sec: 4.5064226977512485
epoch 1 iter 34420: train loss 0.58254. lr 3.000000e-04, running loss 0.61061, it/sec: 4.437513187092316
epoch 1 iter 34440: train loss 0.59555. lr 3.000000e-04, running loss 0.61062, it/sec: 4.417285441620395
epoch 1 iter 34460: train loss 0.59880. lr 3.000000e-04, running loss 0.61001, it/sec: 4.508241531864819
epoch 1 iter 34480: train loss 0.55527. lr 3.000000e-04, running loss 0.61058, it/sec: 4.4657992612688275
epoch 1 iter 34500: train loss 0.60829. lr 3.000000e-04, running loss 0.61020, it/sec: 4.479401072879533
epoch 1 iter 34520: train loss 0.68788. lr 3.000000e-04, running loss 0.61075, it/sec: 4.4812199448054315
epoch 1 iter 34540: train loss 0.57863. lr 3.000000e-04, running loss 0.61073, it/sec: 4.444585190598868
epoch 1 iter 34560: train loss 0.59341. lr 3.000000e-04, running loss 0.61046, it/sec: 4.510900433518188
epoch 1 iter 34580: train loss 0.58846. lr 3.000000e-04, running loss 0.61002, it/sec: 4.444190513042529
epoch 1 iter 34600: train loss 0.64535. lr 3.000000e-04, running loss 0.61024, it/sec: 4.49137465842999
epoch 1 iter 34620: train loss 0.74293. lr 3.000000e-04, running loss 0.61029, it/sec: 4.484633859620296
epoch 1 iter 34640: train loss 0.67693. lr 3.000000e-04, running loss 0.61065, it/sec: 4.468957331325088
epoch 1 iter 34660: train loss 0.68953. lr 3.000000e-04, running loss 0.61076, it/sec: 4.493457077677225
epoch 1 iter 34680: train loss 0.56043. lr 3.000000e-04, running loss 0.61064, it/sec: 4.487867212258034
epoch 1 iter 34700: train loss 0.60535. lr 3.000000e-04, running loss 0.61054, it/sec: 4.499021838556825
epoch 1 iter 34720: train loss 0.73768. lr 3.000000e-04, running loss 0.61075, it/sec: 4.476748923862079
epoch 1 iter 34740: train loss 0.59169. lr 3.000000e-04, running loss 0.61045, it/sec: 4.511112715698872
epoch 1 iter 34760: train loss 0.62238. lr 3.000000e-04, running loss 0.61050, it/sec: 4.449249416487437
epoch 1 iter 34780: train loss 0.54663. lr 3.000000e-04, running loss 0.61123, it/sec: 4.500142448143178
epoch 1 iter 34800: train loss 0.61604. lr 3.000000e-04, running loss 0.61145, it/sec: 4.440199436038118
epoch 1 iter 34820: train loss 0.63202. lr 3.000000e-04, running loss 0.61137, it/sec: 4.483930211815771
epoch 1 iter 34840: train loss 0.66234. lr 3.000000e-04, running loss 0.61138, it/sec: 4.490432338999406
epoch 1 iter 34860: train loss 0.63465. lr 3.000000e-04, running loss 0.61147, it/sec: 4.459226542180462
epoch 1 iter 34880: train loss 0.59279. lr 3.000000e-04, running loss 0.61169, it/sec: 4.455783859690967
epoch 1 iter 34900: train loss 0.58603. lr 3.000000e-04, running loss 0.61122, it/sec: 4.46203615089897
epoch 1 iter 34920: train loss 0.62288. lr 3.000000e-04, running loss 0.61057, it/sec: 4.501486500418427
epoch 1 iter 34940: train loss 0.56343. lr 3.000000e-04, running loss 0.61094, it/sec: 4.459444886934084
epoch 1 iter 34960: train loss 0.61253. lr 3.000000e-04, running loss 0.61090, it/sec: 4.522530229798216
epoch 1 iter 34980: train loss 0.70842. lr 3.000000e-04, running loss 0.61138, it/sec: 4.455546954826348
epoch 1 iter 35000: train loss 0.62150. lr 3.000000e-04, running loss 0.61136, it/sec: 4.5117498255064845
epoch 1 iter 35020: train loss 0.49653. lr 3.000000e-04, running loss 0.61085, it/sec: 4.395628276954799
epoch 1 iter 35040: train loss 0.62197. lr 3.000000e-04, running loss 0.61090, it/sec: 4.496694414719343
epoch 1 iter 35060: train loss 0.58252. lr 3.000000e-04, running loss 0.61065, it/sec: 4.447760062123368
epoch 1 iter 35080: train loss 0.56619. lr 3.000000e-04, running loss 0.61015, it/sec: 4.489806052940853
epoch 1 iter 35100: train loss 0.55790. lr 3.000000e-04, running loss 0.61029, it/sec: 4.457691315582978
epoch 1 iter 35120: train loss 0.54183. lr 3.000000e-04, running loss 0.61009, it/sec: 4.456462473779008
epoch 1 iter 35140: train loss 0.60711. lr 3.000000e-04, running loss 0.61018, it/sec: 4.520138216291762
epoch 1 iter 35160: train loss 0.61468. lr 3.000000e-04, running loss 0.61022, it/sec: 4.429564336937784
epoch 1 iter 35180: train loss 0.65313. lr 3.000000e-04, running loss 0.61026, it/sec: 4.521192920677484
epoch 1 iter 35200: train loss 0.62280. lr 3.000000e-04, running loss 0.61017, it/sec: 4.464327707136918
epoch 1 iter 35220: train loss 0.65771. lr 3.000000e-04, running loss 0.61037, it/sec: 4.484095044336908
epoch 1 iter 35240: train loss 0.57226. lr 3.000000e-04, running loss 0.61018, it/sec: 4.48303088663516
epoch 1 iter 35260: train loss 0.62907. lr 3.000000e-04, running loss 0.61030, it/sec: 4.474564647948112
epoch 1 iter 35280: train loss 0.59580. lr 3.000000e-04, running loss 0.61011, it/sec: 4.432874110423151
epoch 1 iter 35300: train loss 0.67533. lr 3.000000e-04, running loss 0.60982, it/sec: 4.518734487849538
epoch 1 iter 35320: train loss 0.59360. lr 3.000000e-04, running loss 0.60956, it/sec: 4.482236832835227
epoch 1 iter 35340: train loss 0.61503. lr 3.000000e-04, running loss 0.60998, it/sec: 4.455834548472183
epoch 1 iter 35360: train loss 0.66790. lr 3.000000e-04, running loss 0.61038, it/sec: 4.485126294740377
epoch 1 iter 35380: train loss 0.62967. lr 3.000000e-04, running loss 0.61029, it/sec: 4.454045010094654
epoch 1 iter 35400: train loss 0.68674. lr 3.000000e-04, running loss 0.61043, it/sec: 4.498089215479207
epoch 1 iter 35420: train loss 0.60812. lr 3.000000e-04, running loss 0.61049, it/sec: 4.429225134474561
epoch 1 iter 35440: train loss 0.57267. lr 3.000000e-04, running loss 0.60987, it/sec: 4.4707495792406435
epoch 1 iter 35460: train loss 0.70583. lr 3.000000e-04, running loss 0.60991, it/sec: 4.5123316923183525
epoch 1 iter 35480: train loss 0.59418. lr 3.000000e-04, running loss 0.61001, it/sec: 4.456022974171951
epoch 1 iter 35500: train loss 0.65208. lr 3.000000e-04, running loss 0.60975, it/sec: 4.501920726871925
epoch 1 iter 35520: train loss 0.64750. lr 3.000000e-04, running loss 0.60982, it/sec: 4.4718035545895285
epoch 1 iter 35540: train loss 0.53292. lr 3.000000e-04, running loss 0.60963, it/sec: 4.49753753455271
epoch 1 iter 35560: train loss 0.59574. lr 3.000000e-04, running loss 0.60967, it/sec: 4.476253777908465
epoch 1 iter 35580: train loss 0.60998. lr 3.000000e-04, running loss 0.60935, it/sec: 4.496098663479509
epoch 1 iter 35600: train loss 0.55337. lr 3.000000e-04, running loss 0.60955, it/sec: 4.447917516501868
epoch 1 iter 35620: train loss 0.54959. lr 3.000000e-04, running loss 0.60956, it/sec: 4.506612197801464
epoch 1 iter 35640: train loss 0.68408. lr 3.000000e-04, running loss 0.60979, it/sec: 4.450113691155431
epoch 1 iter 35660: train loss 0.55285. lr 3.000000e-04, running loss 0.61075, it/sec: 4.477361227896759
epoch 1 iter 35680: train loss 0.52284. lr 3.000000e-04, running loss 0.61029, it/sec: 4.4589040963826
epoch 1 iter 35700: train loss 0.55238. lr 3.000000e-04, running loss 0.61005, it/sec: 4.479852601442691
epoch 1 iter 35720: train loss 0.62472. lr 3.000000e-04, running loss 0.61043, it/sec: 4.498971682271967
epoch 1 iter 35740: train loss 0.68811. lr 3.000000e-04, running loss 0.61043, it/sec: 4.447232700986924
epoch 1 iter 35760: train loss 0.58748. lr 3.000000e-04, running loss 0.61055, it/sec: 4.500421690103725
epoch 1 iter 35780: train loss 0.51897. lr 3.000000e-04, running loss 0.61036, it/sec: 4.443948439919134
epoch 1 iter 35800: train loss 0.66833. lr 3.000000e-04, running loss 0.61026, it/sec: 4.514737013101434
epoch 1 iter 35820: train loss 0.67108. lr 3.000000e-04, running loss 0.60993, it/sec: 4.447259381915734
epoch 1 iter 35840: train loss 0.56257. lr 3.000000e-04, running loss 0.60973, it/sec: 4.482259374648574
epoch 1 iter 35860: train loss 0.64556. lr 3.000000e-04, running loss 0.60917, it/sec: 4.4830014444891235
epoch 1 iter 35880: train loss 0.62483. lr 3.000000e-04, running loss 0.60930, it/sec: 4.462881818617719
epoch 1 iter 35900: train loss 0.65684. lr 3.000000e-04, running loss 0.60903, it/sec: 4.462098150643134
epoch 1 iter 35920: train loss 0.59575. lr 3.000000e-04, running loss 0.60917, it/sec: 4.48973612464507
epoch 1 iter 35940: train loss 0.56836. lr 3.000000e-04, running loss 0.60936, it/sec: 4.507547463589278
epoch 1 iter 35960: train loss 0.59360. lr 3.000000e-04, running loss 0.60951, it/sec: 4.443048103389412
epoch 1 iter 35980: train loss 0.59924. lr 3.000000e-04, running loss 0.60932, it/sec: 4.485546724733122
epoch 1 iter 36000: train loss 0.69057. lr 3.000000e-04, running loss 0.60937, it/sec: 4.4503231437656545
epoch 1 iter 36020: train loss 0.55941. lr 3.000000e-04, running loss 0.60950, it/sec: 4.48104331652076
epoch 1 iter 36040: train loss 0.69403. lr 3.000000e-04, running loss 0.60944, it/sec: 4.504355332351216
epoch 1 iter 36060: train loss 0.61566. lr 3.000000e-04, running loss 0.60927, it/sec: 4.456977604022633
epoch 1 iter 36080: train loss 0.60477. lr 3.000000e-04, running loss 0.60933, it/sec: 4.514060505484177
epoch 1 iter 36100: train loss 0.54613. lr 3.000000e-04, running loss 0.60880, it/sec: 4.443322989001225
epoch 1 iter 36120: train loss 0.57835. lr 3.000000e-04, running loss 0.60903, it/sec: 4.5185251219705975
epoch 1 iter 36140: train loss 0.63414. lr 3.000000e-04, running loss 0.60933, it/sec: 4.478167794795668
epoch 1 iter 36160: train loss 0.63700. lr 3.000000e-04, running loss 0.60968, it/sec: 4.49194179731844
epoch 1 iter 36180: train loss 0.57317. lr 3.000000e-04, running loss 0.60953, it/sec: 4.439413917249313
epoch 1 iter 36200: train loss 0.56885. lr 3.000000e-04, running loss 0.60983, it/sec: 4.478622183886002
epoch 1 iter 36220: train loss 0.46873. lr 3.000000e-04, running loss 0.60962, it/sec: 4.4878859231651145
epoch 1 iter 36240: train loss 0.55769. lr 3.000000e-04, running loss 0.60921, it/sec: 4.471550027311697
epoch 1 iter 36260: train loss 0.54949. lr 3.000000e-04, running loss 0.60896, it/sec: 4.515875826398557
epoch 1 iter 36280: train loss 0.70457. lr 3.000000e-04, running loss 0.60950, it/sec: 4.456268131960001
epoch 1 iter 36300: train loss 0.62498. lr 3.000000e-04, running loss 0.60935, it/sec: 4.497693194265999
epoch 1 iter 36320: train loss 0.59311. lr 3.000000e-04, running loss 0.60957, it/sec: 4.47029698736547
epoch 1 iter 36340: train loss 0.66264. lr 3.000000e-04, running loss 0.60959, it/sec: 4.451251198525676
epoch 1 iter 36360: train loss 0.58027. lr 3.000000e-04, running loss 0.61013, it/sec: 4.490044760951509
epoch 1 iter 36380: train loss 0.58653. lr 3.000000e-04, running loss 0.61001, it/sec: 4.464845494022488
epoch 1 iter 36400: train loss 0.63472. lr 3.000000e-04, running loss 0.60960, it/sec: 4.516642371458851
epoch 1 iter 36420: train loss 0.59009. lr 3.000000e-04, running loss 0.60974, it/sec: 4.434516547348457
epoch 1 iter 36440: train loss 0.63611. lr 3.000000e-04, running loss 0.60963, it/sec: 4.488947188917494
epoch 1 iter 36460: train loss 0.61631. lr 3.000000e-04, running loss 0.60957, it/sec: 4.480134088357113
epoch 1 iter 36480: train loss 0.46252. lr 3.000000e-04, running loss 0.60956, it/sec: 4.499503406875231
epoch 1 iter 36500: train loss 0.60634. lr 3.000000e-04, running loss 0.60967, it/sec: 4.45337175191869
epoch 1 iter 36520: train loss 0.64475. lr 3.000000e-04, running loss 0.60993, it/sec: 4.485573183412186
epoch 1 iter 36540: train loss 0.59251. lr 3.000000e-04, running loss 0.60987, it/sec: 4.497976987766075
epoch 1 iter 36560: train loss 0.56743. lr 3.000000e-04, running loss 0.60933, it/sec: 4.456670398366203
epoch 1 iter 36580: train loss 0.59371. lr 3.000000e-04, running loss 0.60960, it/sec: 4.509713426406112
epoch 1 iter 36600: train loss 0.55145. lr 3.000000e-04, running loss 0.60986, it/sec: 4.456724285555761
epoch 1 iter 36620: train loss 0.55850. lr 3.000000e-04, running loss 0.60979, it/sec: 4.497452498505107
epoch 1 iter 36640: train loss 0.65380. lr 3.000000e-04, running loss 0.61012, it/sec: 4.450634209116217
epoch 1 iter 36660: train loss 0.60023. lr 3.000000e-04, running loss 0.61026, it/sec: 4.454664612380277
epoch 1 iter 36680: train loss 0.56029. lr 3.000000e-04, running loss 0.60993, it/sec: 4.494351723758147
epoch 1 iter 36700: train loss 0.58144. lr 3.000000e-04, running loss 0.60949, it/sec: 4.452471280262779
epoch 1 iter 36720: train loss 0.67041. lr 3.000000e-04, running loss 0.60921, it/sec: 4.50494921606288
epoch 1 iter 36740: train loss 0.56182. lr 3.000000e-04, running loss 0.60930, it/sec: 4.427654150816399
epoch 1 iter 36760: train loss 0.63254. lr 3.000000e-04, running loss 0.61014, it/sec: 4.46743940724383
epoch 1 iter 36780: train loss 0.56812. lr 3.000000e-04, running loss 0.61015, it/sec: 4.45071643351016
epoch 1 iter 36800: train loss 0.62769. lr 3.000000e-04, running loss 0.60996, it/sec: 4.502994257247069
epoch 1 iter 36820: train loss 0.60816. lr 3.000000e-04, running loss 0.60983, it/sec: 4.424529381780194
epoch 1 iter 36840: train loss 0.48209. lr 3.000000e-04, running loss 0.60934, it/sec: 4.499528958064777
epoch 1 iter 36860: train loss 0.64028. lr 3.000000e-04, running loss 0.60940, it/sec: 4.485242831850345
epoch 1 iter 36880: train loss 0.52779. lr 3.000000e-04, running loss 0.60948, it/sec: 4.452515093404408
epoch 1 iter 36900: train loss 0.55725. lr 3.000000e-04, running loss 0.60981, it/sec: 4.51535041727052
epoch 1 iter 36920: train loss 0.68127. lr 3.000000e-04, running loss 0.60989, it/sec: 4.447543610777901
epoch 1 iter 36940: train loss 0.54092. lr 3.000000e-04, running loss 0.60960, it/sec: 4.495204756797422
epoch 1 iter 36960: train loss 0.65734. lr 3.000000e-04, running loss 0.61061, it/sec: 4.469738036896686
epoch 1 iter 36980: train loss 0.63598. lr 3.000000e-04, running loss 0.61066, it/sec: 4.480844113579549
epoch 1 iter 37000: train loss 0.51229. lr 3.000000e-04, running loss 0.61027, it/sec: 4.509131604988768
epoch 1 iter 37020: train loss 0.60358. lr 3.000000e-04, running loss 0.61033, it/sec: 4.424097841682541
epoch 1 iter 37040: train loss 0.62323. lr 3.000000e-04, running loss 0.61024, it/sec: 4.506614371816091
epoch 1 iter 37060: train loss 0.61560. lr 3.000000e-04, running loss 0.61007, it/sec: 4.473399266664814
epoch 1 iter 37080: train loss 0.65263. lr 3.000000e-04, running loss 0.61031, it/sec: 4.494814797502097
epoch 1 iter 37100: train loss 0.61635. lr 3.000000e-04, running loss 0.61028, it/sec: 4.4658681069256785
epoch 1 iter 37120: train loss 0.46487. lr 3.000000e-04, running loss 0.61005, it/sec: 4.517959292253553
epoch 1 iter 37140: train loss 0.67034. lr 3.000000e-04, running loss 0.60990, it/sec: 4.434833096569568
epoch 1 iter 37160: train loss 0.53035. lr 3.000000e-04, running loss 0.60963, it/sec: 4.497513363520279
epoch 1 iter 37180: train loss 0.65535. lr 3.000000e-04, running loss 0.60955, it/sec: 4.486447060856938
epoch 1 iter 37200: train loss 0.66992. lr 3.000000e-04, running loss 0.60969, it/sec: 4.455580345346187
epoch 1 iter 37220: train loss 0.55434. lr 3.000000e-04, running loss 0.60995, it/sec: 4.504745995680407
epoch 1 iter 37240: train loss 0.54362. lr 3.000000e-04, running loss 0.60988, it/sec: 4.4649970039810905
epoch 1 iter 37260: train loss 0.57052. lr 3.000000e-04, running loss 0.60986, it/sec: 4.5054230224303735
epoch 1 iter 37280: train loss 0.58266. lr 3.000000e-04, running loss 0.61002, it/sec: 4.463847778958548
epoch 1 iter 37300: train loss 0.57883. lr 3.000000e-04, running loss 0.61024, it/sec: 4.48108841610752
epoch 1 iter 37320: train loss 0.55129. lr 3.000000e-04, running loss 0.61062, it/sec: 4.5022561757131365
epoch 1 iter 37340: train loss 0.70754. lr 3.000000e-04, running loss 0.61060, it/sec: 4.464268873866926
epoch 1 iter 37360: train loss 0.70696. lr 3.000000e-04, running loss 0.61110, it/sec: 4.474042982600933
epoch 1 iter 37380: train loss 0.60920. lr 3.000000e-04, running loss 0.61198, it/sec: 4.459577077880457
epoch 1 iter 37400: train loss 0.62274. lr 3.000000e-04, running loss 0.61163, it/sec: 4.489035368581249
epoch 1 iter 37420: train loss 0.55044. lr 3.000000e-04, running loss 0.61137, it/sec: 4.433212929398294
epoch 1 iter 37440: train loss 2.61141. lr 3.000000e-04, running loss 0.61342, it/sec: 4.509740842178171
epoch 1 iter 37460: train loss 0.58883. lr 3.000000e-04, running loss 0.61325, it/sec: 4.475380621952481
epoch 1 iter 37480: train loss 0.65136. lr 3.000000e-04, running loss 0.61313, it/sec: 4.493335871970608
epoch 1 iter 37500: train loss 0.91204. lr 3.000000e-04, running loss 0.61312, it/sec: 1.1710951416436526
epoch 1 iter 37520: train loss 0.54948. lr 3.000000e-04, running loss 0.61328, it/sec: 4.505029645080326
epoch 1 iter 37540: train loss 0.63513. lr 3.000000e-04, running loss 0.61446, it/sec: 4.454998533774395
epoch 1 iter 37560: train loss 0.59624. lr 3.000000e-04, running loss 0.61441, it/sec: 4.502724447376499
epoch 1 iter 37580: train loss 0.60434. lr 3.000000e-04, running loss 0.61418, it/sec: 4.46133611305601
epoch 1 iter 37600: train loss 0.61099. lr 3.000000e-04, running loss 0.61820, it/sec: 4.510533625211714
epoch 1 iter 37620: train loss 0.59585. lr 3.000000e-04, running loss 0.61807, it/sec: 4.459981155340603
epoch 1 iter 37640: train loss 0.61147. lr 3.000000e-04, running loss 0.61783, it/sec: 4.489249872469514
epoch 1 iter 37660: train loss 0.71744. lr 3.000000e-04, running loss 0.61796, it/sec: 4.465755406862121
epoch 1 iter 37680: train loss 0.56991. lr 3.000000e-04, running loss 0.61801, it/sec: 4.506903435138453
epoch 1 iter 37700: train loss 0.67697. lr 3.000000e-04, running loss 0.61757, it/sec: 4.4594359378919854
epoch 1 iter 37720: train loss 0.57231. lr 3.000000e-04, running loss 0.61721, it/sec: 4.525327759302274
epoch 1 iter 37740: train loss 0.56135. lr 3.000000e-04, running loss 0.61706, it/sec: 4.441671123851651
epoch 1 iter 37760: train loss 0.56965. lr 3.000000e-04, running loss 0.61677, it/sec: 4.503107689181269
epoch 1 iter 37780: train loss 0.55530. lr 3.000000e-04, running loss 0.61653, it/sec: 4.501767166697179
epoch 1 iter 37800: train loss 0.58451. lr 3.000000e-04, running loss 0.61642, it/sec: 4.48649069928576
epoch 1 iter 37820: train loss 0.64560. lr 3.000000e-04, running loss 0.61600, it/sec: 4.510551935847697
epoch 1 iter 37840: train loss 0.53436. lr 3.000000e-04, running loss 0.61594, it/sec: 4.463039191855431
epoch 1 iter 37860: train loss 0.63226. lr 3.000000e-04, running loss 0.61591, it/sec: 4.491123666839164
epoch 1 iter 37880: train loss 0.61886. lr 3.000000e-04, running loss 0.61609, it/sec: 4.481150021884833
epoch 1 iter 37900: train loss 0.59316. lr 3.000000e-04, running loss 0.61558, it/sec: 4.512612449104003
epoch 1 iter 37920: train loss 0.56170. lr 3.000000e-04, running loss 0.61547, it/sec: 4.397272053137261
epoch 1 iter 37940: train loss 0.62975. lr 3.000000e-04, running loss 0.61550, it/sec: 4.510642534353516
epoch 1 iter 37960: train loss 0.57967. lr 3.000000e-04, running loss 0.61484, it/sec: 4.437310058098704
epoch 1 iter 37980: train loss 0.62765. lr 3.000000e-04, running loss 0.61496, it/sec: 4.505455297821243
epoch 1 iter 38000: train loss 0.58715. lr 3.000000e-04, running loss 0.61522, it/sec: 4.462259469539157
epoch 1 iter 38020: train loss 0.50639. lr 3.000000e-04, running loss 0.61495, it/sec: 4.50327409641726
epoch 1 iter 38040: train loss 0.64655. lr 3.000000e-04, running loss 0.61486, it/sec: 4.4303710860504735
epoch 1 iter 38060: train loss 0.67847. lr 3.000000e-04, running loss 0.61467, it/sec: 4.515349947313428
epoch 1 iter 38080: train loss 0.61845. lr 3.000000e-04, running loss 0.61462, it/sec: 4.491549600903197
epoch 1 iter 38100: train loss 0.53652. lr 3.000000e-04, running loss 0.61447, it/sec: 4.461768400585772
epoch 1 iter 38120: train loss 0.57824. lr 3.000000e-04, running loss 0.61394, it/sec: 4.509632728259534
epoch 1 iter 38140: train loss 0.55371. lr 3.000000e-04, running loss 0.61402, it/sec: 4.453699053138419
epoch 1 iter 38160: train loss 0.69297. lr 3.000000e-04, running loss 0.61407, it/sec: 4.493644277021074
epoch 1 iter 38180: train loss 0.54557. lr 3.000000e-04, running loss 0.61402, it/sec: 4.457801761735373
epoch 1 iter 38200: train loss 0.58806. lr 3.000000e-04, running loss 0.61401, it/sec: 4.5167870121805045
epoch 1 iter 38220: train loss 0.60268. lr 3.000000e-04, running loss 0.61396, it/sec: 4.44037818313848
epoch 1 iter 38240: train loss 0.61582. lr 3.000000e-04, running loss 0.61381, it/sec: 4.5013017878304655
epoch 1 iter 38260: train loss 0.64879. lr 3.000000e-04, running loss 0.61384, it/sec: 4.450431026555519
epoch 1 iter 38280: train loss 0.71364. lr 3.000000e-04, running loss 0.61329, it/sec: 4.505169321776781
epoch 1 iter 38300: train loss 0.61054. lr 3.000000e-04, running loss 0.61351, it/sec: 4.450330193299344
epoch 1 iter 38320: train loss 0.58852. lr 3.000000e-04, running loss 0.61462, it/sec: 4.520367430429097
epoch 1 iter 38340: train loss 0.58648. lr 3.000000e-04, running loss 0.61430, it/sec: 4.450998351816441
epoch 1 iter 38360: train loss 0.62119. lr 3.000000e-04, running loss 0.61393, it/sec: 4.480820341355557
epoch 1 iter 38380: train loss 0.61178. lr 3.000000e-04, running loss 0.61380, it/sec: 4.517458969344532
epoch 1 iter 38400: train loss 0.58346. lr 3.000000e-04, running loss 0.61342, it/sec: 4.455837645701463
epoch 1 iter 38420: train loss 0.52251. lr 3.000000e-04, running loss 0.61342, it/sec: 4.482518820625425
epoch 1 iter 38440: train loss 0.69680. lr 3.000000e-04, running loss 0.61320, it/sec: 4.479816919847038
epoch 1 iter 38460: train loss 0.61700. lr 3.000000e-04, running loss 0.61330, it/sec: 4.506546295062658
epoch 1 iter 38480: train loss 0.62814. lr 3.000000e-04, running loss 0.61359, it/sec: 4.422992849767238
epoch 1 iter 38500: train loss 0.55545. lr 3.000000e-04, running loss 0.61292, it/sec: 4.49719724719602
epoch 1 iter 38520: train loss 0.62538. lr 3.000000e-04, running loss 0.61257, it/sec: 4.472382843614053
epoch 1 iter 38540: train loss 0.54863. lr 3.000000e-04, running loss 0.61240, it/sec: 4.520074082978667
epoch 1 iter 38560: train loss 0.60488. lr 3.000000e-04, running loss 0.61213, it/sec: 4.475237198703247
epoch 1 iter 38580: train loss 0.60920. lr 3.000000e-04, running loss 0.61197, it/sec: 4.499487758358525
epoch 1 iter 38600: train loss 0.54228. lr 3.000000e-04, running loss 0.61186, it/sec: 4.480895755138004
epoch 1 iter 38620: train loss 0.62801. lr 3.000000e-04, running loss 0.61225, it/sec: 4.50960364709323
epoch 1 iter 38640: train loss 0.58215. lr 3.000000e-04, running loss 0.61236, it/sec: 4.45951912566428
epoch 1 iter 38660: train loss 0.62481. lr 3.000000e-04, running loss 0.61195, it/sec: 4.524546267704165
epoch 1 iter 38680: train loss 0.58412. lr 3.000000e-04, running loss 0.61203, it/sec: 4.453869683818462
epoch 1 iter 38700: train loss 0.50407. lr 3.000000e-04, running loss 0.61213, it/sec: 4.449782700666674
epoch 1 iter 38720: train loss 0.61208. lr 3.000000e-04, running loss 0.61203, it/sec: 4.50883387892314
epoch 1 iter 38740: train loss 0.52542. lr 3.000000e-04, running loss 0.61167, it/sec: 4.455895680253455
epoch 1 iter 38760: train loss 0.61518. lr 3.000000e-04, running loss 0.61153, it/sec: 4.509543635746251
epoch 1 iter 38780: train loss 0.56234. lr 3.000000e-04, running loss 0.61162, it/sec: 4.469282652432334
epoch 1 iter 38800: train loss 0.61218. lr 3.000000e-04, running loss 0.61155, it/sec: 4.503250774961231
epoch 1 iter 38820: train loss 0.64011. lr 3.000000e-04, running loss 0.61097, it/sec: 4.437075330126659
epoch 1 iter 38840: train loss 1.11421. lr 3.000000e-04, running loss 0.61140, it/sec: 4.51275752528628
epoch 1 iter 38860: train loss 0.79716. lr 3.000000e-04, running loss 0.61098, it/sec: 4.435752026029802
epoch 1 iter 38880: train loss 0.62506. lr 3.000000e-04, running loss 0.61120, it/sec: 4.499659060096532
epoch 1 iter 38900: train loss 0.58474. lr 3.000000e-04, running loss 0.61122, it/sec: 4.501075191781617
epoch 1 iter 38920: train loss 0.58754. lr 3.000000e-04, running loss 0.61116, it/sec: 4.4888839575820905
epoch 1 iter 38940: train loss 0.60093. lr 3.000000e-04, running loss 0.61068, it/sec: 4.472872471869717
epoch 1 iter 38960: train loss 0.70485. lr 3.000000e-04, running loss 0.61072, it/sec: 4.505730610954085
epoch 1 iter 38980: train loss 0.59959. lr 3.000000e-04, running loss 0.61054, it/sec: 4.455675062007642
epoch 1 iter 39000: train loss 0.58734. lr 3.000000e-04, running loss 0.61048, it/sec: 4.501616209651659
epoch 1 iter 39020: train loss 0.57385. lr 3.000000e-04, running loss 0.61015, it/sec: 4.456435682310047
epoch 1 iter 39040: train loss 0.81308. lr 3.000000e-04, running loss 0.61039, it/sec: 4.495835581906116
epoch 1 iter 39060: train loss 0.59187. lr 3.000000e-04, running loss 0.61018, it/sec: 4.438134561280519
epoch 1 iter 39080: train loss 0.62101. lr 3.000000e-04, running loss 0.61049, it/sec: 4.476506497472485
epoch 1 iter 39100: train loss 0.69467. lr 3.000000e-04, running loss 0.61021, it/sec: 4.517015315306295
epoch 1 iter 39120: train loss 0.57693. lr 3.000000e-04, running loss 0.61019, it/sec: 4.465911924074774
epoch 1 iter 39140: train loss 0.57649. lr 3.000000e-04, running loss 0.60997, it/sec: 4.464907114668317
epoch 1 iter 39160: train loss 0.60421. lr 3.000000e-04, running loss 0.60966, it/sec: 4.439208486386719
epoch 1 iter 39180: train loss 0.64856. lr 3.000000e-04, running loss 0.60977, it/sec: 4.509547377456822
epoch 1 iter 39200: train loss 0.62129. lr 3.000000e-04, running loss 0.60978, it/sec: 4.507763109911041
epoch 1 iter 39220: train loss 0.52066. lr 3.000000e-04, running loss 0.61028, it/sec: 4.5053276191920695
epoch 1 iter 39240: train loss 0.84740. lr 3.000000e-04, running loss 0.61085, it/sec: 4.468177436478413
epoch 1 iter 39260: train loss 0.70631. lr 3.000000e-04, running loss 0.61071, it/sec: 4.492983543811187
epoch 1 iter 39280: train loss 0.61446. lr 3.000000e-04, running loss 0.61054, it/sec: 4.474943691469381
epoch 1 iter 39300: train loss 0.63778. lr 3.000000e-04, running loss 0.61055, it/sec: 4.5116212424979025
epoch 1 iter 39320: train loss 0.58442. lr 3.000000e-04, running loss 0.61012, it/sec: 4.435941551785298
epoch 1 iter 39340: train loss 0.56935. lr 3.000000e-04, running loss 0.61028, it/sec: 4.520026764613547
epoch 1 iter 39360: train loss 0.58437. lr 3.000000e-04, running loss 0.61038, it/sec: 4.4892362483573915
epoch 1 iter 39380: train loss 0.57856. lr 3.000000e-04, running loss 0.61045, it/sec: 4.469956232972306
epoch 1 iter 39400: train loss 0.62729. lr 3.000000e-04, running loss 0.61076, it/sec: 4.510812611487893
epoch 1 iter 39420: train loss 0.67307. lr 3.000000e-04, running loss 0.61085, it/sec: 4.470835388617991
epoch 1 iter 39440: train loss 0.59494. lr 3.000000e-04, running loss 0.61067, it/sec: 4.4972221647391
epoch 1 iter 39460: train loss 0.57223. lr 3.000000e-04, running loss 0.61035, it/sec: 4.475687027657945
epoch 1 iter 39480: train loss 0.61051. lr 3.000000e-04, running loss 0.61023, it/sec: 4.479072270884832
epoch 1 iter 39500: train loss 0.59715. lr 3.000000e-04, running loss 0.61021, it/sec: 4.479899825381093
epoch 1 iter 39520: train loss 0.56662. lr 3.000000e-04, running loss 0.60990, it/sec: 4.491414156211346
epoch 1 iter 39540: train loss 0.66172. lr 3.000000e-04, running loss 0.60967, it/sec: 4.443866109062863
epoch 1 iter 39560: train loss 0.56386. lr 3.000000e-04, running loss 0.60952, it/sec: 4.4974747697643656
epoch 1 iter 39580: train loss 0.52637. lr 3.000000e-04, running loss 0.60957, it/sec: 4.455128197978548
epoch 1 iter 39600: train loss 0.62029. lr 3.000000e-04, running loss 0.60909, it/sec: 4.52063089769471
epoch 1 iter 39620: train loss 0.48951. lr 3.000000e-04, running loss 0.60946, it/sec: 4.450266441656581
epoch 1 iter 39640: train loss 0.62892. lr 3.000000e-04, running loss 0.60960, it/sec: 4.508884947613443
epoch 1 iter 39660: train loss 0.63031. lr 3.000000e-04, running loss 0.60976, it/sec: 4.446342043801839
epoch 1 iter 39680: train loss 0.53888. lr 3.000000e-04, running loss 0.60968, it/sec: 4.479688602802926
epoch 1 iter 39700: train loss 0.55489. lr 3.000000e-04, running loss 0.60968, it/sec: 4.453364831273886
epoch 1 iter 39720: train loss 0.57992. lr 3.000000e-04, running loss 0.60946, it/sec: 4.479524315993278
epoch 1 iter 39740: train loss 0.68242. lr 3.000000e-04, running loss 0.60950, it/sec: 4.506463597820106
epoch 1 iter 39760: train loss 0.56788. lr 3.000000e-04, running loss 0.60947, it/sec: 4.437323604954326
epoch 1 iter 39780: train loss 0.57938. lr 3.000000e-04, running loss 0.60956, it/sec: 4.501908100454538
epoch 1 iter 39800: train loss 0.73997. lr 3.000000e-04, running loss 0.61009, it/sec: 4.4534872796468195
epoch 1 iter 39820: train loss 0.67504. lr 3.000000e-04, running loss 0.61046, it/sec: 4.510637305732385
epoch 1 iter 39840: train loss 0.61691. lr 3.000000e-04, running loss 0.61048, it/sec: 4.417105368937765
epoch 1 iter 39860: train loss 0.62658. lr 3.000000e-04, running loss 0.60997, it/sec: 4.460910040242732
epoch 1 iter 39880: train loss 0.56067. lr 3.000000e-04, running loss 0.60995, it/sec: 4.47738277785197
epoch 1 iter 39900: train loss 0.62187. lr 3.000000e-04, running loss 0.61070, it/sec: 4.423526844469883
epoch 1 iter 39920: train loss 0.59983. lr 3.000000e-04, running loss 0.61095, it/sec: 4.494068347550734
epoch 1 iter 39940: train loss 0.59051. lr 3.000000e-04, running loss 0.61071, it/sec: 4.492120357048378
epoch 1 iter 39960: train loss 0.53668. lr 3.000000e-04, running loss 0.61080, it/sec: 4.420917636892422
epoch 1 iter 39980: train loss 0.59575. lr 3.000000e-04, running loss 0.61075, it/sec: 4.492826111450593
epoch 1 iter 40000: train loss 0.63507. lr 3.000000e-04, running loss 0.61054, it/sec: 4.469793817500575
epoch 1 iter 40020: train loss 0.62419. lr 3.000000e-04, running loss 0.61045, it/sec: 4.446357861095357
epoch 1 iter 40040: train loss 0.65576. lr 3.000000e-04, running loss 0.61069, it/sec: 4.500438560598801
epoch 1 iter 40060: train loss 0.55743. lr 3.000000e-04, running loss 0.61074, it/sec: 4.443440977131388
epoch 1 iter 40080: train loss 0.64645. lr 3.000000e-04, running loss 0.61080, it/sec: 4.489520043233059
epoch 1 iter 40100: train loss 0.54270. lr 3.000000e-04, running loss 0.61051, it/sec: 4.426086062325468
epoch 1 iter 40120: train loss 0.65845. lr 3.000000e-04, running loss 0.61020, it/sec: 4.4849147195391454
epoch 1 iter 40140: train loss 0.62180. lr 3.000000e-04, running loss 0.60996, it/sec: 4.484423618489169
epoch 1 iter 40160: train loss 0.66990. lr 3.000000e-04, running loss 0.60968, it/sec: 4.462261759757825
epoch 1 iter 40180: train loss 0.66874. lr 3.000000e-04, running loss 0.61008, it/sec: 4.456182544493227
epoch 1 iter 40200: train loss 0.61108. lr 3.000000e-04, running loss 0.61005, it/sec: 4.464031205098298
epoch 1 iter 40220: train loss 0.67203. lr 3.000000e-04, running loss 0.61007, it/sec: 4.520612791812445
epoch 1 iter 40240: train loss 0.56268. lr 3.000000e-04, running loss 0.60965, it/sec: 4.447693810572998
epoch 1 iter 40260: train loss 0.58594. lr 3.000000e-04, running loss 0.60972, it/sec: 4.496733864882524
epoch 1 iter 40280: train loss 0.52811. lr 3.000000e-04, running loss 0.61029, it/sec: 4.470880042117406
epoch 1 iter 40300: train loss 0.54533. lr 3.000000e-04, running loss 0.60989, it/sec: 4.489238424409013
epoch 1 iter 40320: train loss 0.46934. lr 3.000000e-04, running loss 0.61003, it/sec: 4.501398985587027
epoch 1 iter 40340: train loss 0.66835. lr 3.000000e-04, running loss 0.61017, it/sec: 4.472765058748652
epoch 1 iter 40360: train loss 0.59131. lr 3.000000e-04, running loss 0.61038, it/sec: 4.475437825940521
epoch 1 iter 40380: train loss 0.66606. lr 3.000000e-04, running loss 0.61056, it/sec: 4.443214168097898
epoch 1 iter 40400: train loss 0.66990. lr 3.000000e-04, running loss 0.61055, it/sec: 4.493448172598376
epoch 1 iter 40420: train loss 0.53637. lr 3.000000e-04, running loss 0.61051, it/sec: 4.472520283149126
epoch 1 iter 40440: train loss 0.57666. lr 3.000000e-04, running loss 0.61054, it/sec: 4.505058159300128
epoch 1 iter 40460: train loss 0.62185. lr 3.000000e-04, running loss 0.61097, it/sec: 4.448619819718273
epoch 1 iter 40480: train loss 0.54153. lr 3.000000e-04, running loss 0.61064, it/sec: 4.505776798529051
epoch 1 iter 40500: train loss 0.53769. lr 3.000000e-04, running loss 0.61021, it/sec: 4.455394715143525
epoch 1 iter 40520: train loss 0.60267. lr 3.000000e-04, running loss 0.61031, it/sec: 4.479999533367206
epoch 1 iter 40540: train loss 0.59118. lr 3.000000e-04, running loss 0.61028, it/sec: 4.514370987491471
epoch 1 iter 40560: train loss 0.63999. lr 3.000000e-04, running loss 0.60992, it/sec: 4.483035709858934
epoch 1 iter 40580: train loss 0.65406. lr 3.000000e-04, running loss 0.60989, it/sec: 4.508301205697893
epoch 1 iter 40600: train loss 0.48600. lr 3.000000e-04, running loss 0.60960, it/sec: 4.441573174353331
epoch 1 iter 40620: train loss 0.57549. lr 3.000000e-04, running loss 0.60952, it/sec: 4.493885472813979
epoch 1 iter 40640: train loss 0.64519. lr 3.000000e-04, running loss 0.60928, it/sec: 4.399576526420639
epoch 1 iter 40660: train loss 0.58246. lr 3.000000e-04, running loss 0.60914, it/sec: 4.4981968578768585
epoch 1 iter 40680: train loss 0.69270. lr 3.000000e-04, running loss 0.60969, it/sec: 4.412690935765304
epoch 1 iter 40700: train loss 0.54263. lr 3.000000e-04, running loss 0.60920, it/sec: 4.509775741272613
epoch 1 iter 40720: train loss 0.67657. lr 3.000000e-04, running loss 0.60931, it/sec: 4.44533959740997
epoch 1 iter 40740: train loss 0.59999. lr 3.000000e-04, running loss 0.60993, it/sec: 4.500103828113377
epoch 1 iter 40760: train loss 0.60177. lr 3.000000e-04, running loss 0.60980, it/sec: 4.449088105912399
epoch 1 iter 40780: train loss 0.65823. lr 3.000000e-04, running loss 0.60963, it/sec: 4.528210625411694
epoch 1 iter 40800: train loss 0.51492. lr 3.000000e-04, running loss 0.60964, it/sec: 4.474558781241591
epoch 1 iter 40820: train loss 0.66616. lr 3.000000e-04, running loss 0.60926, it/sec: 4.491760650501835
epoch 1 iter 40840: train loss 0.73222. lr 3.000000e-04, running loss 0.60934, it/sec: 4.4922891201169985
epoch 1 iter 40860: train loss 0.59340. lr 3.000000e-04, running loss 0.60947, it/sec: 4.461476915700931
epoch 1 iter 40880: train loss 0.64612. lr 3.000000e-04, running loss 0.60949, it/sec: 4.501888177685679
epoch 1 iter 40900: train loss 0.52654. lr 3.000000e-04, running loss 0.60957, it/sec: 4.439548805581078
epoch 1 iter 40920: train loss 0.56834. lr 3.000000e-04, running loss 0.60946, it/sec: 4.517817066610669
epoch 1 iter 40940: train loss 0.70413. lr 3.000000e-04, running loss 0.60997, it/sec: 4.443720512429179
epoch 1 iter 40960: train loss 0.60791. lr 3.000000e-04, running loss 0.60995, it/sec: 4.526007668832528
epoch 1 iter 40980: train loss 0.48575. lr 3.000000e-04, running loss 0.60953, it/sec: 4.45526108516298
epoch 1 iter 41000: train loss 0.75480. lr 3.000000e-04, running loss 0.61008, it/sec: 4.507400833604848
epoch 1 iter 41020: train loss 0.67414. lr 3.000000e-04, running loss 0.61002, it/sec: 4.444926610710664
epoch 1 iter 41040: train loss 0.55016. lr 3.000000e-04, running loss 0.61019, it/sec: 4.487747396981744
epoch 1 iter 41060: train loss 0.60933. lr 3.000000e-04, running loss 0.61026, it/sec: 4.491311519549507
epoch 1 iter 41080: train loss 0.67640. lr 3.000000e-04, running loss 0.61056, it/sec: 4.416374771098587
epoch 1 iter 41100: train loss 0.59349. lr 3.000000e-04, running loss 0.61074, it/sec: 4.503523465889145
epoch 1 iter 41120: train loss 0.51717. lr 3.000000e-04, running loss 0.61058, it/sec: 4.4508427190677855
epoch 1 iter 41140: train loss 0.58816. lr 3.000000e-04, running loss 0.61049, it/sec: 4.493353235862807
epoch 1 iter 41160: train loss 0.52977. lr 3.000000e-04, running loss 0.61054, it/sec: 4.470609890379392
epoch 1 iter 41180: train loss 0.60749. lr 3.000000e-04, running loss 0.61056, it/sec: 4.496654479166644
epoch 1 iter 41200: train loss 0.66771. lr 3.000000e-04, running loss 0.61043, it/sec: 4.526130682935655
epoch 1 iter 41220: train loss 0.54706. lr 3.000000e-04, running loss 0.61037, it/sec: 4.471714849420513
epoch 1 iter 41240: train loss 0.68146. lr 3.000000e-04, running loss 0.61032, it/sec: 4.49393541701169
epoch 1 iter 41260: train loss 0.55202. lr 3.000000e-04, running loss 0.61021, it/sec: 4.456516394089643
epoch 1 iter 41280: train loss 0.70290. lr 3.000000e-04, running loss 0.61051, it/sec: 4.495141832454429
epoch 1 iter 41300: train loss 0.58185. lr 3.000000e-04, running loss 0.61069, it/sec: 4.494591944271943
epoch 1 iter 41320: train loss 0.63010. lr 3.000000e-04, running loss 0.61082, it/sec: 4.501260575701531
epoch 1 iter 41340: train loss 0.55710. lr 3.000000e-04, running loss 0.61128, it/sec: 4.4173968023080885
epoch 1 iter 41360: train loss 0.54205. lr 3.000000e-04, running loss 0.61085, it/sec: 4.508931340703892
epoch 1 iter 41380: train loss 0.69951. lr 3.000000e-04, running loss 0.61127, it/sec: 4.453751618062487
epoch 1 iter 41400: train loss 0.63692. lr 3.000000e-04, running loss 0.61142, it/sec: 4.487912589994422
epoch 1 iter 41420: train loss 0.51086. lr 3.000000e-04, running loss 0.61170, it/sec: 4.5013387454111475
epoch 1 iter 41440: train loss 0.64607. lr 3.000000e-04, running loss 0.61190, it/sec: 4.459578250553808
epoch 1 iter 41460: train loss 0.69370. lr 3.000000e-04, running loss 0.61257, it/sec: 4.501038239707777
epoch 1 iter 41480: train loss 0.62112. lr 3.000000e-04, running loss 0.61271, it/sec: 4.461372000197271
epoch 1 iter 41500: train loss 0.58215. lr 3.000000e-04, running loss 0.61255, it/sec: 4.521779638308621
epoch 1 iter 41520: train loss 0.61650. lr 3.000000e-04, running loss 0.61216, it/sec: 4.430773145845588
epoch 1 iter 41540: train loss 0.67522. lr 3.000000e-04, running loss 0.61219, it/sec: 4.474605193207728
epoch 1 iter 41560: train loss 0.58131. lr 3.000000e-04, running loss 0.61199, it/sec: 4.506828566871693
epoch 1 iter 41580: train loss 0.47808. lr 3.000000e-04, running loss 0.61192, it/sec: 4.481779319048088
epoch 1 iter 41600: train loss 0.72043. lr 3.000000e-04, running loss 0.61317, it/sec: 4.4492451000942
epoch 1 iter 41620: train loss 0.62537. lr 3.000000e-04, running loss 0.61284, it/sec: 4.464915167808485
epoch 1 iter 41640: train loss 0.71592. lr 3.000000e-04, running loss 0.61273, it/sec: 4.492207591338167
epoch 1 iter 41660: train loss 0.57871. lr 3.000000e-04, running loss 0.61268, it/sec: 4.479179746585989
epoch 1 iter 41680: train loss 0.61455. lr 3.000000e-04, running loss 0.61318, it/sec: 4.492536751664365
epoch 1 iter 41700: train loss 0.66195. lr 3.000000e-04, running loss 0.61356, it/sec: 4.45470981900797
epoch 1 iter 41720: train loss 0.66314. lr 3.000000e-04, running loss 0.61327, it/sec: 4.518883408496926
epoch 1 iter 41740: train loss 0.54360. lr 3.000000e-04, running loss 0.61312, it/sec: 4.461245495264609
epoch 1 iter 41760: train loss 0.63242. lr 3.000000e-04, running loss 0.61299, it/sec: 4.483287989575273
epoch 1 iter 41780: train loss 0.58580. lr 3.000000e-04, running loss 0.61308, it/sec: 4.485284977239024
epoch 1 iter 41800: train loss 0.68159. lr 3.000000e-04, running loss 0.61306, it/sec: 4.481875093240441
epoch 1 iter 41820: train loss 0.55925. lr 3.000000e-04, running loss 0.61443, it/sec: 4.493831735286699
epoch 1 iter 41840: train loss 0.62083. lr 3.000000e-04, running loss 0.61455, it/sec: 4.442650462438258
epoch 1 iter 41860: train loss 0.65888. lr 3.000000e-04, running loss 0.61450, it/sec: 4.491316663541169
epoch 1 iter 41880: train loss 0.69448. lr 3.000000e-04, running loss 0.61449, it/sec: 4.466595602225536
epoch 1 iter 41900: train loss 0.63563. lr 3.000000e-04, running loss 0.61424, it/sec: 4.481059961395499
epoch 1 iter 41920: train loss 0.54172. lr 3.000000e-04, running loss 0.61404, it/sec: 4.435794565865665
epoch 1 iter 41940: train loss 0.66661. lr 3.000000e-04, running loss 0.61410, it/sec: 4.509206550976235
epoch 1 iter 41960: train loss 0.65179. lr 3.000000e-04, running loss 0.61445, it/sec: 4.446821299628741
epoch 1 iter 41980: train loss 0.60753. lr 3.000000e-04, running loss 0.61436, it/sec: 4.482092507921857
epoch 1 iter 42000: train loss 0.61184. lr 3.000000e-04, running loss 0.61399, it/sec: 4.4352809962407616
epoch 1 iter 42020: train loss 0.67054. lr 3.000000e-04, running loss 0.61397, it/sec: 4.487348883686281
epoch 1 iter 42040: train loss 0.66160. lr 3.000000e-04, running loss 0.61401, it/sec: 4.4882780451778315
epoch 1 iter 42060: train loss 0.63672. lr 3.000000e-04, running loss 0.61439, it/sec: 4.456005024988499
epoch 1 iter 42080: train loss 0.55009. lr 3.000000e-04, running loss 0.61413, it/sec: 4.524591817043363
epoch 1 iter 42100: train loss 0.64137. lr 3.000000e-04, running loss 0.61387, it/sec: 4.438489649279617
epoch 1 iter 42120: train loss 1.21788. lr 3.000000e-04, running loss 0.61453, it/sec: 4.510573624113196
epoch 1 iter 42140: train loss 0.71887. lr 3.000000e-04, running loss 0.61407, it/sec: 4.415745162496669
epoch 1 iter 42160: train loss 0.64031. lr 3.000000e-04, running loss 0.61413, it/sec: 4.494573460788896
epoch 1 iter 42180: train loss 0.55482. lr 3.000000e-04, running loss 0.61407, it/sec: 4.484839855322476
epoch 1 iter 42200: train loss 0.65785. lr 3.000000e-04, running loss 0.61400, it/sec: 4.508582355642233
epoch 1 iter 42220: train loss 0.55961. lr 3.000000e-04, running loss 0.61439, it/sec: 4.465178450706832
epoch 1 iter 42240: train loss 0.60464. lr 3.000000e-04, running loss 0.61414, it/sec: 4.501098227729617
epoch 1 iter 42260: train loss 0.57456. lr 3.000000e-04, running loss 0.61408, it/sec: 4.499080275320386
epoch 1 iter 42280: train loss 0.54259. lr 3.000000e-04, running loss 0.61360, it/sec: 4.4530461862941175
epoch 1 iter 42300: train loss 0.58938. lr 3.000000e-04, running loss 0.61359, it/sec: 4.503585772727727
epoch 1 iter 42320: train loss 0.55922. lr 3.000000e-04, running loss 0.61330, it/sec: 4.444860067495326
epoch 1 iter 42340: train loss 0.59999. lr 3.000000e-04, running loss 0.61322, it/sec: 4.518479796899383
epoch 1 iter 42360: train loss 0.61276. lr 3.000000e-04, running loss 0.61339, it/sec: 4.488635841942484
epoch 1 iter 42380: train loss 0.64282. lr 3.000000e-04, running loss 0.61319, it/sec: 4.453810729827645
epoch 1 iter 42400: train loss 0.55197. lr 3.000000e-04, running loss 0.61309, it/sec: 4.5098282341740425
epoch 1 iter 42420: train loss 0.56618. lr 3.000000e-04, running loss 0.61314, it/sec: 4.439322413205253
epoch 1 iter 42440: train loss 0.63674. lr 3.000000e-04, running loss 0.61301, it/sec: 4.513351100062428
epoch 1 iter 42460: train loss 0.65477. lr 3.000000e-04, running loss 0.61319, it/sec: 4.430861530011746
epoch 1 iter 42480: train loss 0.59263. lr 3.000000e-04, running loss 0.61293, it/sec: 4.5053456241083865
epoch 1 iter 42500: train loss 0.62240. lr 3.000000e-04, running loss 0.61279, it/sec: 4.441583235744246
epoch 1 iter 42520: train loss 0.62127. lr 3.000000e-04, running loss 0.61276, it/sec: 4.51118009536418
epoch 1 iter 42540: train loss 0.58225. lr 3.000000e-04, running loss 0.61304, it/sec: 4.456417232728419
epoch 1 iter 42560: train loss 0.61757. lr 3.000000e-04, running loss 0.61316, it/sec: 4.512750967674746
epoch 1 iter 42580: train loss 0.62755. lr 3.000000e-04, running loss 0.61300, it/sec: 4.44003381347712
epoch 1 iter 42600: train loss 0.53441. lr 3.000000e-04, running loss 0.61250, it/sec: 4.473963156358384
epoch 1 iter 42620: train loss 0.70411. lr 3.000000e-04, running loss 0.61243, it/sec: 4.498199750459029
epoch 1 iter 42640: train loss 0.55148. lr 3.000000e-04, running loss 0.61260, it/sec: 4.441542261296259
epoch 1 iter 42660: train loss 0.53313. lr 3.000000e-04, running loss 0.61250, it/sec: 4.513904039345711
epoch 1 iter 42680: train loss 0.60535. lr 3.000000e-04, running loss 0.61265, it/sec: 4.454932225828541
epoch 1 iter 42700: train loss 0.54921. lr 3.000000e-04, running loss 0.61284, it/sec: 4.516851868095884
epoch 1 iter 42720: train loss 0.58674. lr 3.000000e-04, running loss 0.61315, it/sec: 4.464375958188116
epoch 1 iter 42740: train loss 0.57992. lr 3.000000e-04, running loss 0.61275, it/sec: 4.4941897726539795
epoch 1 iter 42760: train loss 0.59634. lr 3.000000e-04, running loss 0.61273, it/sec: 4.462824318400004
epoch 1 iter 42780: train loss 0.54286. lr 3.000000e-04, running loss 0.61282, it/sec: 4.503806596511184
epoch 1 iter 42800: train loss 0.49555. lr 3.000000e-04, running loss 0.61306, it/sec: 4.462850807640402
epoch 1 iter 42820: train loss 0.62382. lr 3.000000e-04, running loss 0.61284, it/sec: 4.474860788606007
epoch 1 iter 42840: train loss 0.60692. lr 3.000000e-04, running loss 0.61270, it/sec: 4.476757500398843
epoch 1 iter 42860: train loss 0.53346. lr 3.000000e-04, running loss 0.61266, it/sec: 4.473128689277592
epoch 1 iter 42880: train loss 0.62594. lr 3.000000e-04, running loss 0.61273, it/sec: 4.49711398391953
epoch 1 iter 42900: train loss 0.60251. lr 3.000000e-04, running loss 0.61264, it/sec: 4.45388239900107
epoch 1 iter 42920: train loss 0.70828. lr 3.000000e-04, running loss 0.61232, it/sec: 4.522402400630562
epoch 1 iter 42940: train loss 0.59104. lr 3.000000e-04, running loss 0.61214, it/sec: 4.458055045377771
epoch 1 iter 42960: train loss 0.56822. lr 3.000000e-04, running loss 0.61162, it/sec: 4.527546473192567
epoch 1 iter 42980: train loss 0.61498. lr 3.000000e-04, running loss 0.61090, it/sec: 4.489773537895597
epoch 1 iter 43000: train loss 0.64403. lr 3.000000e-04, running loss 0.61060, it/sec: 4.48936682574705
epoch 1 iter 43020: train loss 0.57281. lr 3.000000e-04, running loss 0.61051, it/sec: 4.462656704642945
epoch 1 iter 43040: train loss 0.59513. lr 3.000000e-04, running loss 0.61063, it/sec: 4.503033736586709
epoch 1 iter 43060: train loss 0.54027. lr 3.000000e-04, running loss 0.61077, it/sec: 4.493141552435506
epoch 1 iter 43080: train loss 0.62585. lr 3.000000e-04, running loss 0.61105, it/sec: 4.455264518967802
epoch 1 iter 43100: train loss 0.56066. lr 3.000000e-04, running loss 0.61094, it/sec: 4.4889032610718775
epoch 1 iter 43120: train loss 0.62661. lr 3.000000e-04, running loss 0.61057, it/sec: 4.491628240448723
epoch 1 iter 43140: train loss 0.53545. lr 3.000000e-04, running loss 0.61060, it/sec: 4.468174062924325
epoch 1 iter 43160: train loss 0.56372. lr 3.000000e-04, running loss 0.61056, it/sec: 4.495553251396881
epoch 1 iter 43180: train loss 0.72097. lr 3.000000e-04, running loss 0.61049, it/sec: 4.493311018627657
epoch 1 iter 43200: train loss 0.57299. lr 3.000000e-04, running loss 0.60991, it/sec: 4.46137542373281
epoch 1 iter 43220: train loss 0.58373. lr 3.000000e-04, running loss 0.61002, it/sec: 4.488542156846755
epoch 1 iter 43240: train loss 0.54874. lr 3.000000e-04, running loss 0.61072, it/sec: 4.4582325686060384
epoch 1 iter 43260: train loss 0.72007. lr 3.000000e-04, running loss 0.61127, it/sec: 4.517335426023047
epoch 1 iter 43280: train loss 0.67119. lr 3.000000e-04, running loss 0.61139, it/sec: 4.424813826092434
epoch 1 iter 43300: train loss 0.60914. lr 3.000000e-04, running loss 0.61145, it/sec: 4.507689918586349
epoch 1 iter 43320: train loss 0.65010. lr 3.000000e-04, running loss 0.61148, it/sec: 4.470540258620215
epoch 1 iter 43340: train loss 0.62171. lr 3.000000e-04, running loss 0.61166, it/sec: 4.533522684307779
epoch 1 iter 43360: train loss 0.66006. lr 3.000000e-04, running loss 0.61204, it/sec: 4.448965720747883
epoch 1 iter 43380: train loss 0.71751. lr 3.000000e-04, running loss 0.61204, it/sec: 4.51026504722125
epoch 1 iter 43400: train loss 0.57025. lr 3.000000e-04, running loss 0.61209, it/sec: 4.44857032591537
epoch 1 iter 43420: train loss 0.62050. lr 3.000000e-04, running loss 0.61231, it/sec: 4.52921053147866
epoch 1 iter 43440: train loss 0.52940. lr 3.000000e-04, running loss 0.61205, it/sec: 4.370060842838863
epoch 1 iter 43460: train loss 0.55851. lr 3.000000e-04, running loss 0.61217, it/sec: 4.499947861237363
epoch 1 iter 43480: train loss 0.56117. lr 3.000000e-04, running loss 0.61232, it/sec: 4.481495417061636
epoch 1 iter 43500: train loss 0.61867. lr 3.000000e-04, running loss 0.61261, it/sec: 4.4378476131251245
epoch 1 iter 43520: train loss 0.71233. lr 3.000000e-04, running loss 0.61267, it/sec: 4.491680856629861
epoch 1 iter 43540: train loss 0.53834. lr 3.000000e-04, running loss 0.61252, it/sec: 4.467560974142778
epoch 1 iter 43560: train loss 0.54187. lr 3.000000e-04, running loss 0.61287, it/sec: 4.494626913852678
epoch 1 iter 43580: train loss 0.59346. lr 3.000000e-04, running loss 0.61294, it/sec: 4.45637789147096
epoch 1 iter 43600: train loss 0.47266. lr 3.000000e-04, running loss 0.61253, it/sec: 4.5186058926719666
epoch 1 iter 43620: train loss 0.76428. lr 3.000000e-04, running loss 0.61259, it/sec: 4.405829192239735
epoch 1 iter 43640: train loss 0.56113. lr 3.000000e-04, running loss 0.61239, it/sec: 4.492650141388999
epoch 1 iter 43660: train loss 0.60411. lr 3.000000e-04, running loss 0.61229, it/sec: 4.447041496648209
epoch 1 iter 43680: train loss 0.61842. lr 3.000000e-04, running loss 0.61263, it/sec: 4.4908086311970665
epoch 1 iter 43700: train loss 0.52282. lr 3.000000e-04, running loss 0.61308, it/sec: 4.452627205799038
epoch 1 iter 43720: train loss 0.65616. lr 3.000000e-04, running loss 0.61313, it/sec: 4.500645505019283
epoch 1 iter 43740: train loss 0.67170. lr 3.000000e-04, running loss 0.61283, it/sec: 4.472212051166913
epoch 1 iter 43760: train loss 0.58371. lr 3.000000e-04, running loss 0.61267, it/sec: 4.50559922291029
epoch 1 iter 43780: train loss 0.60270. lr 3.000000e-04, running loss 0.61238, it/sec: 4.4672462825732415
epoch 1 iter 43800: train loss 0.62855. lr 3.000000e-04, running loss 0.61229, it/sec: 4.50219285204863
epoch 1 iter 43820: train loss 0.59814. lr 3.000000e-04, running loss 0.61208, it/sec: 4.42967039212106
epoch 1 iter 43840: train loss 0.49940. lr 3.000000e-04, running loss 0.61195, it/sec: 4.487457664194264
epoch 1 iter 43860: train loss 0.62242. lr 3.000000e-04, running loss 0.61195, it/sec: 4.459859443707657
epoch 1 iter 43880: train loss 0.52928. lr 3.000000e-04, running loss 0.61195, it/sec: 4.472407846704591
epoch 1 iter 43900: train loss 0.65654. lr 3.000000e-04, running loss 0.61213, it/sec: 4.492067527372342
epoch 1 iter 43920: train loss 0.53464. lr 3.000000e-04, running loss 0.61216, it/sec: 4.445453107551932
epoch 1 iter 43940: train loss 0.66175. lr 3.000000e-04, running loss 0.61210, it/sec: 4.462024801810894
epoch 1 iter 43960: train loss 0.52721. lr 3.000000e-04, running loss 0.61193, it/sec: 4.431950302931798
epoch 1 iter 43980: train loss 0.76437. lr 3.000000e-04, running loss 0.61207, it/sec: 4.4867694365497055
epoch 1 iter 44000: train loss 0.62721. lr 3.000000e-04, running loss 0.61214, it/sec: 4.46026003124033
epoch 1 iter 44020: train loss 0.68734. lr 3.000000e-04, running loss 0.61214, it/sec: 4.481479129010679
epoch 1 iter 44040: train loss 0.49189. lr 3.000000e-04, running loss 0.61212, it/sec: 4.467024918760735
epoch 1 iter 44060: train loss 0.58241. lr 3.000000e-04, running loss 0.61194, it/sec: 4.499282762118861
epoch 1 iter 44080: train loss 0.65681. lr 3.000000e-04, running loss 0.61164, it/sec: 4.444934257276236
epoch 1 iter 44100: train loss 0.54912. lr 3.000000e-04, running loss 0.61170, it/sec: 4.517319978683325
epoch 1 iter 44120: train loss 0.60763. lr 3.000000e-04, running loss 0.61161, it/sec: 4.428118307182001
epoch 1 iter 44140: train loss 0.67583. lr 3.000000e-04, running loss 0.61133, it/sec: 4.457303547028036
epoch 1 iter 44160: train loss 0.59485. lr 3.000000e-04, running loss 0.61111, it/sec: 4.520165963519371
epoch 1 iter 44180: train loss 0.61783. lr 3.000000e-04, running loss 0.61144, it/sec: 4.448969343020705
epoch 1 iter 44200: train loss 0.64892. lr 3.000000e-04, running loss 0.61133, it/sec: 4.501954634396889
epoch 1 iter 44220: train loss 0.68463. lr 3.000000e-04, running loss 0.61116, it/sec: 4.464523230577049
epoch 1 iter 44240: train loss 0.57665. lr 3.000000e-04, running loss 0.61106, it/sec: 4.505547478297799
epoch 1 iter 44260: train loss 0.60129. lr 3.000000e-04, running loss 0.61117, it/sec: 4.453312869981954
epoch 1 iter 44280: train loss 0.62518. lr 3.000000e-04, running loss 0.61143, it/sec: 4.531526138086104
epoch 1 iter 44300: train loss 0.64635. lr 3.000000e-04, running loss 0.61125, it/sec: 4.464104518992405
epoch 1 iter 44320: train loss 0.56129. lr 3.000000e-04, running loss 0.61105, it/sec: 4.519629751079357
epoch 1 iter 44340: train loss 0.58497. lr 3.000000e-04, running loss 0.61101, it/sec: 4.445066417408696
epoch 1 iter 44360: train loss 0.68398. lr 3.000000e-04, running loss 0.61144, it/sec: 4.523594849513332
epoch 1 iter 44380: train loss 0.60474. lr 3.000000e-04, running loss 0.61144, it/sec: 4.453738050381083
epoch 1 iter 44400: train loss 0.60624. lr 3.000000e-04, running loss 0.61138, it/sec: 4.511833958665894
epoch 1 iter 44420: train loss 0.58170. lr 3.000000e-04, running loss 0.61116, it/sec: 4.47696255380618
epoch 1 iter 44440: train loss 0.59337. lr 3.000000e-04, running loss 0.61109, it/sec: 4.45424003112321
epoch 1 iter 44460: train loss 0.61798. lr 3.000000e-04, running loss 0.61139, it/sec: 4.50476874320476
epoch 1 iter 44480: train loss 0.57030. lr 3.000000e-04, running loss 0.61118, it/sec: 4.460585896306864
epoch 1 iter 44500: train loss 0.55535. lr 3.000000e-04, running loss 0.61171, it/sec: 4.479401072879533
epoch 1 iter 44520: train loss 0.68933. lr 3.000000e-04, running loss 0.61157, it/sec: 4.4726005783954355
epoch 1 iter 44540: train loss 0.61452. lr 3.000000e-04, running loss 0.61136, it/sec: 4.505546442023369
epoch 1 iter 44560: train loss 0.57435. lr 3.000000e-04, running loss 0.61122, it/sec: 4.442064801580902
epoch 1 iter 44580: train loss 0.54286. lr 3.000000e-04, running loss 0.61121, it/sec: 4.520340151724342
epoch 1 iter 44600: train loss 0.57049. lr 3.000000e-04, running loss 0.61128, it/sec: 4.442298617331009
epoch 1 iter 44620: train loss 0.56226. lr 3.000000e-04, running loss 0.61137, it/sec: 4.525609378673912
epoch 1 iter 44640: train loss 0.65893. lr 3.000000e-04, running loss 0.61114, it/sec: 4.4421592993984
epoch 1 iter 44660: train loss 0.55262. lr 3.000000e-04, running loss 0.61189, it/sec: 4.494550816113069
epoch 1 iter 44680: train loss 0.59749. lr 3.000000e-04, running loss 0.61176, it/sec: 4.460598909292748
epoch 1 iter 44700: train loss 0.61045. lr 3.000000e-04, running loss 0.61138, it/sec: 4.499880431268398
epoch 1 iter 44720: train loss 0.69724. lr 3.000000e-04, running loss 0.61144, it/sec: 4.500008205636234
epoch 1 iter 44740: train loss 0.54841. lr 3.000000e-04, running loss 0.61147, it/sec: 4.499954604463275
epoch 1 iter 44760: train loss 0.54760. lr 3.000000e-04, running loss 0.61167, it/sec: 4.489009354645447
epoch 1 iter 44780: train loss 0.58839. lr 3.000000e-04, running loss 0.61165, it/sec: 4.472739931723787
epoch 1 iter 44800: train loss 0.62382. lr 3.000000e-04, running loss 0.61172, it/sec: 4.52649341463229
epoch 1 iter 44820: train loss 0.58697. lr 3.000000e-04, running loss 0.61151, it/sec: 4.452514675670741
epoch 1 iter 44840: train loss 0.52378. lr 3.000000e-04, running loss 0.61131, it/sec: 4.513464708143261
epoch 1 iter 44860: train loss 0.61524. lr 3.000000e-04, running loss 0.61131, it/sec: 4.4735468554202145
epoch 1 iter 44880: train loss 0.60422. lr 3.000000e-04, running loss 0.61090, it/sec: 4.514099323926158
epoch 1 iter 44900: train loss 0.54367. lr 3.000000e-04, running loss 0.61069, it/sec: 4.456861994575647
epoch 1 iter 44920: train loss 0.54959. lr 3.000000e-04, running loss 0.61098, it/sec: 4.488016844089124
epoch 1 iter 44940: train loss 0.54770. lr 3.000000e-04, running loss 0.61072, it/sec: 4.438764797986603
epoch 1 iter 44960: train loss 0.54971. lr 3.000000e-04, running loss 0.61056, it/sec: 4.496112228082624
epoch 1 iter 44980: train loss 0.56884. lr 3.000000e-04, running loss 0.61045, it/sec: 4.426626937124573
epoch 1 iter 45000: train loss 0.53526. lr 3.000000e-04, running loss 0.61041, it/sec: 4.517064568286818
epoch 1 iter 45020: train loss 0.68823. lr 3.000000e-04, running loss 0.61051, it/sec: 4.4671405171000655
epoch 1 iter 45040: train loss 0.74401. lr 3.000000e-04, running loss 0.61077, it/sec: 4.481592283902318
epoch 1 iter 45060: train loss 0.65318. lr 3.000000e-04, running loss 0.61139, it/sec: 4.510258598682831
epoch 1 iter 45080: train loss 0.58478. lr 3.000000e-04, running loss 0.61124, it/sec: 4.473955070546383
epoch 1 iter 45100: train loss 0.61959. lr 3.000000e-04, running loss 0.61136, it/sec: 4.510613236467238
epoch 1 iter 45120: train loss 0.55899. lr 3.000000e-04, running loss 0.61119, it/sec: 4.4455489356006215
epoch 1 iter 45140: train loss 0.64896. lr 3.000000e-04, running loss 0.61122, it/sec: 4.51137097309384
epoch 1 iter 45160: train loss 0.56667. lr 3.000000e-04, running loss 0.61110, it/sec: 4.447310013933705
epoch 1 iter 45180: train loss 0.73215. lr 3.000000e-04, running loss 0.61122, it/sec: 4.5036475936956
epoch 1 iter 45200: train loss 0.73269. lr 3.000000e-04, running loss 0.61093, it/sec: 4.458782919140974
epoch 1 iter 45220: train loss 0.60141. lr 3.000000e-04, running loss 0.61104, it/sec: 4.5120737112429605
epoch 1 iter 45240: train loss 0.63572. lr 3.000000e-04, running loss 0.61064, it/sec: 4.446055379606563
epoch 1 iter 45260: train loss 0.53236. lr 3.000000e-04, running loss 0.61049, it/sec: 4.528804067871538
epoch 1 iter 45280: train loss 0.56503. lr 3.000000e-04, running loss 0.61018, it/sec: 4.447778716454651
epoch 1 iter 45300: train loss 0.59139. lr 3.000000e-04, running loss 0.61009, it/sec: 4.493463942498143
epoch 1 iter 45320: train loss 0.54988. lr 3.000000e-04, running loss 0.61008, it/sec: 4.483774842094119
epoch 1 iter 45340: train loss 0.60413. lr 3.000000e-04, running loss 0.60988, it/sec: 4.489622981692652
epoch 1 iter 45360: train loss 0.52929. lr 3.000000e-04, running loss 0.60951, it/sec: 4.47685021471898
epoch 1 iter 45380: train loss 0.60103. lr 3.000000e-04, running loss 0.60952, it/sec: 4.463756580111223
epoch 1 iter 45400: train loss 0.46062. lr 3.000000e-04, running loss 0.60922, it/sec: 4.5270175254986595
epoch 1 iter 45420: train loss 0.63961. lr 3.000000e-04, running loss 0.60923, it/sec: 4.455069189871279
epoch 1 iter 45440: train loss 0.69369. lr 3.000000e-04, running loss 0.60944, it/sec: 4.515871277678671
epoch 1 iter 45460: train loss 0.54397. lr 3.000000e-04, running loss 0.60918, it/sec: 4.456947051983704
epoch 1 iter 45480: train loss 0.54987. lr 3.000000e-04, running loss 0.60885, it/sec: 4.473951546120182
epoch 1 iter 45500: train loss 0.68454. lr 3.000000e-04, running loss 0.60953, it/sec: 4.461299054071479
epoch 1 iter 45520: train loss 0.52180. lr 3.000000e-04, running loss 0.60940, it/sec: 4.511317568822293
epoch 1 iter 45540: train loss 0.61974. lr 3.000000e-04, running loss 0.61018, it/sec: 4.455034617087083
epoch 1 iter 45560: train loss 0.63316. lr 3.000000e-04, running loss 0.61024, it/sec: 4.51771368897183
epoch 1 iter 45580: train loss 0.55706. lr 3.000000e-04, running loss 0.61021, it/sec: 4.459248415625799
epoch 1 iter 45600: train loss 0.69697. lr 3.000000e-04, running loss 0.61020, it/sec: 4.48816044276902
epoch 1 iter 45620: train loss 0.56462. lr 3.000000e-04, running loss 0.61033, it/sec: 4.485080309429634
epoch 1 iter 45640: train loss 0.68798. lr 3.000000e-04, running loss 0.61077, it/sec: 4.4580986885201135
epoch 1 iter 45660: train loss 0.62350. lr 3.000000e-04, running loss 0.61075, it/sec: 4.517095010636187
epoch 1 iter 45680: train loss 0.61490. lr 3.000000e-04, running loss 0.61060, it/sec: 4.462654992470769
epoch 1 iter 45700: train loss 0.61015. lr 3.000000e-04, running loss 0.61047, it/sec: 4.505405058249274
epoch 1 iter 45720: train loss 0.54912. lr 3.000000e-04, running loss 0.60997, it/sec: 4.471844887907364
epoch 1 iter 45740: train loss 0.52392. lr 3.000000e-04, running loss 0.61054, it/sec: 4.523437535932047
epoch 1 iter 45760: train loss 0.66265. lr 3.000000e-04, running loss 0.61080, it/sec: 4.445619333686541
epoch 1 iter 45780: train loss 0.60170. lr 3.000000e-04, running loss 0.61071, it/sec: 4.507119384031785
epoch 1 iter 45800: train loss 0.58848. lr 3.000000e-04, running loss 0.61077, it/sec: 4.466788811165438
epoch 1 iter 45820: train loss 0.58320. lr 3.000000e-04, running loss 0.61069, it/sec: 4.499045601652129
epoch 1 iter 45840: train loss 0.55471. lr 3.000000e-04, running loss 0.61048, it/sec: 4.464263950573384
epoch 1 iter 45860: train loss 0.68964. lr 3.000000e-04, running loss 0.61072, it/sec: 4.519491321149076
epoch 1 iter 45880: train loss 0.55273. lr 3.000000e-04, running loss 0.61078, it/sec: 4.4325515347704
epoch 1 iter 45900: train loss 0.55257. lr 3.000000e-04, running loss 0.60998, it/sec: 4.496945989347436
epoch 1 iter 45920: train loss 0.55668. lr 3.000000e-04, running loss 0.61018, it/sec: 4.498597035321644
epoch 1 iter 45940: train loss 0.58027. lr 3.000000e-04, running loss 0.61025, it/sec: 4.472689918395964
epoch 1 iter 45960: train loss 0.56120. lr 3.000000e-04, running loss 0.61028, it/sec: 4.463378692971664
epoch 1 iter 45980: train loss 0.61607. lr 3.000000e-04, running loss 0.61050, it/sec: 4.456614626901959
epoch 1 iter 46000: train loss 0.74953. lr 3.000000e-04, running loss 0.61019, it/sec: 4.510605321993787
epoch 1 iter 46020: train loss 0.61222. lr 3.000000e-04, running loss 0.61076, it/sec: 4.437303107058111
epoch 1 iter 46040: train loss 0.71291. lr 3.000000e-04, running loss 0.61118, it/sec: 4.496924918075691
epoch 1 iter 46060: train loss 0.62968. lr 3.000000e-04, running loss 0.61127, it/sec: 4.435445792611356
epoch 1 iter 46080: train loss 0.53695. lr 3.000000e-04, running loss 0.61102, it/sec: 4.5385738602816605
epoch 1 iter 46100: train loss 0.61347. lr 3.000000e-04, running loss 0.61121, it/sec: 4.413017522653966
epoch 1 iter 46120: train loss 0.59262. lr 3.000000e-04, running loss 0.61090, it/sec: 4.516513507057222
epoch 1 iter 46140: train loss 0.66012. lr 3.000000e-04, running loss 0.61111, it/sec: 4.437157881707034
epoch 1 iter 46160: train loss 0.66650. lr 3.000000e-04, running loss 0.61126, it/sec: 4.513900779033294
epoch 1 iter 46180: train loss 0.53735. lr 3.000000e-04, running loss 0.61166, it/sec: 4.458114808217342
epoch 1 iter 46200: train loss 0.55157. lr 3.000000e-04, running loss 0.61144, it/sec: 4.41283024196026
epoch 1 iter 46220: train loss 0.58791. lr 3.000000e-04, running loss 0.61151, it/sec: 4.44631594810275
epoch 1 iter 46240: train loss 0.52770. lr 3.000000e-04, running loss 0.61129, it/sec: 4.468881021548053
epoch 1 iter 46260: train loss 0.58126. lr 3.000000e-04, running loss 0.61094, it/sec: 4.404939518335324
epoch 1 iter 46280: train loss 0.55942. lr 3.000000e-04, running loss 0.61120, it/sec: 4.493179264540807
epoch 1 iter 46300: train loss 0.62597. lr 3.000000e-04, running loss 0.61148, it/sec: 4.465512812760063
epoch 1 iter 46320: train loss 0.70499. lr 3.000000e-04, running loss 0.61147, it/sec: 4.460126904739055
epoch 1 iter 46340: train loss 0.74245. lr 3.000000e-04, running loss 0.61170, it/sec: 4.509579670535523
epoch 1 iter 46360: train loss 0.68509. lr 3.000000e-04, running loss 0.61162, it/sec: 4.440671512292977
epoch 1 iter 46380: train loss 0.59329. lr 3.000000e-04, running loss 0.61141, it/sec: 4.474388844557767
epoch 1 iter 46400: train loss 0.61409. lr 3.000000e-04, running loss 0.61115, it/sec: 4.458873855845878
epoch 1 iter 46420: train loss 0.54886. lr 3.000000e-04, running loss 0.61129, it/sec: 4.447653020377487
epoch 1 iter 46440: train loss 0.61149. lr 3.000000e-04, running loss 0.61154, it/sec: 4.485247115324835
epoch 1 iter 46460: train loss 0.59898. lr 3.000000e-04, running loss 0.61130, it/sec: 4.436591126430477
epoch 1 iter 46480: train loss 0.51590. lr 3.000000e-04, running loss 0.61131, it/sec: 4.487311774549108
epoch 1 iter 46500: train loss 0.70679. lr 3.000000e-04, running loss 0.61102, it/sec: 4.493169513294478
epoch 1 iter 46520: train loss 0.62151. lr 3.000000e-04, running loss 0.61086, it/sec: 4.4761264474423585
epoch 1 iter 46540: train loss 0.57587. lr 3.000000e-04, running loss 0.61105, it/sec: 4.503445992336696
epoch 1 iter 46560: train loss 0.58864. lr 3.000000e-04, running loss 0.61132, it/sec: 4.445510378420191
epoch 1 iter 46580: train loss 0.58597. lr 3.000000e-04, running loss 0.61144, it/sec: 4.4876959408500205
epoch 1 iter 46600: train loss 0.82440. lr 3.000000e-04, running loss 0.61145, it/sec: 4.487902942488462
epoch 1 iter 46620: train loss 0.51447. lr 3.000000e-04, running loss 0.61105, it/sec: 4.457227197596726
epoch 1 iter 46640: train loss 0.59277. lr 3.000000e-04, running loss 0.61072, it/sec: 4.500351835103607
epoch 1 iter 46660: train loss 0.63398. lr 3.000000e-04, running loss 0.61093, it/sec: 4.4483072552217475
epoch 1 iter 46680: train loss 0.72696. lr 3.000000e-04, running loss 0.61117, it/sec: 4.489537035062941
epoch 1 iter 46700: train loss 0.59205. lr 3.000000e-04, running loss 0.61111, it/sec: 4.381142235635101
epoch 1 iter 46720: train loss 0.77589. lr 3.000000e-04, running loss 0.61171, it/sec: 4.501643325355622
epoch 1 iter 46740: train loss 0.63860. lr 3.000000e-04, running loss 0.61161, it/sec: 4.45016773690631
epoch 1 iter 46760: train loss 0.56765. lr 3.000000e-04, running loss 0.61129, it/sec: 4.491621441125903
epoch 1 iter 46780: train loss 0.58379. lr 3.000000e-04, running loss 0.61083, it/sec: 4.491940041460357
epoch 1 iter 46800: train loss 0.53931. lr 3.000000e-04, running loss 0.61086, it/sec: 4.479684228315253
epoch 1 iter 46820: train loss 0.65787. lr 3.000000e-04, running loss 0.61057, it/sec: 4.504352128333428
epoch 1 iter 46840: train loss 0.59775. lr 3.000000e-04, running loss 0.61049, it/sec: 4.433003591475007
epoch 1 iter 46860: train loss 0.59796. lr 3.000000e-04, running loss 0.61024, it/sec: 4.506872419435839
epoch 1 iter 46880: train loss 0.68376. lr 3.000000e-04, running loss 0.61110, it/sec: 4.468087738627181
epoch 1 iter 46900: train loss 0.65932. lr 3.000000e-04, running loss 0.61095, it/sec: 4.478383445544451
epoch 1 iter 46920: train loss 0.73630. lr 3.000000e-04, running loss 0.61087, it/sec: 4.4917364804547955
epoch 1 iter 46940: train loss 0.65353. lr 3.000000e-04, running loss 0.61088, it/sec: 4.4515946747856
epoch 1 iter 46960: train loss 0.59132. lr 3.000000e-04, running loss 0.61041, it/sec: 4.509196159579622
epoch 1 iter 46980: train loss 0.54621. lr 3.000000e-04, running loss 0.61000, it/sec: 4.468551365453869
epoch 1 iter 47000: train loss 0.60472. lr 3.000000e-04, running loss 0.60994, it/sec: 4.515982137530141
epoch 1 iter 47020: train loss 0.63163. lr 3.000000e-04, running loss 0.61131, it/sec: 4.436354112285355
epoch 1 iter 47040: train loss 0.60824. lr 3.000000e-04, running loss 0.61134, it/sec: 4.507470257166753
epoch 1 iter 47060: train loss 0.67302. lr 3.000000e-04, running loss 0.61144, it/sec: 4.442024626811868
epoch 1 iter 47080: train loss 0.58414. lr 3.000000e-04, running loss 0.61150, it/sec: 4.490413323994394
epoch 1 iter 47100: train loss 0.47700. lr 3.000000e-04, running loss 0.61125, it/sec: 4.48718316960828
epoch 1 iter 47120: train loss 0.97814. lr 3.000000e-04, running loss 0.61130, it/sec: 4.4416481214423555
epoch 1 iter 47140: train loss 0.62129. lr 3.000000e-04, running loss 0.61073, it/sec: 4.493496086734069
epoch 1 iter 47160: train loss 0.61110. lr 3.000000e-04, running loss 0.61079, it/sec: 4.414272129001016
epoch 1 iter 47180: train loss 0.55891. lr 3.000000e-04, running loss 0.61116, it/sec: 4.470233478929201
epoch 1 iter 47200: train loss 0.57576. lr 3.000000e-04, running loss 0.61074, it/sec: 4.418622720150075
epoch 1 iter 47220: train loss 0.84082. lr 3.000000e-04, running loss 0.61056, it/sec: 4.442770487495784
epoch 1 iter 47240: train loss 0.64731. lr 3.000000e-04, running loss 0.61040, it/sec: 4.510302864966642
epoch 1 iter 47260: train loss 0.56414. lr 3.000000e-04, running loss 0.61036, it/sec: 4.466105751904143
epoch 1 iter 47280: train loss 0.54168. lr 3.000000e-04, running loss 0.61034, it/sec: 4.5101350013133175
epoch 1 iter 47300: train loss 0.60567. lr 3.000000e-04, running loss 0.61069, it/sec: 4.4522711410554185
epoch 1 iter 47320: train loss 0.58338. lr 3.000000e-04, running loss 0.61043, it/sec: 4.4705208335437305
epoch 1 iter 47340: train loss 0.61903. lr 3.000000e-04, running loss 0.61047, it/sec: 4.480348041510407
epoch 1 iter 47360: train loss 0.54752. lr 3.000000e-04, running loss 0.61037, it/sec: 4.488447387432134
epoch 1 iter 47380: train loss 0.46289. lr 3.000000e-04, running loss 0.60994, it/sec: 4.447895021678658
epoch 1 iter 47400: train loss 0.61131. lr 3.000000e-04, running loss 0.60982, it/sec: 4.520460835873916
epoch 1 iter 47420: train loss 0.56908. lr 3.000000e-04, running loss 0.60968, it/sec: 4.457761700863199
epoch 1 iter 47440: train loss 0.68343. lr 3.000000e-04, running loss 0.60992, it/sec: 4.483149003035435
epoch 1 iter 47460: train loss 0.59541. lr 3.000000e-04, running loss 0.60978, it/sec: 4.510938546185743
epoch 1 iter 47480: train loss 0.63242. lr 3.000000e-04, running loss 0.60913, it/sec: 4.455156958585524
epoch 1 iter 47500: train loss 0.54876. lr 3.000000e-04, running loss 0.60956, it/sec: 4.50399967051235
epoch 1 iter 47520: train loss 0.52519. lr 3.000000e-04, running loss 0.60989, it/sec: 4.43477737805622
epoch 1 iter 47540: train loss 0.56684. lr 3.000000e-04, running loss 0.60946, it/sec: 4.51109602804662
epoch 1 iter 47560: train loss 0.66884. lr 3.000000e-04, running loss 0.60968, it/sec: 4.453921677734825
epoch 1 iter 47580: train loss 0.64731. lr 3.000000e-04, running loss 0.61018, it/sec: 4.507628819216711
epoch 1 iter 47600: train loss 0.52895. lr 3.000000e-04, running loss 0.61009, it/sec: 4.431491666478419
epoch 1 iter 47620: train loss 0.57739. lr 3.000000e-04, running loss 0.60974, it/sec: 4.516024108764307
epoch 1 iter 47640: train loss 0.55291. lr 3.000000e-04, running loss 0.60973, it/sec: 4.41974896923588
epoch 1 iter 47660: train loss 0.57295. lr 3.000000e-04, running loss 0.61046, it/sec: 4.498473469633582
epoch 1 iter 47680: train loss 0.53924. lr 3.000000e-04, running loss 0.61050, it/sec: 4.482575664548005
epoch 1 iter 47700: train loss 0.63444. lr 3.000000e-04, running loss 0.61051, it/sec: 4.473968200102315
epoch 1 iter 47720: train loss 0.52249. lr 3.000000e-04, running loss 0.61013, it/sec: 4.50303142439009
epoch 1 iter 47740: train loss 0.58564. lr 3.000000e-04, running loss 0.60992, it/sec: 4.47600281047178
epoch 1 iter 47760: train loss 0.67456. lr 3.000000e-04, running loss 0.60981, it/sec: 4.497218523506682
epoch 1 iter 47780: train loss 0.65864. lr 3.000000e-04, running loss 0.60948, it/sec: 4.460502391944187
epoch 1 iter 47800: train loss 0.63663. lr 3.000000e-04, running loss 0.60946, it/sec: 4.527863199933661
epoch 1 iter 47820: train loss 0.59863. lr 3.000000e-04, running loss 0.60920, it/sec: 4.467548181901457
epoch 1 iter 47840: train loss 0.56836. lr 3.000000e-04, running loss 0.60912, it/sec: 4.502410072503286
epoch 1 iter 47860: train loss 0.69208. lr 3.000000e-04, running loss 0.60951, it/sec: 4.4815980685256696
epoch 1 iter 47880: train loss 0.56122. lr 3.000000e-04, running loss 0.60939, it/sec: 4.481119439109816
epoch 1 iter 47900: train loss 0.66561. lr 3.000000e-04, running loss 0.60938, it/sec: 4.460016026091489
epoch 1 iter 47920: train loss 0.60759. lr 3.000000e-04, running loss 0.60947, it/sec: 4.510888772909327
epoch 1 iter 47940: train loss 0.60185. lr 3.000000e-04, running loss 0.60942, it/sec: 4.461731671613282
epoch 1 iter 47960: train loss 0.68403. lr 3.000000e-04, running loss 0.60976, it/sec: 4.485677308934609
epoch 1 iter 47980: train loss 0.58477. lr 3.000000e-04, running loss 0.60978, it/sec: 4.48861478749315
epoch 1 iter 48000: train loss 0.68105. lr 3.000000e-04, running loss 0.60965, it/sec: 4.456908138429438
epoch 1 iter 48020: train loss 0.64026. lr 3.000000e-04, running loss 0.60945, it/sec: 4.504814179881254
epoch 1 iter 48040: train loss 0.61719. lr 3.000000e-04, running loss 0.60945, it/sec: 4.442118925364615
epoch 1 iter 48060: train loss 0.69244. lr 3.000000e-04, running loss 0.60988, it/sec: 4.508668991610065
epoch 1 iter 48080: train loss 0.55173. lr 3.000000e-04, running loss 0.60962, it/sec: 4.465793538253551
epoch 1 iter 48100: train loss 0.62140. lr 3.000000e-04, running loss 0.61002, it/sec: 4.472600657574305
epoch 1 iter 48120: train loss 0.61527. lr 3.000000e-04, running loss 0.61005, it/sec: 4.484792629034006
epoch 1 iter 48140: train loss 0.77301. lr 3.000000e-04, running loss 0.60997, it/sec: 4.491711785725674
epoch 1 iter 48160: train loss 0.52699. lr 3.000000e-04, running loss 0.60968, it/sec: 4.490399088373877
epoch 1 iter 48180: train loss 0.65068. lr 3.000000e-04, running loss 0.60986, it/sec: 4.451868044085093
epoch 1 iter 48200: train loss 0.67131. lr 3.000000e-04, running loss 0.61041, it/sec: 4.49541960602873
epoch 1 iter 48220: train loss 0.58730. lr 3.000000e-04, running loss 0.61017, it/sec: 4.461500203892891
epoch 1 iter 48240: train loss 0.60750. lr 3.000000e-04, running loss 0.61115, it/sec: 4.488623129267447
epoch 1 iter 48260: train loss 0.67678. lr 3.000000e-04, running loss 0.61105, it/sec: 4.429614370394358
epoch 1 iter 48280: train loss 0.69486. lr 3.000000e-04, running loss 0.61080, it/sec: 4.5174124813783045
epoch 1 iter 48300: train loss 0.54611. lr 3.000000e-04, running loss 0.61115, it/sec: 4.455590966030686
epoch 1 iter 48320: train loss 0.72439. lr 3.000000e-04, running loss 0.61116, it/sec: 4.505777062055606
epoch 1 iter 48340: train loss 0.61085. lr 3.000000e-04, running loss 0.61079, it/sec: 4.451441813484253
epoch 1 iter 48360: train loss 0.55872. lr 3.000000e-04, running loss 0.61051, it/sec: 4.505370144060824
epoch 1 iter 48380: train loss 0.59322. lr 3.000000e-04, running loss 0.61031, it/sec: 4.449321157874764
epoch 1 iter 48400: train loss 0.59714. lr 3.000000e-04, running loss 0.61054, it/sec: 4.485956710033539
epoch 1 iter 48420: train loss 0.59369. lr 3.000000e-04, running loss 0.61050, it/sec: 4.5045231924111695
epoch 1 iter 48440: train loss 0.58553. lr 3.000000e-04, running loss 0.61063, it/sec: 4.46372780810748
epoch 1 iter 48460: train loss 0.57837. lr 3.000000e-04, running loss 0.61034, it/sec: 4.507617522046648
epoch 1 iter 48480: train loss 0.73074. lr 3.000000e-04, running loss 0.61003, it/sec: 4.455859742477087
epoch 1 iter 48500: train loss 0.56625. lr 3.000000e-04, running loss 0.61007, it/sec: 4.484612500865503
epoch 1 iter 48520: train loss 0.64710. lr 3.000000e-04, running loss 0.61026, it/sec: 4.468546973172821
epoch 1 iter 48540: train loss 0.58396. lr 3.000000e-04, running loss 0.61001, it/sec: 4.49190386404244
epoch 1 iter 48560: train loss 0.70406. lr 3.000000e-04, running loss 0.61011, it/sec: 4.461982654354994
epoch 1 iter 48580: train loss 0.62146. lr 3.000000e-04, running loss 0.61005, it/sec: 4.512407824451194
epoch 1 iter 48600: train loss 0.56574. lr 3.000000e-04, running loss 0.60974, it/sec: 4.422469176394611
epoch 1 iter 48620: train loss 0.62459. lr 3.000000e-04, running loss 0.61002, it/sec: 4.50242150642257
epoch 1 iter 48640: train loss 0.62840. lr 3.000000e-04, running loss 0.61038, it/sec: 4.467122914981317
epoch 1 iter 48660: train loss 0.57495. lr 3.000000e-04, running loss 0.60984, it/sec: 4.479565170773498
epoch 1 iter 48680: train loss 0.60450. lr 3.000000e-04, running loss 0.61067, it/sec: 4.490629894018451
epoch 1 iter 48700: train loss 0.57386. lr 3.000000e-04, running loss 0.61044, it/sec: 4.468496135385448
epoch 1 iter 48720: train loss 0.53440. lr 3.000000e-04, running loss 0.61012, it/sec: 4.517118783317927
epoch 1 iter 48740: train loss 1.02583. lr 3.000000e-04, running loss 0.61033, it/sec: 4.476340820424286
epoch 1 iter 48760: train loss 0.66715. lr 3.000000e-04, running loss 0.61041, it/sec: 4.501680957369979
epoch 1 iter 48780: train loss 0.58540. lr 3.000000e-04, running loss 0.61040, it/sec: 4.453009164488094
epoch 1 iter 48800: train loss 0.57969. lr 3.000000e-04, running loss 0.61031, it/sec: 4.501239301225979
epoch 1 iter 48820: train loss 0.61981. lr 3.000000e-04, running loss 0.61056, it/sec: 4.455264380321474
epoch 1 iter 48840: train loss 0.58773. lr 3.000000e-04, running loss 0.61066, it/sec: 4.48687299302853
epoch 1 iter 48860: train loss 0.63982. lr 3.000000e-04, running loss 0.61099, it/sec: 4.460084455026592
epoch 1 iter 48880: train loss 0.53732. lr 3.000000e-04, running loss 0.61083, it/sec: 4.500416909563653
epoch 1 iter 48900: train loss 0.56682. lr 3.000000e-04, running loss 0.61073, it/sec: 4.484645847303244
epoch 1 iter 48920: train loss 0.59754. lr 3.000000e-04, running loss 0.61033, it/sec: 4.505958589542842
epoch 1 iter 48940: train loss 0.56746. lr 3.000000e-04, running loss 0.61013, it/sec: 4.485659460877597
epoch 1 iter 48960: train loss 0.44546. lr 3.000000e-04, running loss 0.61020, it/sec: 4.511647804707967
epoch 1 iter 48980: train loss 0.57128. lr 3.000000e-04, running loss 0.61017, it/sec: 4.478915872608646
epoch 1 iter 49000: train loss 0.63570. lr 3.000000e-04, running loss 0.60977, it/sec: 4.4578491569649135
epoch 1 iter 49020: train loss 0.60588. lr 3.000000e-04, running loss 0.60933, it/sec: 4.517805187255769
epoch 1 iter 49040: train loss 1.09728. lr 3.000000e-04, running loss 0.60986, it/sec: 4.4573225798630025
epoch 1 iter 49060: train loss 0.74294. lr 3.000000e-04, running loss 0.61003, it/sec: 4.503469397270868
epoch 1 iter 49080: train loss 0.62211. lr 3.000000e-04, running loss 0.60994, it/sec: 4.457287256262365
epoch 1 iter 49100: train loss 0.53940. lr 3.000000e-04, running loss 0.60992, it/sec: 4.505452942963974
epoch 1 iter 49120: train loss 0.66774. lr 3.000000e-04, running loss 0.61010, it/sec: 4.483080327803033
epoch 1 iter 49140: train loss 0.53775. lr 3.000000e-04, running loss 0.60990, it/sec: 4.505279027076296
epoch 1 iter 49160: train loss 0.77853. lr 3.000000e-04, running loss 0.60971, it/sec: 4.4579045024136486
epoch 1 iter 49180: train loss 0.86000. lr 3.000000e-04, running loss 0.60992, it/sec: 4.497877813352754
epoch 1 iter 49200: train loss 0.70400. lr 3.000000e-04, running loss 0.60965, it/sec: 4.461980702813454
epoch 1 iter 49220: train loss 0.60375. lr 3.000000e-04, running loss 0.60963, it/sec: 4.515159752079668
epoch 1 iter 49240: train loss 0.55044. lr 3.000000e-04, running loss 0.60940, it/sec: 4.4431665101393305
epoch 1 iter 49260: train loss 0.58178. lr 3.000000e-04, running loss 0.60913, it/sec: 4.502173068340666
epoch 1 iter 49280: train loss 0.63513. lr 3.000000e-04, running loss 0.60927, it/sec: 4.439654708399421
epoch 1 iter 49300: train loss 0.59397. lr 3.000000e-04, running loss 0.60978, it/sec: 4.507959875568487
epoch 1 iter 49320: train loss 0.67726. lr 3.000000e-04, running loss 0.60993, it/sec: 4.517849172902534
epoch 1 iter 49340: train loss 0.61464. lr 3.000000e-04, running loss 0.60966, it/sec: 4.449963169967193
epoch 1 iter 49360: train loss 0.63338. lr 3.000000e-04, running loss 0.61011, it/sec: 4.518066110242111
epoch 1 iter 49380: train loss 0.61601. lr 3.000000e-04, running loss 0.61029, it/sec: 4.487081510256606
epoch 1 iter 49400: train loss 0.65389. lr 3.000000e-04, running loss 0.61030, it/sec: 4.507583183822727
epoch 1 iter 49420: train loss 0.63592. lr 3.000000e-04, running loss 0.61038, it/sec: 4.470866909737684
epoch 1 iter 49440: train loss 0.58560. lr 3.000000e-04, running loss 0.61047, it/sec: 4.492646063460878
epoch 1 iter 49460: train loss 0.50031. lr 3.000000e-04, running loss 0.61053, it/sec: 4.465237965993609
epoch 1 iter 49480: train loss 0.54781. lr 3.000000e-04, running loss 0.61024, it/sec: 4.402505123725344
epoch 1 iter 49500: train loss 0.68095. lr 3.000000e-04, running loss 0.61035, it/sec: 4.450846185270495
epoch 1 iter 49520: train loss 0.59620. lr 3.000000e-04, running loss 0.61058, it/sec: 4.503403929939519
epoch 1 iter 49540: train loss 0.61249. lr 3.000000e-04, running loss 0.61068, it/sec: 4.446907043549923
epoch 1 iter 49560: train loss 0.63075. lr 3.000000e-04, running loss 0.61086, it/sec: 4.515870707902295
epoch 1 iter 49580: train loss 0.58996. lr 3.000000e-04, running loss 0.61051, it/sec: 4.486353143752326
epoch 1 iter 49600: train loss 0.51063. lr 3.000000e-04, running loss 0.61020, it/sec: 4.522909076298772
epoch 1 iter 49620: train loss 0.52261. lr 3.000000e-04, running loss 0.61042, it/sec: 4.4630739504392105
epoch 1 iter 49640: train loss 0.64133. lr 3.000000e-04, running loss 0.61012, it/sec: 4.482363928779413
epoch 1 iter 49660: train loss 0.57217. lr 3.000000e-04, running loss 0.60996, it/sec: 4.512414217505477
epoch 1 iter 49680: train loss 0.59813. lr 3.000000e-04, running loss 0.61000, it/sec: 4.471075481336086
epoch 1 iter 49700: train loss 0.59397. lr 3.000000e-04, running loss 0.61001, it/sec: 4.476967003480154
epoch 1 iter 49720: train loss 0.59028. lr 3.000000e-04, running loss 0.61013, it/sec: 4.474688826682167
epoch 1 iter 49740: train loss 0.64769. lr 3.000000e-04, running loss 0.61058, it/sec: 4.484331035014913
epoch 1 iter 49760: train loss 0.56124. lr 3.000000e-04, running loss 0.61008, it/sec: 4.471127917310763
epoch 1 iter 49780: train loss 0.60386. lr 3.000000e-04, running loss 0.61026, it/sec: 4.5132736733592465
epoch 1 iter 49800: train loss 0.54959. lr 3.000000e-04, running loss 0.61008, it/sec: 4.470431079970002
epoch 1 iter 49820: train loss 0.66762. lr 3.000000e-04, running loss 0.60975, it/sec: 4.517593030288759
epoch 1 iter 49840: train loss 0.49846. lr 3.000000e-04, running loss 0.60946, it/sec: 4.4832796079510295
epoch 1 iter 49860: train loss 0.63677. lr 3.000000e-04, running loss 0.60948, it/sec: 4.497656539083765
epoch 1 iter 49880: train loss 0.66042. lr 3.000000e-04, running loss 0.61000, it/sec: 4.441698961093232
epoch 1 iter 49900: train loss 0.61971. lr 3.000000e-04, running loss 0.61001, it/sec: 4.510214619810978
epoch 1 iter 49920: train loss 0.68353. lr 3.000000e-04, running loss 0.61073, it/sec: 4.46529493071854
epoch 1 iter 49940: train loss 0.60961. lr 3.000000e-04, running loss 0.61080, it/sec: 4.519106980834501
epoch 1 iter 49960: train loss 0.62285. lr 3.000000e-04, running loss 0.61041, it/sec: 4.4527814157245835
epoch 1 iter 49980: train loss 0.62858. lr 3.000000e-04, running loss 0.61033, it/sec: 4.496289681527803
epoch 1 iter 50000: train loss 0.59910. lr 3.000000e-04, running loss 0.61037, it/sec: 1.1417552251127727
epoch 1 iter 50020: train loss 0.57960. lr 3.000000e-04, running loss 0.60991, it/sec: 4.472276534409472
epoch 1 iter 50040: train loss 0.60686. lr 3.000000e-04, running loss 0.61022, it/sec: 4.454067447071443
epoch 1 iter 50060: train loss 0.64262. lr 3.000000e-04, running loss 0.61026, it/sec: 4.505346172327796
epoch 1 iter 50080: train loss 0.65911. lr 3.000000e-04, running loss 0.61060, it/sec: 4.434886279514217
epoch 1 iter 50100: train loss 0.72150. lr 3.000000e-04, running loss 0.61111, it/sec: 4.528223399800692
epoch 1 iter 50120: train loss 0.68955. lr 3.000000e-04, running loss 0.61068, it/sec: 4.458839063129331
epoch 1 iter 50140: train loss 0.58304. lr 3.000000e-04, running loss 0.61053, it/sec: 4.47751493164279
epoch 1 iter 50160: train loss 0.62597. lr 3.000000e-04, running loss 0.61045, it/sec: 4.502325602536462
epoch 1 iter 50180: train loss 0.63842. lr 3.000000e-04, running loss 0.61030, it/sec: 4.476010304275208
epoch 1 iter 50200: train loss 0.64381. lr 3.000000e-04, running loss 0.61020, it/sec: 4.503273813116249
epoch 1 iter 50220: train loss 0.62026. lr 3.000000e-04, running loss 0.61035, it/sec: 4.443557806114766
epoch 1 iter 50240: train loss 0.59145. lr 3.000000e-04, running loss 0.61057, it/sec: 4.485348450337736
epoch 1 iter 50260: train loss 0.64676. lr 3.000000e-04, running loss 0.61110, it/sec: 4.440431044670128
epoch 1 iter 50280: train loss 0.55538. lr 3.000000e-04, running loss 0.61090, it/sec: 4.519568654576089
epoch 1 iter 50300: train loss 0.66919. lr 3.000000e-04, running loss 0.61131, it/sec: 4.451680700938353
epoch 1 iter 50320: train loss 0.55073. lr 3.000000e-04, running loss 0.61128, it/sec: 4.504855802032606
epoch 1 iter 50340: train loss 0.59812. lr 3.000000e-04, running loss 0.61112, it/sec: 4.469200338203145
epoch 1 iter 50360: train loss 0.68874. lr 3.000000e-04, running loss 0.61149, it/sec: 4.511563841989228
epoch 1 iter 50380: train loss 0.60340. lr 3.000000e-04, running loss 0.61225, it/sec: 4.4430595526388155
epoch 1 iter 50400: train loss 0.52401. lr 3.000000e-04, running loss 0.61257, it/sec: 4.510629675401716
epoch 1 iter 50420: train loss 0.69069. lr 3.000000e-04, running loss 0.61272, it/sec: 4.439918864490942
epoch 1 iter 50440: train loss 0.49774. lr 3.000000e-04, running loss 0.61242, it/sec: 4.509982894142539
epoch 1 iter 50460: train loss 0.56985. lr 3.000000e-04, running loss 0.61205, it/sec: 4.410815407586325
epoch 1 iter 50480: train loss 0.62502. lr 3.000000e-04, running loss 0.61186, it/sec: 4.526522079557295
epoch 1 iter 50500: train loss 0.61772. lr 3.000000e-04, running loss 0.61158, it/sec: 4.497468721558006
epoch 1 iter 50520: train loss 0.54256. lr 3.000000e-04, running loss 0.61210, it/sec: 4.523446211304169
epoch 1 iter 50540: train loss 0.57408. lr 3.000000e-04, running loss 0.61190, it/sec: 4.447213339785027
epoch 1 iter 50560: train loss 0.53003. lr 3.000000e-04, running loss 0.61137, it/sec: 4.466633808353698
epoch 1 iter 50580: train loss 0.55212. lr 3.000000e-04, running loss 0.61113, it/sec: 4.491091939274396
epoch 1 iter 50600: train loss 0.58587. lr 3.000000e-04, running loss 0.61111, it/sec: 4.45088212063227
epoch 1 iter 50620: train loss 0.59368. lr 3.000000e-04, running loss 0.61069, it/sec: 4.4863121849790355
epoch 1 iter 50640: train loss 0.58892. lr 3.000000e-04, running loss 0.61050, it/sec: 4.512772859645342
epoch 1 iter 50660: train loss 0.57945. lr 3.000000e-04, running loss 0.61056, it/sec: 4.478970137955466
epoch 1 iter 50680: train loss 0.63433. lr 3.000000e-04, running loss 0.61086, it/sec: 4.495173394968934
epoch 1 iter 50700: train loss 0.62145. lr 3.000000e-04, running loss 0.61074, it/sec: 4.501567576069905
epoch 1 iter 50720: train loss 0.61528. lr 3.000000e-04, running loss 0.61074, it/sec: 4.466622675090147
epoch 1 iter 50740: train loss 0.61663. lr 3.000000e-04, running loss 0.61047, it/sec: 4.499330396590165
epoch 1 iter 50760: train loss 0.53748. lr 3.000000e-04, running loss 0.61013, it/sec: 4.463448838183142
epoch 1 iter 50780: train loss 0.69380. lr 3.000000e-04, running loss 0.61041, it/sec: 4.506083683676488
epoch 1 iter 50800: train loss 0.60476. lr 3.000000e-04, running loss 0.61044, it/sec: 4.462948005175784
epoch 1 iter 50820: train loss 0.57230. lr 3.000000e-04, running loss 0.61056, it/sec: 4.503611470654058
epoch 1 iter 50840: train loss 0.58416. lr 3.000000e-04, running loss 0.61025, it/sec: 4.458796538406726
epoch 1 iter 50860: train loss 0.60641. lr 3.000000e-04, running loss 0.61051, it/sec: 4.473235800729779
epoch 1 iter 50880: train loss 0.69897. lr 3.000000e-04, running loss 0.61033, it/sec: 4.500382700999043
epoch 1 iter 50900: train loss 0.59462. lr 3.000000e-04, running loss 0.61064, it/sec: 4.486351272760912
epoch 1 iter 50920: train loss 0.69210. lr 3.000000e-04, running loss 0.61077, it/sec: 4.4462398756577555
epoch 1 iter 50940: train loss 0.70626. lr 3.000000e-04, running loss 0.61070, it/sec: 4.509527671105331
epoch 1 iter 50960: train loss 0.54611. lr 3.000000e-04, running loss 0.61099, it/sec: 4.454864034604581
epoch 1 iter 50980: train loss 0.62350. lr 3.000000e-04, running loss 0.61084, it/sec: 4.512378197847134
epoch 1 iter 51000: train loss 0.56317. lr 3.000000e-04, running loss 0.61035, it/sec: 4.4395963848156486
epoch 1 iter 51020: train loss 0.59086. lr 3.000000e-04, running loss 0.61076, it/sec: 4.489635559238072
epoch 1 iter 51040: train loss 0.68375. lr 3.000000e-04, running loss 0.61055, it/sec: 4.513617009950487
epoch 1 iter 51060: train loss 0.58102. lr 3.000000e-04, running loss 0.61057, it/sec: 4.459551401929478
epoch 1 iter 51080: train loss 0.58629. lr 3.000000e-04, running loss 0.61079, it/sec: 4.517071506617016
epoch 1 iter 51100: train loss 0.69755. lr 3.000000e-04, running loss 0.61082, it/sec: 4.4485188715441595
epoch 1 iter 51120: train loss 0.57888. lr 3.000000e-04, running loss 0.61102, it/sec: 4.515498339939565
epoch 1 iter 51140: train loss 0.58783. lr 3.000000e-04, running loss 0.61122, it/sec: 4.42463218073896
epoch 1 iter 51160: train loss 0.60398. lr 3.000000e-04, running loss 0.61112, it/sec: 4.509336014277022
epoch 1 iter 51180: train loss 0.58228. lr 3.000000e-04, running loss 0.61189, it/sec: 4.4456868061714765
epoch 1 iter 51200: train loss 0.66528. lr 3.000000e-04, running loss 0.61199, it/sec: 4.502682925966287
epoch 1 iter 51220: train loss 0.56855. lr 3.000000e-04, running loss 0.61226, it/sec: 4.450578725826219
epoch 1 iter 51240: train loss 0.72819. lr 3.000000e-04, running loss 0.61240, it/sec: 4.503602769664861
epoch 1 iter 51260: train loss 0.49821. lr 3.000000e-04, running loss 0.61279, it/sec: 4.48115550380225
epoch 1 iter 51280: train loss 0.61742. lr 3.000000e-04, running loss 0.61254, it/sec: 4.4572854880732695
epoch 1 iter 51300: train loss 0.71336. lr 3.000000e-04, running loss 0.61244, it/sec: 4.511269722843712
epoch 1 iter 51320: train loss 0.52371. lr 3.000000e-04, running loss 0.61204, it/sec: 4.484739107577716
epoch 1 iter 51340: train loss 0.54084. lr 3.000000e-04, running loss 0.61123, it/sec: 4.518420711313941
epoch 1 iter 51360: train loss 0.50631. lr 3.000000e-04, running loss 0.61212, it/sec: 4.456131054890919
epoch 1 iter 51380: train loss 0.68092. lr 3.000000e-04, running loss 0.61197, it/sec: 4.510685687816782
epoch 1 iter 51400: train loss 0.60831. lr 3.000000e-04, running loss 0.61170, it/sec: 4.452863026992019
epoch 1 iter 51420: train loss 0.63233. lr 3.000000e-04, running loss 0.61198, it/sec: 4.498340703570273
epoch 1 iter 51440: train loss 0.57592. lr 3.000000e-04, running loss 0.61127, it/sec: 4.430813352753339
epoch 1 iter 51460: train loss 0.49091. lr 3.000000e-04, running loss 0.61126, it/sec: 4.491634574758659
epoch 1 iter 51480: train loss 0.60243. lr 3.000000e-04, running loss 0.61106, it/sec: 4.468294133441633
epoch 1 iter 51500: train loss 0.53631. lr 3.000000e-04, running loss 0.61146, it/sec: 4.487255374196052
epoch 1 iter 51520: train loss 0.67392. lr 3.000000e-04, running loss 0.61103, it/sec: 4.428111463662148
epoch 1 iter 51540: train loss 0.57640. lr 3.000000e-04, running loss 0.61342, it/sec: 4.516716321662918
epoch 1 iter 51560: train loss 0.54020. lr 3.000000e-04, running loss 0.61325, it/sec: 4.487499287404893
epoch 1 iter 51580: train loss 0.57816. lr 3.000000e-04, running loss 0.61304, it/sec: 4.489573194311499
epoch 1 iter 51600: train loss 0.60280. lr 3.000000e-04, running loss 0.61313, it/sec: 4.497749209672425
epoch 1 iter 51620: train loss 0.58101. lr 3.000000e-04, running loss 0.61342, it/sec: 4.419004451255408
epoch 1 iter 51640: train loss 0.51940. lr 3.000000e-04, running loss 0.61328, it/sec: 4.5175114369436535
epoch 1 iter 51660: train loss 0.63546. lr 3.000000e-04, running loss 0.61331, it/sec: 4.475312985422195
epoch 1 iter 51680: train loss 0.68206. lr 3.000000e-04, running loss 0.61288, it/sec: 4.524068676294131
epoch 1 iter 51700: train loss 0.61129. lr 3.000000e-04, running loss 0.61282, it/sec: 4.460616179759367
epoch 1 iter 51720: train loss 0.55204. lr 3.000000e-04, running loss 0.61295, it/sec: 4.493326283398922
epoch 1 iter 51740: train loss 0.57877. lr 3.000000e-04, running loss 0.61318, it/sec: 4.477344048058874
epoch 1 iter 51760: train loss 0.66890. lr 3.000000e-04, running loss 0.61324, it/sec: 4.47009767912744
epoch 1 iter 51780: train loss 0.65120. lr 3.000000e-04, running loss 0.61352, it/sec: 4.500437770712562
epoch 1 iter 51800: train loss 0.59744. lr 3.000000e-04, running loss 0.61304, it/sec: 4.436477457756883
epoch 1 iter 51820: train loss 0.64329. lr 3.000000e-04, running loss 0.61356, it/sec: 4.504698714213111
epoch 1 iter 51840: train loss 0.64781. lr 3.000000e-04, running loss 0.61371, it/sec: 4.5021345160944115
epoch 1 iter 51860: train loss 0.53566. lr 3.000000e-04, running loss 0.61348, it/sec: 4.486318665977649
epoch 1 iter 51880: train loss 0.50738. lr 3.000000e-04, running loss 0.61320, it/sec: 4.434578157845232
epoch 1 iter 51900: train loss 0.63161. lr 3.000000e-04, running loss 0.61289, it/sec: 4.510911542243688
epoch 1 iter 51920: train loss 0.72378. lr 3.000000e-04, running loss 0.61270, it/sec: 4.463156694255865
epoch 1 iter 51940: train loss 0.52488. lr 3.000000e-04, running loss 0.61223, it/sec: 4.516548592982645
epoch 1 iter 51960: train loss 0.74229. lr 3.000000e-04, running loss 0.61191, it/sec: 4.496988618637185
epoch 1 iter 51980: train loss 0.56983. lr 3.000000e-04, running loss 0.61225, it/sec: 4.468269954959985
epoch 1 iter 52000: train loss 0.67750. lr 3.000000e-04, running loss 0.61195, it/sec: 4.4788808469826105
epoch 1 iter 52020: train loss 0.63397. lr 3.000000e-04, running loss 0.61179, it/sec: 4.482254351953682
epoch 1 iter 52040: train loss 0.58065. lr 3.000000e-04, running loss 0.61150, it/sec: 4.449709617859056
epoch 1 iter 52060: train loss 0.52230. lr 3.000000e-04, running loss 0.61177, it/sec: 4.460555693176661
epoch 1 iter 52080: train loss 0.58993. lr 3.000000e-04, running loss 0.61137, it/sec: 4.488614425113949
epoch 1 iter 52100: train loss 0.54713. lr 3.000000e-04, running loss 0.61119, it/sec: 4.4374641555969925
epoch 1 iter 52120: train loss 0.64281. lr 3.000000e-04, running loss 0.61067, it/sec: 4.480570307104531
epoch 1 iter 52140: train loss 0.63547. lr 3.000000e-04, running loss 0.61107, it/sec: 4.491962016211262
epoch 1 iter 52160: train loss 0.63346. lr 3.000000e-04, running loss 0.61086, it/sec: 4.499800611478528
epoch 1 iter 52180: train loss 0.55991. lr 3.000000e-04, running loss 0.61063, it/sec: 4.451156551064293
epoch 1 iter 52200: train loss 0.61598. lr 3.000000e-04, running loss 0.61077, it/sec: 4.482468507670229
epoch 1 iter 52220: train loss 0.54545. lr 3.000000e-04, running loss 0.61043, it/sec: 4.466321459331474
epoch 1 iter 52240: train loss 0.63537. lr 3.000000e-04, running loss 0.61022, it/sec: 4.49910744060237
epoch 1 iter 52260: train loss 0.54062. lr 3.000000e-04, running loss 0.60992, it/sec: 4.42228662612418
epoch 1 iter 52280: train loss 0.62633. lr 3.000000e-04, running loss 0.60998, it/sec: 4.500282044751219
epoch 1 iter 52300: train loss 0.51565. lr 3.000000e-04, running loss 0.60975, it/sec: 4.5196223150169255
epoch 1 iter 52320: train loss 0.57777. lr 3.000000e-04, running loss 0.60969, it/sec: 4.449672552397315
epoch 1 iter 52340: train loss 0.61073. lr 3.000000e-04, running loss 0.60984, it/sec: 4.501477807638181
epoch 1 iter 52360: train loss 0.62768. lr 3.000000e-04, running loss 0.61017, it/sec: 4.434634559323808
epoch 1 iter 52380: train loss 0.62475. lr 3.000000e-04, running loss 0.60990, it/sec: 4.507117130306641
epoch 1 iter 52400: train loss 0.67864. lr 3.000000e-04, running loss 0.60987, it/sec: 4.463121417261915
epoch 1 iter 52420: train loss 0.51112. lr 3.000000e-04, running loss 0.60974, it/sec: 4.487685487758553
epoch 1 iter 52440: train loss 0.51573. lr 3.000000e-04, running loss 0.60942, it/sec: 4.483223511309572
epoch 1 iter 52460: train loss 0.72580. lr 3.000000e-04, running loss 0.60943, it/sec: 4.515369581159701
epoch 1 iter 52480: train loss 0.53511. lr 3.000000e-04, running loss 0.60972, it/sec: 4.481203940456652
epoch 1 iter 52500: train loss 0.64956. lr 3.000000e-04, running loss 0.60993, it/sec: 4.50468629426658
epoch 1 iter 52520: train loss 0.58544. lr 3.000000e-04, running loss 0.61005, it/sec: 4.438542878678148
epoch 1 iter 52540: train loss 0.60897. lr 3.000000e-04, running loss 0.61010, it/sec: 4.521696544091813
epoch 1 iter 52560: train loss 0.69141. lr 3.000000e-04, running loss 0.61018, it/sec: 4.461418118153208
epoch 1 iter 52580: train loss 0.71354. lr 3.000000e-04, running loss 0.61013, it/sec: 4.5129406743204505
epoch 1 iter 52600: train loss 0.60313. lr 3.000000e-04, running loss 0.60980, it/sec: 4.459941950277523
epoch 1 iter 52620: train loss 0.63903. lr 3.000000e-04, running loss 0.60959, it/sec: 4.483655083746378
epoch 1 iter 52640: train loss 0.55424. lr 3.000000e-04, running loss 0.60925, it/sec: 4.518748249995877
epoch 1 iter 52660: train loss 0.67834. lr 3.000000e-04, running loss 0.60988, it/sec: 4.460641689613582
epoch 1 iter 52680: train loss 0.53669. lr 3.000000e-04, running loss 0.60994, it/sec: 4.498059352628383
epoch 1 iter 52700: train loss 0.58114. lr 3.000000e-04, running loss 0.60921, it/sec: 4.446333938992899
epoch 1 iter 52720: train loss 0.70353. lr 3.000000e-04, running loss 0.60920, it/sec: 4.4854055264867325
epoch 1 iter 52740: train loss 0.57740. lr 3.000000e-04, running loss 0.60900, it/sec: 4.493255154844431
epoch 1 iter 52760: train loss 0.61865. lr 3.000000e-04, running loss 0.60899, it/sec: 4.506327578410172
epoch 1 iter 52780: train loss 0.59876. lr 3.000000e-04, running loss 0.60875, it/sec: 4.487916075487088
epoch 1 iter 52800: train loss 0.51700. lr 3.000000e-04, running loss 0.60912, it/sec: 4.515103201307841
epoch 1 iter 52820: train loss 0.61310. lr 3.000000e-04, running loss 0.60963, it/sec: 4.459850692137391
epoch 1 iter 52840: train loss 1.05077. lr 3.000000e-04, running loss 0.60974, it/sec: 4.526650283658297
epoch 1 iter 52860: train loss 0.58293. lr 3.000000e-04, running loss 0.60931, it/sec: 4.461332769519759
epoch 1 iter 52880: train loss 0.52783. lr 3.000000e-04, running loss 0.60921, it/sec: 4.494984472264025
epoch 1 iter 52900: train loss 0.56189. lr 3.000000e-04, running loss 0.60934, it/sec: 4.463376679909694
epoch 1 iter 52920: train loss 0.55202. lr 3.000000e-04, running loss 0.60940, it/sec: 4.46316452309937
epoch 1 iter 52940: train loss 0.61677. lr 3.000000e-04, running loss 0.60928, it/sec: 4.501405043189427
epoch 1 iter 52960: train loss 0.55451. lr 3.000000e-04, running loss 0.60930, it/sec: 4.472516762147465
epoch 1 iter 52980: train loss 0.62740. lr 3.000000e-04, running loss 0.60931, it/sec: 4.50155047418043
epoch 1 iter 53000: train loss 0.54390. lr 3.000000e-04, running loss 0.60912, it/sec: 4.457977854659792
epoch 1 iter 53020: train loss 0.55775. lr 3.000000e-04, running loss 0.60913, it/sec: 4.53136541826568
epoch 1 iter 53040: train loss 0.60676. lr 3.000000e-04, running loss 0.60934, it/sec: 4.468783345720871
epoch 1 iter 53060: train loss 0.59346. lr 3.000000e-04, running loss 0.60918, it/sec: 4.51762260186259
epoch 1 iter 53080: train loss 0.58960. lr 3.000000e-04, running loss 0.60908, it/sec: 4.456349432984138
epoch 1 iter 53100: train loss 0.55232. lr 3.000000e-04, running loss 0.60909, it/sec: 4.524798060675537
epoch 1 iter 53120: train loss 0.50999. lr 3.000000e-04, running loss 0.60880, it/sec: 4.424177934354238
epoch 1 iter 53140: train loss 0.57567. lr 3.000000e-04, running loss 0.60902, it/sec: 4.520707125751529
epoch 1 iter 53160: train loss 0.50925. lr 3.000000e-04, running loss 0.60888, it/sec: 4.448063625536862
epoch 1 iter 53180: train loss 0.54923. lr 3.000000e-04, running loss 0.60872, it/sec: 4.5047702055365955
epoch 1 iter 53200: train loss 0.63501. lr 3.000000e-04, running loss 0.60898, it/sec: 4.454594822689162
epoch 1 iter 53220: train loss 0.72457. lr 3.000000e-04, running loss 0.60910, it/sec: 4.502531523989196
epoch 1 iter 53240: train loss 0.70512. lr 3.000000e-04, running loss 0.60881, it/sec: 4.394929895159192
epoch 1 iter 53260: train loss 0.62637. lr 3.000000e-04, running loss 0.60878, it/sec: 4.503584109284982
epoch 1 iter 53280: train loss 0.55602. lr 3.000000e-04, running loss 0.60891, it/sec: 4.460870559389246
epoch 1 iter 53300: train loss 0.51402. lr 3.000000e-04, running loss 0.60857, it/sec: 4.516852174483762
epoch 1 iter 53320: train loss 0.62218. lr 3.000000e-04, running loss 0.60844, it/sec: 4.4534427547054465
epoch 1 iter 53340: train loss 0.60978. lr 3.000000e-04, running loss 0.60822, it/sec: 4.503002529804512
epoch 1 iter 53360: train loss 0.69750. lr 3.000000e-04, running loss 0.60805, it/sec: 4.4282882971420525
epoch 1 iter 53380: train loss 0.55498. lr 3.000000e-04, running loss 0.60785, it/sec: 4.482440137177113
epoch 1 iter 53400: train loss 0.61986. lr 3.000000e-04, running loss 0.60808, it/sec: 4.500292332623932
epoch 1 iter 53420: train loss 0.50565. lr 3.000000e-04, running loss 0.60873, it/sec: 4.4705151984650975
epoch 1 iter 53440: train loss 0.61385. lr 3.000000e-04, running loss 0.60873, it/sec: 4.524313579407013
epoch 1 iter 53460: train loss 0.64817. lr 3.000000e-04, running loss 0.60872, it/sec: 4.428984356614814
epoch 1 iter 53480: train loss 0.67831. lr 3.000000e-04, running loss 0.60897, it/sec: 4.4831474564361695
epoch 1 iter 53500: train loss 0.64743. lr 3.000000e-04, running loss 0.60877, it/sec: 4.478172787324787
epoch 1 iter 53520: train loss 0.68417. lr 3.000000e-04, running loss 0.60859, it/sec: 4.465553552807696
epoch 1 iter 53540: train loss 0.60860. lr 3.000000e-04, running loss 0.60849, it/sec: 4.494428542568933
epoch 1 iter 53560: train loss 0.58438. lr 3.000000e-04, running loss 0.60817, it/sec: 4.474320255661168
epoch 1 iter 53580: train loss 0.62572. lr 3.000000e-04, running loss 0.60826, it/sec: 4.458157856732813
epoch 1 iter 53600: train loss 0.59297. lr 3.000000e-04, running loss 0.60820, it/sec: 4.495887549595457
epoch 1 iter 53620: train loss 0.65172. lr 3.000000e-04, running loss 0.60846, it/sec: 4.44213135760816
epoch 1 iter 53640: train loss 0.61771. lr 3.000000e-04, running loss 0.60847, it/sec: 4.49571261257234
epoch 1 iter 53660: train loss 0.53944. lr 3.000000e-04, running loss 0.60839, it/sec: 4.457178961026932
epoch 1 iter 53680: train loss 0.63345. lr 3.000000e-04, running loss 0.60829, it/sec: 4.49914251936557
epoch 1 iter 53700: train loss 0.70396. lr 3.000000e-04, running loss 0.60905, it/sec: 4.490882807324228
epoch 1 iter 53720: train loss 0.57611. lr 3.000000e-04, running loss 0.60893, it/sec: 4.474889845345733
epoch 1 iter 53740: train loss 0.60100. lr 3.000000e-04, running loss 0.60915, it/sec: 4.4942506892979335
epoch 1 iter 53760: train loss 0.59516. lr 3.000000e-04, running loss 0.60999, it/sec: 4.4773171659553475
epoch 1 iter 53780: train loss 0.60922. lr 3.000000e-04, running loss 0.61001, it/sec: 4.52015674889501
epoch 1 iter 53800: train loss 0.69047. lr 3.000000e-04, running loss 0.60981, it/sec: 4.457320772326484
epoch 1 iter 53820: train loss 0.59593. lr 3.000000e-04, running loss 0.60989, it/sec: 4.515012219433549
epoch 1 iter 53840: train loss 0.54445. lr 3.000000e-04, running loss 0.60971, it/sec: 4.484578472440375
epoch 1 iter 53860: train loss 0.67802. lr 3.000000e-04, running loss 0.60964, it/sec: 4.500483687142186
epoch 1 iter 53880: train loss 0.65325. lr 3.000000e-04, running loss 0.61002, it/sec: 4.425911344180244
epoch 1 iter 53900: train loss 0.54316. lr 3.000000e-04, running loss 0.60946, it/sec: 4.54636675291071
epoch 1 iter 53920: train loss 0.74419. lr 3.000000e-04, running loss 0.61047, it/sec: 4.448772942313225
epoch 1 iter 53940: train loss 0.58648. lr 3.000000e-04, running loss 0.61025, it/sec: 4.536523471701343
epoch 1 iter 53960: train loss 0.57411. lr 3.000000e-04, running loss 0.60999, it/sec: 4.436820763764429
epoch 1 iter 53980: train loss 0.62593. lr 3.000000e-04, running loss 0.60978, it/sec: 4.531663704480015
epoch 1 iter 54000: train loss 0.62619. lr 3.000000e-04, running loss 0.60993, it/sec: 4.440805667789975
epoch 1 iter 54020: train loss 0.68679. lr 3.000000e-04, running loss 0.60950, it/sec: 4.499805977653834
epoch 1 iter 54040: train loss 0.53264. lr 3.000000e-04, running loss 0.60961, it/sec: 4.492038733384721
epoch 1 iter 54060: train loss 0.68169. lr 3.000000e-04, running loss 0.60971, it/sec: 4.469698578710833
epoch 1 iter 54080: train loss 0.66627. lr 3.000000e-04, running loss 0.60995, it/sec: 4.496348876976784
epoch 1 iter 54100: train loss 0.60534. lr 3.000000e-04, running loss 0.61026, it/sec: 4.455897308654336
epoch 1 iter 54120: train loss 0.60255. lr 3.000000e-04, running loss 0.61029, it/sec: 4.51842285514332
epoch 1 iter 54140: train loss 0.52617. lr 3.000000e-04, running loss 0.61014, it/sec: 4.453658985152756
epoch 1 iter 54160: train loss 0.58430. lr 3.000000e-04, running loss 0.61007, it/sec: 4.492274327557684
epoch 1 iter 54180: train loss 0.66256. lr 3.000000e-04, running loss 0.60999, it/sec: 4.465778620174567
epoch 1 iter 54200: train loss 0.55832. lr 3.000000e-04, running loss 0.60953, it/sec: 4.51288265105782
epoch 1 iter 54220: train loss 0.63723. lr 3.000000e-04, running loss 0.60976, it/sec: 4.44439891404492
epoch 1 iter 54240: train loss 0.64070. lr 3.000000e-04, running loss 0.60961, it/sec: 4.503216097180642
epoch 1 iter 54260: train loss 0.60322. lr 3.000000e-04, running loss 0.61044, it/sec: 4.50067418778887
epoch 1 iter 54280: train loss 0.61222. lr 3.000000e-04, running loss 0.61079, it/sec: 4.48481931999525
epoch 1 iter 54300: train loss 0.62075. lr 3.000000e-04, running loss 0.61065, it/sec: 4.4656112429338854
epoch 1 iter 54320: train loss 0.66922. lr 3.000000e-04, running loss 0.61055, it/sec: 4.541820242627249
epoch 1 iter 54340: train loss 0.55045. lr 3.000000e-04, running loss 0.61034, it/sec: 4.451739103676376
epoch 1 iter 54360: train loss 0.56594. lr 3.000000e-04, running loss 0.61023, it/sec: 4.5249352593908885
epoch 1 iter 54380: train loss 0.56703. lr 3.000000e-04, running loss 0.61007, it/sec: 4.376387820716063
epoch 1 iter 54400: train loss 0.56470. lr 3.000000e-04, running loss 0.60979, it/sec: 4.52181155458319
epoch 1 iter 54420: train loss 0.54306. lr 3.000000e-04, running loss 0.60975, it/sec: 4.457120454786615
epoch 1 iter 54440: train loss 0.59035. lr 3.000000e-04, running loss 0.61010, it/sec: 4.506648675183714
epoch 1 iter 54460: train loss 0.59211. lr 3.000000e-04, running loss 0.61033, it/sec: 4.46358214219364
epoch 1 iter 54480: train loss 0.63615. lr 3.000000e-04, running loss 0.61064, it/sec: 4.505065527432266
epoch 1 iter 54500: train loss 0.69161. lr 3.000000e-04, running loss 0.61017, it/sec: 4.445600162537762
epoch 1 iter 54520: train loss 0.54607. lr 3.000000e-04, running loss 0.61015, it/sec: 4.514589364529908
epoch 1 iter 54540: train loss 0.55105. lr 3.000000e-04, running loss 0.60972, it/sec: 4.463014790792769
epoch 1 iter 54560: train loss 0.54556. lr 3.000000e-04, running loss 0.60941, it/sec: 4.51238658669846
epoch 1 iter 54580: train loss 0.59437. lr 3.000000e-04, running loss 0.60904, it/sec: 4.431634616647181
epoch 1 iter 54600: train loss 0.53456. lr 3.000000e-04, running loss 0.60851, it/sec: 4.494127725528591
epoch 1 iter 54620: train loss 0.57533. lr 3.000000e-04, running loss 0.60899, it/sec: 4.49800073982517
epoch 1 iter 54640: train loss 0.50691. lr 3.000000e-04, running loss 0.60932, it/sec: 4.495164080834802
epoch 1 iter 54660: train loss 0.53869. lr 3.000000e-04, running loss 0.60936, it/sec: 4.443229626443461
epoch 1 iter 54680: train loss 0.57267. lr 3.000000e-04, running loss 0.60946, it/sec: 4.428554221117323
epoch 1 iter 54700: train loss 0.54569. lr 3.000000e-04, running loss 0.60956, it/sec: 4.524684863281381
epoch 1 iter 54720: train loss 0.67377. lr 3.000000e-04, running loss 0.60970, it/sec: 4.458299471170811
epoch 1 iter 54740: train loss 0.54024. lr 3.000000e-04, running loss 0.60996, it/sec: 4.504932513734004
epoch 1 iter 54760: train loss 0.54173. lr 3.000000e-04, running loss 0.60992, it/sec: 4.428101777081732
epoch 1 iter 54780: train loss 0.55505. lr 3.000000e-04, running loss 0.60963, it/sec: 4.518611773240724
epoch 1 iter 54800: train loss 0.60684. lr 3.000000e-04, running loss 0.60911, it/sec: 4.4138436975279784
epoch 1 iter 54820: train loss 0.61508. lr 3.000000e-04, running loss 0.60903, it/sec: 4.509764515022619
epoch 1 iter 54840: train loss 0.77408. lr 3.000000e-04, running loss 0.60908, it/sec: 4.456789255977942
epoch 1 iter 54860: train loss 0.53032. lr 3.000000e-04, running loss 0.60909, it/sec: 4.511656963346152
epoch 1 iter 54880: train loss 0.57252. lr 3.000000e-04, running loss 0.60887, it/sec: 4.430254575852034
epoch 1 iter 54900: train loss 0.65060. lr 3.000000e-04, running loss 0.60910, it/sec: 4.516924806209377
epoch 1 iter 54920: train loss 0.62384. lr 3.000000e-04, running loss 0.60922, it/sec: 4.4790859746753116
epoch 1 iter 54940: train loss 0.62483. lr 3.000000e-04, running loss 0.61082, it/sec: 4.514096614868754
epoch 1 iter 54960: train loss 0.55747. lr 3.000000e-04, running loss 0.61043, it/sec: 4.439946364222854
epoch 1 iter 54980: train loss 0.62670. lr 3.000000e-04, running loss 0.61027, it/sec: 4.437518404589517
epoch 1 iter 55000: train loss 0.55491. lr 3.000000e-04, running loss 0.61026, it/sec: 4.477454647541952
epoch 1 iter 55020: train loss 0.61627. lr 3.000000e-04, running loss 0.61028, it/sec: 4.466770793728032
epoch 1 iter 55040: train loss 0.46706. lr 3.000000e-04, running loss 0.61003, it/sec: 4.507484520813631
epoch 1 iter 55060: train loss 0.61049. lr 3.000000e-04, running loss 0.61017, it/sec: 4.464836544178236
epoch 1 iter 55080: train loss 0.62259. lr 3.000000e-04, running loss 0.61040, it/sec: 4.512250290098602
epoch 1 iter 55100: train loss 0.57530. lr 3.000000e-04, running loss 0.61021, it/sec: 4.44788018493914
epoch 1 iter 55120: train loss 0.53498. lr 3.000000e-04, running loss 0.61072, it/sec: 4.508566539790457
epoch 1 iter 55140: train loss 0.56650. lr 3.000000e-04, running loss 0.61076, it/sec: 4.478967369307321
epoch 1 iter 55160: train loss 0.61452. lr 3.000000e-04, running loss 0.61099, it/sec: 4.510489009794135
epoch 1 iter 55180: train loss 0.60252. lr 3.000000e-04, running loss 0.61127, it/sec: 4.4736957540156315
epoch 1 iter 55200: train loss 0.55740. lr 3.000000e-04, running loss 0.61131, it/sec: 4.526302463140159
epoch 1 iter 55220: train loss 0.56987. lr 3.000000e-04, running loss 0.61160, it/sec: 4.445941699488844
epoch 1 iter 55240: train loss 0.61148. lr 3.000000e-04, running loss 0.61144, it/sec: 4.49496634895788
epoch 1 iter 55260: train loss 0.53578. lr 3.000000e-04, running loss 0.61100, it/sec: 4.453249984033759
epoch 1 iter 55280: train loss 0.57362. lr 3.000000e-04, running loss 0.61066, it/sec: 4.521620364778568
epoch 1 iter 55300: train loss 0.65295. lr 3.000000e-04, running loss 0.61091, it/sec: 4.4552809555509985
epoch 1 iter 55320: train loss 0.63086. lr 3.000000e-04, running loss 0.61135, it/sec: 4.520930164769986
epoch 1 iter 55340: train loss 0.61017. lr 3.000000e-04, running loss 0.61125, it/sec: 4.479675439650755
epoch 1 iter 55360: train loss 0.49602. lr 3.000000e-04, running loss 0.61054, it/sec: 4.463173626251553
epoch 1 iter 55380: train loss 0.59401. lr 3.000000e-04, running loss 0.60995, it/sec: 4.514993056204487
epoch 1 iter 55400: train loss 0.56233. lr 3.000000e-04, running loss 0.61025, it/sec: 4.468678445473102
epoch 1 iter 55420: train loss 0.59565. lr 3.000000e-04, running loss 0.61021, it/sec: 4.508994712055609
epoch 1 iter 55440: train loss 0.61937. lr 3.000000e-04, running loss 0.61063, it/sec: 4.5104251689462975
epoch 1 iter 55460: train loss 0.56192. lr 3.000000e-04, running loss 0.61033, it/sec: 4.504730431157656
epoch 1 iter 55480: train loss 0.72390. lr 3.000000e-04, running loss 0.61032, it/sec: 4.439219837854705
epoch 1 iter 55500: train loss 0.56911. lr 3.000000e-04, running loss 0.61052, it/sec: 4.51211092650402
epoch 1 iter 55520: train loss 0.63854. lr 3.000000e-04, running loss 0.61016, it/sec: 4.460026847400937
epoch 1 iter 55540: train loss 0.54448. lr 3.000000e-04, running loss 0.61019, it/sec: 4.528611773002841
epoch 1 iter 55560: train loss 0.61067. lr 3.000000e-04, running loss 0.61037, it/sec: 4.453423812711391
epoch 1 iter 55580: train loss 0.60516. lr 3.000000e-04, running loss 0.61041, it/sec: 4.510565018178801
epoch 1 iter 55600: train loss 0.69856. lr 3.000000e-04, running loss 0.61016, it/sec: 4.4579401943982395
epoch 1 iter 55620: train loss 0.55666. lr 3.000000e-04, running loss 0.60987, it/sec: 4.52401155308524
epoch 1 iter 55640: train loss 0.67513. lr 3.000000e-04, running loss 0.60944, it/sec: 4.448574045457454
epoch 1 iter 55660: train loss 0.73537. lr 3.000000e-04, running loss 0.60922, it/sec: 4.484044877397836
epoch 1 iter 55680: train loss 0.54778. lr 3.000000e-04, running loss 0.60928, it/sec: 4.466648092271598
epoch 1 iter 55700: train loss 0.67076. lr 3.000000e-04, running loss 0.60934, it/sec: 4.44193988075019
epoch 1 iter 55720: train loss 0.53490. lr 3.000000e-04, running loss 0.60912, it/sec: 4.464432840593507
epoch 1 iter 55740: train loss 0.64577. lr 3.000000e-04, running loss 0.60956, it/sec: 4.533962372989974
epoch 1 iter 55760: train loss 0.60125. lr 3.000000e-04, running loss 0.60981, it/sec: 4.4722967349931295
epoch 1 iter 55780: train loss 0.53771. lr 3.000000e-04, running loss 0.60957, it/sec: 4.506924926351603
epoch 1 iter 55800: train loss 0.72302. lr 3.000000e-04, running loss 0.60967, it/sec: 4.482646795750279
epoch 1 iter 55820: train loss 0.59818. lr 3.000000e-04, running loss 0.60946, it/sec: 4.522696684981903
epoch 1 iter 55840: train loss 0.65092. lr 3.000000e-04, running loss 0.60974, it/sec: 4.4454627919731395
epoch 1 iter 55860: train loss 0.57362. lr 3.000000e-04, running loss 0.60993, it/sec: 4.458479679717904
epoch 1 iter 55880: train loss 0.56863. lr 3.000000e-04, running loss 0.61017, it/sec: 4.497042917857453
epoch 1 iter 55900: train loss 0.66145. lr 3.000000e-04, running loss 0.61046, it/sec: 4.4273024418554305
epoch 1 iter 55920: train loss 0.57633. lr 3.000000e-04, running loss 0.61037, it/sec: 4.5082220818089
epoch 1 iter 55940: train loss 0.51760. lr 3.000000e-04, running loss 0.61042, it/sec: 4.4611190565856464
epoch 1 iter 55960: train loss 0.52312. lr 3.000000e-04, running loss 0.61027, it/sec: 4.526767186347397
epoch 1 iter 55980: train loss 0.55708. lr 3.000000e-04, running loss 0.60999, it/sec: 4.463044508971201
epoch 1 iter 56000: train loss 0.59500. lr 3.000000e-04, running loss 0.60989, it/sec: 4.507394455930871
epoch 1 iter 56020: train loss 0.56777. lr 3.000000e-04, running loss 0.61024, it/sec: 4.455521703115859
epoch 1 iter 56040: train loss 0.64755. lr 3.000000e-04, running loss 0.61051, it/sec: 4.514047179886591
epoch 1 iter 56060: train loss 0.69134. lr 3.000000e-04, running loss 0.61096, it/sec: 4.442040491503474
epoch 1 iter 56080: train loss 0.62630. lr 3.000000e-04, running loss 0.61071, it/sec: 4.537495839460338
epoch 1 iter 56100: train loss 0.58359. lr 3.000000e-04, running loss 0.61052, it/sec: 4.42624055582215
epoch 1 iter 56120: train loss 0.65616. lr 3.000000e-04, running loss 0.61059, it/sec: 4.508782078920473
epoch 1 iter 56140: train loss 0.60216. lr 3.000000e-04, running loss 0.61073, it/sec: 4.448280463818092
epoch 1 iter 56160: train loss 0.60426. lr 3.000000e-04, running loss 0.61116, it/sec: 4.528944832303632
epoch 1 iter 56180: train loss 0.67434. lr 3.000000e-04, running loss 0.61137, it/sec: 4.499625796431056
epoch 1 iter 56200: train loss 0.68809. lr 3.000000e-04, running loss 0.61192, it/sec: 4.49433578655006
epoch 1 iter 56220: train loss 0.57154. lr 3.000000e-04, running loss 0.61168, it/sec: 4.522537102782041
epoch 1 iter 56240: train loss 0.61282. lr 3.000000e-04, running loss 0.61136, it/sec: 4.438221426664142
epoch 1 iter 56260: train loss 0.53020. lr 3.000000e-04, running loss 0.61156, it/sec: 4.522467684581528
epoch 1 iter 56280: train loss 0.62140. lr 3.000000e-04, running loss 0.61166, it/sec: 4.481931337377479
epoch 1 iter 56300: train loss 0.60221. lr 3.000000e-04, running loss 0.61149, it/sec: 4.517504049426275
epoch 1 iter 56320: train loss 0.55094. lr 3.000000e-04, running loss 0.61133, it/sec: 4.4642894604047285
epoch 1 iter 56340: train loss 0.65095. lr 3.000000e-04, running loss 0.61116, it/sec: 4.470175649541672
epoch 1 iter 56360: train loss 0.62758. lr 3.000000e-04, running loss 0.61110, it/sec: 4.493680826870122
epoch 1 iter 56380: train loss 0.53464. lr 3.000000e-04, running loss 0.61078, it/sec: 4.514943724987035
epoch 1 iter 56400: train loss 0.51187. lr 3.000000e-04, running loss 0.61055, it/sec: 4.46533765956838
epoch 1 iter 56420: train loss 0.55629. lr 3.000000e-04, running loss 0.61068, it/sec: 4.501059511103528
epoch 1 iter 56440: train loss 0.70827. lr 3.000000e-04, running loss 0.61077, it/sec: 4.4368617095830025
epoch 1 iter 56460: train loss 0.61132. lr 3.000000e-04, running loss 0.61081, it/sec: 4.520869767126094
epoch 1 iter 56480: train loss 0.65629. lr 3.000000e-04, running loss 0.61046, it/sec: 4.470517735644697
epoch 1 iter 56500: train loss 0.51320. lr 3.000000e-04, running loss 0.61047, it/sec: 4.467419948696783
epoch 1 iter 56520: train loss 0.62826. lr 3.000000e-04, running loss 0.61052, it/sec: 4.465439492065043
epoch 1 iter 56540: train loss 0.74383. lr 3.000000e-04, running loss 0.61028, it/sec: 4.451467000515484
epoch 1 iter 56560: train loss 0.69513. lr 3.000000e-04, running loss 0.61043, it/sec: 4.516418307958064
epoch 1 iter 56580: train loss 0.61765. lr 3.000000e-04, running loss 0.61109, it/sec: 4.4535943449487485
epoch 1 iter 56600: train loss 0.62952. lr 3.000000e-04, running loss 0.61098, it/sec: 4.445334795145805
epoch 1 iter 56620: train loss 0.59739. lr 3.000000e-04, running loss 0.61127, it/sec: 4.473689008875959
epoch 1 iter 56640: train loss 0.65050. lr 3.000000e-04, running loss 0.61128, it/sec: 4.496021888756654
epoch 1 iter 56660: train loss 0.75697. lr 3.000000e-04, running loss 0.61187, it/sec: 4.506346707158023
epoch 1 iter 56680: train loss 0.52722. lr 3.000000e-04, running loss 0.61198, it/sec: 4.429262703959455
epoch 1 iter 56700: train loss 0.64739. lr 3.000000e-04, running loss 0.61185, it/sec: 4.48697758203761
epoch 1 iter 56720: train loss 0.54500. lr 3.000000e-04, running loss 0.61155, it/sec: 4.460350311389279
epoch 1 iter 56740: train loss 0.61541. lr 3.000000e-04, running loss 0.61125, it/sec: 4.448993945598496
epoch 1 iter 56760: train loss 0.55833. lr 3.000000e-04, running loss 0.61170, it/sec: 4.505908724013669
epoch 1 iter 56780: train loss 0.60411. lr 3.000000e-04, running loss 0.61194, it/sec: 4.4545022551852975
epoch 1 iter 56800: train loss 0.56627. lr 3.000000e-04, running loss 0.61150, it/sec: 4.479400010055573
epoch 1 iter 56820: train loss 0.66396. lr 3.000000e-04, running loss 0.61185, it/sec: 4.49034478868461
epoch 1 iter 56840: train loss 0.64937. lr 3.000000e-04, running loss 0.61214, it/sec: 4.449848460072693
epoch 1 iter 56860: train loss 0.58904. lr 3.000000e-04, running loss 0.61379, it/sec: 4.481065203487195
epoch 1 iter 56880: train loss 0.55727. lr 3.000000e-04, running loss 0.61389, it/sec: 4.480040716922791
epoch 1 iter 56900: train loss 0.51896. lr 3.000000e-04, running loss 0.61345, it/sec: 4.475402933968702
epoch 1 iter 56920: train loss 0.65408. lr 3.000000e-04, running loss 0.61369, it/sec: 4.518477039799137
epoch 1 iter 56940: train loss 0.57737. lr 3.000000e-04, running loss 0.61369, it/sec: 4.478147500285235
epoch 1 iter 56960: train loss 0.72504. lr 3.000000e-04, running loss 0.61314, it/sec: 4.47972554741502
epoch 1 iter 56980: train loss 0.53527. lr 3.000000e-04, running loss 0.61271, it/sec: 4.454746610351271
epoch 1 iter 57000: train loss 0.61585. lr 3.000000e-04, running loss 0.61241, it/sec: 4.491324026714313
epoch 1 iter 57020: train loss 0.66330. lr 3.000000e-04, running loss 0.61213, it/sec: 4.432276604627828
epoch 1 iter 57040: train loss 0.55686. lr 3.000000e-04, running loss 0.61207, it/sec: 4.503571190196968
epoch 1 iter 57060: train loss 0.53239. lr 3.000000e-04, running loss 0.61212, it/sec: 4.431062478153622
epoch 1 iter 57080: train loss 0.62676. lr 3.000000e-04, running loss 0.61182, it/sec: 4.480446725992917
epoch 1 iter 57100: train loss 0.66658. lr 3.000000e-04, running loss 0.61192, it/sec: 4.481151990230609
epoch 1 iter 57120: train loss 0.56327. lr 3.000000e-04, running loss 0.61201, it/sec: 4.469231578165043
epoch 1 iter 57140: train loss 0.66904. lr 3.000000e-04, running loss 0.61218, it/sec: 4.487839337281874
epoch 1 iter 57160: train loss 0.64832. lr 3.000000e-04, running loss 0.61206, it/sec: 4.488412574919576
epoch 1 iter 57180: train loss 0.60748. lr 3.000000e-04, running loss 0.61196, it/sec: 4.507220023552246
epoch 1 iter 57200: train loss 0.60495. lr 3.000000e-04, running loss 0.61201, it/sec: 4.390234761421722
epoch 1 iter 57220: train loss 0.55622. lr 3.000000e-04, running loss 0.61196, it/sec: 4.51557657648331
epoch 1 iter 57240: train loss 0.59168. lr 3.000000e-04, running loss 0.61199, it/sec: 4.445583383172938
epoch 1 iter 57260: train loss 0.65000. lr 3.000000e-04, running loss 0.61196, it/sec: 4.4911431715774075
epoch 1 iter 57280: train loss 0.52204. lr 3.000000e-04, running loss 0.61192, it/sec: 4.441655222754814
epoch 1 iter 57300: train loss 0.64046. lr 3.000000e-04, running loss 0.61204, it/sec: 4.452061406979359
epoch 1 iter 57320: train loss 0.55734. lr 3.000000e-04, running loss 0.61173, it/sec: 4.490857820283221
epoch 1 iter 57340: train loss 0.65693. lr 3.000000e-04, running loss 0.61238, it/sec: 4.46796113026891
epoch 1 iter 57360: train loss 0.60340. lr 3.000000e-04, running loss 0.61238, it/sec: 4.505410599671074
epoch 1 iter 57380: train loss 0.58055. lr 3.000000e-04, running loss 0.61216, it/sec: 4.430263859426836
epoch 1 iter 57400: train loss 0.61845. lr 3.000000e-04, running loss 0.61237, it/sec: 4.489579866589514
epoch 1 iter 57420: train loss 0.61333. lr 3.000000e-04, running loss 0.61220, it/sec: 4.46284132786692
epoch 1 iter 57440: train loss 0.62974. lr 3.000000e-04, running loss 0.61234, it/sec: 4.4735650265801326
epoch 1 iter 57460: train loss 0.64184. lr 3.000000e-04, running loss 0.61217, it/sec: 4.4842005900473
epoch 1 iter 57480: train loss 0.67113. lr 3.000000e-04, running loss 0.61198, it/sec: 4.444510123662725
epoch 1 iter 57500: train loss 0.60313. lr 3.000000e-04, running loss 0.61214, it/sec: 4.516143317211881
epoch 1 iter 57520: train loss 0.78414. lr 3.000000e-04, running loss 0.61192, it/sec: 4.447873912404476
epoch 1 iter 57540: train loss 0.59588. lr 3.000000e-04, running loss 0.61197, it/sec: 4.5107958253846325
epoch 1 iter 57560: train loss 0.78856. lr 3.000000e-04, running loss 0.61195, it/sec: 4.429187468565452
epoch 1 iter 57580: train loss 0.55257. lr 3.000000e-04, running loss 0.61149, it/sec: 4.493301004740199
epoch 1 iter 57600: train loss 0.63906. lr 3.000000e-04, running loss 0.61141, it/sec: 4.441368806619281
epoch 1 iter 57620: train loss 0.61366. lr 3.000000e-04, running loss 0.61163, it/sec: 4.487140362703656
epoch 1 iter 57640: train loss 0.54873. lr 3.000000e-04, running loss 0.61173, it/sec: 4.515540036324721
epoch 1 iter 57660: train loss 0.61975. lr 3.000000e-04, running loss 0.61196, it/sec: 4.4801063502523535
epoch 1 iter 57680: train loss 0.60910. lr 3.000000e-04, running loss 0.61217, it/sec: 4.507689653653258
epoch 1 iter 57700: train loss 0.59223. lr 3.000000e-04, running loss 0.61196, it/sec: 4.437265619950146
epoch 1 iter 57720: train loss 0.69323. lr 3.000000e-04, running loss 0.61220, it/sec: 4.5021108218216455
epoch 1 iter 57740: train loss 0.62982. lr 3.000000e-04, running loss 0.61225, it/sec: 4.465699028202061
epoch 1 iter 57760: train loss 0.51992. lr 3.000000e-04, running loss 0.61206, it/sec: 4.481722796961243
epoch 1 iter 57780: train loss 0.62476. lr 3.000000e-04, running loss 0.61232, it/sec: 4.502959786421093
epoch 1 iter 57800: train loss 0.65549. lr 3.000000e-04, running loss 0.61246, it/sec: 4.4660495048771915
epoch 1 iter 57820: train loss 0.56931. lr 3.000000e-04, running loss 0.61274, it/sec: 4.488634331428987
epoch 1 iter 57840: train loss 0.62501. lr 3.000000e-04, running loss 0.61250, it/sec: 4.495845809457153
epoch 1 iter 57860: train loss 0.59613. lr 3.000000e-04, running loss 0.61247, it/sec: 4.462745250194836
epoch 1 iter 57880: train loss 0.55053. lr 3.000000e-04, running loss 0.61253, it/sec: 4.495531787328799
epoch 1 iter 57900: train loss 0.52588. lr 3.000000e-04, running loss 0.61251, it/sec: 4.5072536857611105
epoch 1 iter 57920: train loss 0.55695. lr 3.000000e-04, running loss 0.61235, it/sec: 4.484137471294117
epoch 1 iter 57940: train loss 0.56219. lr 3.000000e-04, running loss 0.61218, it/sec: 4.5121916944069635
There was an issue while trying to parse BedFrame input
line 1854149: 2	6767504

catch_bed_parser_error is enabled. self.chrom will be None
device: cuda:0
save interval: 100000
batch size: 32
